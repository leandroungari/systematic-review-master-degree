@article{BARLETTA201365,
title = "Effect of different implementations of the same ice history in GIA modeling",
journal = "Journal of Geodynamics",
volume = "71",
pages = "65 - 73",
year = "2013",
issn = "0264-3707",
doi = "https://doi.org/10.1016/j.jog.2013.07.002",
url = "http://www.sciencedirect.com/science/article/pii/S0264370713000975",
author = "V.R. Barletta and A. Bordoni",
keywords = "Glacial Isostatic Adjustment, Antarctica, LGM, Methods comparison",
abstract = "This study shows the effect of changing the way ice histories are implemented in Glacial Isostatic Adjustment (GIA) codes to solve the sea level equation. The ice history models are being constantly improved and are provided in different formats. The overall algorithmic design of the sea-level equation solver often forces to implement the ice model in a representation that differs from the one originally provided. We show that using different representations of the same ice model gives important differences and artificial contributions to the sea level estimates, both at global and at regional scale. This study is not a speculative exercise. The ICE-5G model adopted in this work is widely used in present day sea-level analysis, but discrepancies between the results obtained by different groups for the same ice models still exist, and it was the effort to set a common reference for the sea-level community that inspired this work. Understanding this issue is important to be able to reduce the artefacts introduced by a non-suitable ice model representation. This is especially important when developing new GIA models, since neglecting this problem can easily lead to wrong alignment of the ice and sea-level histories, particularly close to the deglaciation areas, like Antarctica."
}
@article{WANG201524,
title = "Visual tracking based on online sparse feature learning",
journal = "Image and Vision Computing",
volume = "38",
pages = "24 - 32",
year = "2015",
issn = "0262-8856",
doi = "https://doi.org/10.1016/j.imavis.2015.04.005",
url = "http://www.sciencedirect.com/science/article/pii/S0262885615000384",
author = "Zelun Wang and Jinjun Wang and Shun Zhang and Yihong Gong",
keywords = "Visual tracking, Sparse coding, Sparse feature, Bayesian classifier, Haar-like features",
abstract = "Various visual tracking approaches have been proposed for robust target tracking, among which using sparse representation of the tracking target yields promising performance. Some earlier works in this line used a fixed subset of features to compress the target's appearance, which has limited modeling capacity between the target and the background, and could not accommodate their appearance change over long period of time. In this paper, we propose a visual tracking method by modeling targets with online-learned sparse features. We first extract high dimensional Haar-like features as an over-completed basis set, and then solve the feature selection problem in an efficient L1-regularized sparse-coding process. The selected low-dimensional representation best discriminates the target from its neighboring background. Next we use a naive Bayesian classifier to select the most-likely target candidate by a binary classification process. The online feature selection process happens when there are significant appearance changes identified by a thresholding strategy. In this way, our proposed method could work for long tracking tasks. At the same time, our comprehensive experimental evaluation has shown that the proposed methods achieve excellent running speed and higher accuracy over many state-of-the-art approaches."
}
@article{FUNG2017682,
title = "#Globalhealth Twitter Conversations on #Malaria, #HIV, #TB, #NCDS, and #NTDS: a Cross-Sectional Analysis",
journal = "Annals of Global Health",
volume = "83",
number = "3",
pages = "682 - 690",
year = "2017",
note = "Current Topics in Global Health",
issn = "2214-9996",
doi = "https://doi.org/10.1016/j.aogh.2017.09.006",
url = "http://www.sciencedirect.com/science/article/pii/S2214999617306513",
author = "Isaac Chun-Hai Fung and Ashley M. Jackson and Jennifer O. Ahweyevu and Jordan H. Grizzle and Jingjing Yin and Zion Tsz Ho Tse and Hai Liang and Juliet N. Sekandi and King-Wa Fu",
keywords = "global health, health communication, Internet, machine learning, manual coding, social media, Twitter",
abstract = "Background
Advocates use the hashtag #GlobalHealth on Twitter to draw users' attention to prominent themes on global health, to harness their support, and to advocate for change.
Objectives
We aimed to describe #GlobalHealth tweets pertinent to given major health issues.
Methods
Tweets containing the hashtag #GlobalHealth (N = 157,951) from January 1, 2014, to April 30, 2015, were purchased from GNIP Inc. We extracted 5 subcorpora of tweets, each with 1 of 5 co-occurring disease-specific hashtags (#Malaria, #HIV, #TB, #NCDS, and #NTDS) for further analysis. Unsupervised machine learning was applied to each subcorpus to categorize the tweets by their underlying topics and obtain the representative tweets of each topic. The topics were grouped into 1 of 4 themes (advocacy; epidemiological information; prevention, control, and treatment; societal impact) or miscellaneous. Manual categorization of most frequent users was performed. Time zones of users were analyzed.
Findings
In the entire #GlobalHealth corpus (N = 157,951), there were 40,266 unique users, 85,168 retweets, and 13,107 unique co-occurring hashtags. Of the 13,087 tweets across the 5 subcorpora with co-occurring hashtag #malaria (n = 3640), #HIV (n = 3557), #NCDS (noncommunicable diseases; n = 2373), #TB (tuberculosis; n = 1781), and #NTDS (neglected tropical diseases; n = 1736), the most prevalent theme was prevention, control, and treatment (4339, 33.16%), followed by advocacy (3706, 28.32%), epidemiological information (1803, 13.78%), and societal impact (1617, 12.36%). Among the top 10 users who tweeted the highest number of tweets in the #GlobalHealth corpus, 5 were individual professionals, 3 were news media, and 2 were organizations advocating for global health. The most common users' time zone was Eastern Time (United States and Canada).
Conclusions
This study highlighted the specific #GlobalHealth Twitter conversations pertinent to malaria, HIV, tuberculosis, noncommunicable diseases, and neglected tropical diseases. These conversations reflect the priorities of advocates, funders, policymakers, and practitioners of global health on these high-burden diseases as they presented their views and information on Twitter to their followers."
}
@article{SONG201744,
title = "Species delimitation and phylogenetic reconstruction of the sinipercids (Perciformes: Sinipercidae) based on target enrichment of thousands of nuclear coding sequences",
journal = "Molecular Phylogenetics and Evolution",
volume = "111",
pages = "44 - 55",
year = "2017",
issn = "1055-7903",
doi = "https://doi.org/10.1016/j.ympev.2017.03.014",
url = "http://www.sciencedirect.com/science/article/pii/S1055790317302324",
author = "Shuli Song and Jinliang Zhao and Chenhong Li",
keywords = "Sinipercidae, Gene capture, SNPs, BFD, Historical biogeography, Divergence time",
abstract = "The sinipercids are freshwater fishes endemic to East Asia, mainly in China. Phylogenetic studies on the sinipercids have made great progress in the last decades, but interspecific relationships and evolutionary history of the sinipercids remain unresolved. Lack of distinctive morphological characters leads to problems in validating of some species, such as Siniperca loona. Moreover, genetic data are needed to delimitate species pairs with explicit hypothesis testing, such as in S. chuatsi vs. S. kneri and Coreoperca whiteheadi vs. C. liui. Here we reconstructed phylogeny of the sinipercids with an unprecedented scale of data, 16,943 loci of single-copy coding sequence data from nine sinipercid species, eight putative sister taxa and two outgroups. Targeted sequences were collected using gene enrichment and Illumina sequencing, yielding thousands of protein coding sequences and single nucleotide polymorphisms (SNPs) data. Maximum likelihood and coalescent species tree analyses resulted in identical and highly supported trees. We confirmed that the centrarchids are sister to the sinipercids. A monophyletic Sinipercidae with two genera, Siniperca and Coreoperca was also supported. Different from most previous studies, S. scherzeri was found as the most basal taxon to other species of Siniperca, which consists of two clades: a clade having S. roulei sister to S. chuatsi and S. kneri, and a clade consisting S. loona sister to S. obscura and S. undulata. We found that both S. loona and C. liui are valid species using Bayes factor delimitation (BFD∗) based on SNPs data. Species delimitation also provided decisive support for S. chuatsi and S. kneri being two distinct species. We calibrated a chronogram of the sinipercids based on 100 loci and three fossil calibration points using BEAST, and reconstructed ancestral ranges of the sinipercids using Lagrange Analysis (DEC model) and Statistical Dispersal-Vicariance Analysis (S-DIVA) implemented in RASP. Divergence time estimates and ancestral habitat reconstruction suggested a wide-ranging distribution of the common ancestor of the sinipercids in southern China at 53.1 million years ago (CI: 30.4–85.8Ma). The calibrated time tree is consistent with historical climate changes and geological events that might have shaped the current distribution of the sinipercids."
}
@article{KHATER201413,
title = "Contemporary evolution and genetic change of prey as a response to predator removal",
journal = "Ecological Informatics",
volume = "22",
pages = "13 - 22",
year = "2014",
issn = "1574-9541",
doi = "https://doi.org/10.1016/j.ecoinf.2014.02.005",
url = "http://www.sciencedirect.com/science/article/pii/S1574954114000223",
author = "Marwa Khater and Dorian Murariu and Robin Gras",
keywords = "Individual-based modeling, Predator–prey systems, Non-lethal effects, Machine learning, Predator removal",
abstract = "The ecological effects of predator removal and its consequence on prey behavior have been investigated widely; however, predator removal can also cause contemporary evolution of prey resulting in prey genetic change. Here we tested the role of predator removal on the contemporary evolution of prey traits such as movement, reproduction and foraging. We use EcoSim simulation which allows complex intra- and inter-specific interactions, based on individual evolving behavioral models, as well as complex predator–prey dynamics and coevolution in spatially homogenous and heterogeneous worlds. We model organisms' behavior using fuzzy cognitive maps (FCM) that are coded in their genomes which has a clear semantics making reasoning about causality of any evolved behavior possible. We show that the contemporary evolution of prey behavior owing to predator removal is also accompanied by prey genetic change. We employed machine learning methods, now recognized as holding great promise for the advancement of our understanding and prediction of ecological phenomena. A classification algorithm was used to demonstrate the difference between genomes belonging to prey coevolving with predators and prey evolving in the absence of predation pressure. We argue that predator introductions to naive prey might be destabilizing if prey have evolved and adapted to the absence of predators. Our results suggest that both predator introductions and predator removal from an ecosystem have widespread effects on the survival and evolution of prey by altering their genomes and behavior, even after relatively short time intervals. Our study highlights the need to consider both ecological and evolutionary time scales, as well as the complex interplay of behaviors between trophic levels, in determining the outcomes of predator–prey interactions."
}
@article{PAPATHANASSIOUZUHRT201557,
title = "Cognitive Load Management of Cultural Heritage Information: An Application Multi-Mix for Recreational Learners",
journal = "Procedia - Social and Behavioral Sciences",
volume = "188",
pages = "57 - 73",
year = "2015",
note = "Heritage as an alternative driver for sustainable development and economic recovery in South East Europe -Project SEE/B/0016/4.3/X SAGITTARIUS",
issn = "1877-0428",
doi = "https://doi.org/10.1016/j.sbspro.2015.03.339",
url = "http://www.sciencedirect.com/science/article/pii/S1877042815021321",
author = "Dorothea Papathanassiou-Zuhrt",
keywords = "Human Cognitive Architecture (HCA), Significance Assessment Tool (SAT), Heritage Interpretation, Cultural Heritage (CH), RM (RM), Quick Response Code (QRC), Hashtag, South East Europe (SEE), Working Memory (WM), Long-Term Memory (LTM)",
abstract = "Under the umbrella of the SEE/B/0016/4.3/X Project SAGITTARIUS a new cultural heritage infrastructure has been introduced in South East Europe. The main aim is to facilitate cognitive-emotional experiences in cultural heritage environments by effectively communicating cultural values to non-captives audiences. A 3-component Roving Museum (RM) is operated in seven countries (GR, BG, HR, HU, IT, RO). The RM adapts to visitor needs in a constantly changing knowledge ecosystem implementing new ways of recreational learning and visitor satisfaction. It includes a QRC-driven portable exhibition with 110 cultural heritage narratives, accessible via QRCs in the territory, an app for iOS and Android, and a social media driven participatory space, to support contextual co-creation and participatory learning. A cognitive driven communication pattern has been developed and adapted to the conditions regulating the recreational learning environment. The pattern employs interrelated content segments in order to free the working memory (WM) from irrelevant cognitive loads, enabling new cognitive content to relate to prior knowledge. The design presupposes a limited WM capacity to deal with visual, auditory and verbal material, and an almost unlimited long-term memory (LTM), able to hold mental representations that vary in their degree of automation. It considers WM constraints, element interactivity and 3 types of cognitive loads (CL). Cognitive accessibility is ensured through provision of novelty and variety, surprise and exploration, strictly avoiding engagement in complex cognitive procedures."
}
@article{OKEEFFE2015138,
title = "Creation of a personality garden—A tool for reflection and teacher development; an autoethnographical research paper",
journal = "Nurse Education Today",
volume = "35",
number = "1",
pages = "138 - 145",
year = "2015",
issn = "0260-6917",
doi = "https://doi.org/10.1016/j.nedt.2014.08.012",
url = "http://www.sciencedirect.com/science/article/pii/S0260691714002755",
author = "Tracey O'Keeffe",
keywords = "Autoethnography, Teaching, Emotional Connection, Self-concept, Motivation, Loci of control, Resilience, Growth",
abstract = "Background
This paper focuses on the Creation of a Personality Garden as a development tool. The original concept of the Garden was born from an autoethnographical study on the effects of self-concept on the teaching and learning experience.
Objectives
To explore the effects of self-concept on the teaching and learning experience.
Design
An autoethnographical study.
Setting
The study was undertaken in London, UK.
Participants
The researcher was also the sole participant in line with the autoethnographical approach.
Methods
Data was collected through the means of a reflective diary, personal memory data, interview and other creative genres. A thematic analysis approach was then used to code and group core concepts.
Results
Three key areas were identified: emotional connection, growth, and resilience, with a fourth as an over-arching driver for the study; the audience and act of teaching. These elements appeared to underpin a teaching philosophy which recognises the benefits of self-awareness in teachers and an ability and willingness to connect with learners and respond to individual needs. The Garden was one element of self-reflective data which was later re-designed to embrace the personal transformation of the researcher throughout the study.
Conclusions
Educationalists must have a willingness to explore self-perception as it can facilitate a sense of transparency and connection between the teacher and the learner. The Garden works as a dynamic tool and a sustainable model for confronting the on-going challenges of embracing risk-taking and emotionally connecting with learners within the educational context. It allows exploration of the nuances of personality and how the uniqueness of self interacts with the role of the teacher; a sometimes uncomfortable, yet safe, place to sit and experience a virtual reality check questioning assumptions and the theories that the individual espouses to use."
}
@article{AVELLAR20122019,
title = "The Ndynamics package—Numerical analysis of dynamical systems and the fractal dimension of boundaries",
journal = "Computer Physics Communications",
volume = "183",
number = "9",
pages = "2019 - 2020",
year = "2012",
issn = "0010-4655",
doi = "https://doi.org/10.1016/j.cpc.2012.03.024",
url = "http://www.sciencedirect.com/science/article/pii/S0010465512001294",
author = "J. Avellar and L.G.S. Duarte and L.A.C.P. da Mota and N. de Melo and J.E.F. Skea",
keywords = "Dynamical systems, Box counting, Fractal dimension, Symbolic computation",
abstract = "A set of Maple routines is presented, fully compatible with the new releases of Maple (14 and higher). The package deals with the numerical evolution of dynamical systems and provide flexible plotting of the results. The package also brings an initial conditions generator, a numerical solver manager, and a focusing set of routines that allow for better analysis of the graphical display of the results. The novelty that the package presents an optional C interface is maintained. This allows for fast numerical integration, even for the totally inexperienced Maple user, without any C expertise being required. Finally, the package provides the routines to calculate the fractal dimension of boundaries (via box counting). New version program summary Program Title: Ndynamics Catalogue identifier: %Leave blank, supplied by Elsevier. Licensing provisions: no. Programming language: Maple, C. Computer: Intel(R) Core(TM) i3 CPU M330 @ 2.13 GHz. Operating system: Windows 7. RAM: 3.0 GB Keywords: Dynamical systems, Box counting, Fractal dimension, Symbolic computation, Differential equations, Maple. Classification: 4.3. Catalogue identifier of previous version: ADKH_v1_0. Journal reference of previous version: Comput. Phys. Commun. 119 (1999) 256. Does the new version supersede the previous version?: Yes. Nature of problem Computation and plotting of numerical solutions of dynamical systems and the determination of the fractal dimension of the boundaries. Solution method The default method of integration is a fifth-order Runge–Kutta scheme, but any method of integration present on the Maple system is available via an argument when calling the routine. A box counting [1] method is used to calculate the fractal dimension [2] of the boundaries. Reasons for the new version The Ndynamics package met a demand of our research community for a flexible and friendly environment for analyzing dynamical systems. All the user has to do is create his/her own Maple session, with the system to be studied, and use the commands on the package to (for instance) calculate the fractal dimension of a certain boundary, without knowing or worrying about a single line of C programming. So the package combines the flexibility and friendly aspect of Maple with the fast and robust numerical integration of the compiled (for example C) basin. The package is old, but the problems it was designed to dealt with are still there. Since Maple evolved, the package stopped working, and we felt compelled to produce this version, fully compatible with the latest version of Maple, to make it again available to the Maple user. Summary of revisions Deprecated Maple Packages and Commands: Paraphrasing the Maple in-built help files, “Some Maple commands and packages are deprecated. A command (or package) is deprecated when its functionality has been replaced by an improved implementation. The newer command is said to supersede the older one, and use of the newer command is strongly recommended”. So, we have examined our code to see if some of these occurrences could be dangerous for it. For example, the “readlib” command is unnecessary, and we have removed its occurrences from our code. We have checked and changed all the necessary commands in order for us to be safe in respect to danger from this source. Another change we had to make was related to the tools we have implemented in order to use the interface for performing the numerical integration in C, externally, via the use of the Maple command “ssystem”. In the past, we had used, for the external C integration, the DJGPP system. But now we present the package with (free) Borland distribution. The compilation and compiling commands are now slightly changed. For example, to compile only, we had used “gcc-c”; now, we use “bcc32-c”, etc. All this installation (Borland) is explained on a “README” file we are submitting here to help the potential user. Restrictions Besides the inherent restrictions of numerical integration methods, this version of the package only deals with systems of first-order differential equations. Unusual features This package provides user-friendly software tools for analyzing the character of a dynamical system, whether it displays chaotic behaviour, and so on. Options within the package allow the user to specify characteristics that separate the trajectories into families of curves. In conjunction with the facilities for altering the user’s viewpoint, this provides a graphical interface for the speedy and easy identification of regions with interesting dynamics. An unusual characteristic of the package is its interface for performing the numerical integrations in C using a fifth-order Runge–Kutta method (default). This potentially improves the speed of the numerical integration by some orders of magnitude and, in cases where it is necessary to calculate thousands of graphs in regions of difficult integration, this feature is very desirable. Besides that tool, somewhat more experienced users can produce their own C integrator and, by using the commands available in the package, use it as the C integrator provided with the package as long as the new integrator manages the input and output in the same format as the default one does. Running time This depends strongly on the dynamical system. With an Intel® Core™ i3 CPU M330 @ 2.13 GHz, the integration of 50 graphs, for a system of two first-order equations, typically takes less than a second to run (with the C integration interface). Without the C interface, it takes a few seconds. In order to calculate the fractal dimension, where we typically use 10,000 points to integrate, using the C interface it takes from 20 to 30 s. Without the C interface, it becomes really impractical, taking, sometimes, for the same case, almost an hour. For some cases, it takes many hours."
}
@article{MILLS201634,
title = "Using a community of inquiry framework to teach a nursing and midwifery research subject: An evaluative study",
journal = "Nurse Education Today",
volume = "43",
pages = "34 - 39",
year = "2016",
issn = "0260-6917",
doi = "https://doi.org/10.1016/j.nedt.2016.04.016",
url = "http://www.sciencedirect.com/science/article/pii/S0260691716300417",
author = "Jane Mills and Karen Yates and Helena Harrison and Cindy Woods and Jennifer Chamberlain-Salaun and Scott Trueman and Marnie Hitchins",
keywords = "Communities of Inquiry, Nurse research education, Student satisfaction",
abstract = "Background
Postgraduate nursing students' negative perceptions about a core research subject at an Australian university led to a revision and restructure of the subject using a Communities of Inquiry framework. Negative views are often expressed by nursing and midwifery students about the research process. The success of evidence-based practice is dependent on changing these views. A Community of Inquiry is an online teaching, learning, thinking, and sharing space created through the combination of three domains—teacher presence (related largely to pedagogy), social presence, and cognitive presence (critical thinking).
Objectives
Evaluate student satisfaction with a postgraduate core nursing and midwifery subject in research design, theory, and methodology, which was delivered using a Communities of Inquiry framework.
Setting, Participants, and Methods
This evaluative study incorporated a validated Communities of Inquiry survey (n=29) and interviews (n=10) and was conducted at an Australian university. Study participants were a convenience sample drawn from 56 postgraduate students enrolled in a core research subject. Survey data were analysed descriptively and interviews were coded thematically.
Results
Five main themes were identified: subject design and delivery; cultivating community through social interaction; application—knowledge, practice, research; student recommendations; and technology and technicalities. Student satisfaction was generally high, particularly in the areas of cognitive presence (critical thinking) and teacher presence (largely pedagogy related). Students' views about the creation of a “social presence” were varied but overall, the framework was effective in stimulating both inquiry and a sense of community.
Conclusions
The process of research is, in itself, the creation of a “community of inquiry.” This framework showed strong potential for use in the teaching of nurse research subjects; satisfaction was high as students reported learning, not simply the theory and the methods of research, but also how to engage in “doing” research by forging professional and intellectual communities."
}
@article{ESPOSITO20171,
title = "Expectation and futurity: The remarkable success of genetic determinism",
journal = "Studies in History and Philosophy of Science Part C: Studies in History and Philosophy of Biological and Biomedical Sciences",
volume = "62",
pages = "1 - 9",
year = "2017",
issn = "1369-8486",
doi = "https://doi.org/10.1016/j.shpsc.2017.01.001",
url = "http://www.sciencedirect.com/science/article/pii/S1369848617300018",
author = "Maurizio Esposito",
keywords = "Genetic determinism, Genomics, Rhetoric of science",
abstract = "Genetic determinism is nowadays largely questioned and widely criticized. However, if we look at the history of biology in the last one hundred years, we realize that genetic determinism has always been controversial. Why, then, did it acquire such relevance in the past despite facing longstanding criticism? Through the analysis of some of the ambitious expectations of future scientific applications, this article explores the possibility that part of the historical success of genetic determinism lies in the powerful rhetorical strategies that have connected the germinal matter with alluring bio-technological visions. Indeed, in drawing on the recent perspectives of “expectation studies” in science and technology, it will be shown that there has been an interesting historical relationship between reductionist notions of the gene as a hereditary unit, coded information or functional DNA segment, and startling prophecies of what controlling such an entity might achieve. It will also be suggested that the well-known promissory nature of genomics is far older than the emergence of biotechnology in the 1970s. At least from the time of the bio-utopias predicted by J.B.S. Haldane and J. S. Huxley, the gene has often been surrounded by what I call the “rhetoric of futurity”: a promissory rhetoric that, despite momentous changes in the life sciences throughout the 20th century, has remained relatively consistent over time."
}
@article{YAMAMOTO20133997,
title = "High-performance Supercomputing as a Risk Evaluation Tool for Geologic Carbon Dioxide Storage",
journal = "Energy Procedia",
volume = "37",
pages = "3997 - 4005",
year = "2013",
note = "GHGT-11 Proceedings of the 11th International Conference on Greenhouse Gas Control Technologies, 18-22 November 2012, Kyoto, Japan",
issn = "1876-6102",
doi = "https://doi.org/10.1016/j.egypro.2013.06.299",
url = "http://www.sciencedirect.com/science/article/pii/S1876610213005420",
author = "Hajime Yamamoto and Shinichi Nanai and Keni Zhang and Pascal Audigane and Christophe Chiaberge and Ryusei Ogata and Noriaki Nishikawa and Yuichi Hirokawa and Satoru Shingu and Kengo Nakajima",
keywords = "CO storage, parallel computing, heterogeneity, interfacial instability, The Earth Simulator",
abstract = "Numerical modelling is a vital tool for predicting the behavior and fate of CO2 in reservoirs as well as its impacts on subsurface environments. Recently, powerful numerical codes that are capable of solving coupled complex processes of physics and chemistry required for such modeling works have been developed. However they are often computationally demanding for solving the complex non-linear models in sufficient spatial and temporal resolutions. Geological heterogeneity and uncertainties further increase the challenges in modeling work, because they may necessitate stochastic modeling with multiple realizations. There is clearly a need for high-performance computing. In this study, we implemented TOUGH2-MP code (a parallel version of multi-phase flow simulator TOUGH2) on two different types (vector- and scalar-type) of world-class supercomputers with tens of thousands of processors in Japan. The parallelized code generally exhibited excellent performance and scalability after adequate tune-ups of the code. Using the code and the supercomputers, we have been performed several computationally demanding simulations. In this paper, we present the performances of parallel computation of the code measured on the two supercomputers. Then the following two examples are presented: 1) a highly heterogeneous high-resolution model, representing irregular nature of sand/shale distribution; 2) “Dissolution Diffusion Convection Process”, which is expected to significantly enhance the dissolution trapping. Through the above two examples, it is illustrated that the spatial resolution of numerical model can critically change the evaluation of the effectiveness of CO2 trapping mechanisms, demonstrating the necessity of supercomputing techniques for evaluating these risks more accurately."
}
@article{LI201732,
title = "Multi-Connection Pattern Analysis: Decoding the representational content of neural communication",
journal = "NeuroImage",
volume = "162",
pages = "32 - 44",
year = "2017",
issn = "1053-8119",
doi = "https://doi.org/10.1016/j.neuroimage.2017.08.033",
url = "http://www.sciencedirect.com/science/article/pii/S1053811917306808",
author = "Yuanning Li and Robert Mark Richardson and Avniel Singh Ghuman",
keywords = "Functional connectivity, Multivariate statistical analysis, Decoding, Representation similarity analysis, Functional magnetic resonance imaging (fMRI), Intracranial electroencephalography (iEEG)",
abstract = "The lack of multivariate methods for decoding the representational content of interregional neural communication has left it difficult to know what information is represented in distributed brain circuit interactions. Here we present Multi-Connection Pattern Analysis (MCPA), which works by learning mappings between the activity patterns of the populations as a factor of the information being processed. These maps are used to predict the activity from one neural population based on the activity from the other population. Successful MCPA-based decoding indicates the involvement of distributed computational processing and provides a framework for probing the representational structure of the interaction. Simulations demonstrate the efficacy of MCPA in realistic circumstances. In addition, we demonstrate that MCPA can be applied to different signal modalities to evaluate a variety of hypothesis associated with information coding in neural communications. We apply MCPA to fMRI and human intracranial electrophysiological data to provide a proof-of-concept of the utility of this method for decoding individual natural images and faces in functional connectivity data. We further use a MCPA-based representational similarity analysis to illustrate how MCPA may be used to test computational models of information transfer among regions of the visual processing stream. Thus, MCPA can be used to assess the information represented in the coupled activity of interacting neural circuits and probe the underlying principles of information transformation between regions."
}
@article{SPARKMAN2012164,
title = "Rates of molecular evolution vary in vertebrates for insulin-like growth factor-1 (IGF-1), a pleiotropic locus that regulates life history traits",
journal = "General and Comparative Endocrinology",
volume = "178",
number = "1",
pages = "164 - 173",
year = "2012",
issn = "0016-6480",
doi = "https://doi.org/10.1016/j.ygcen.2012.04.022",
url = "http://www.sciencedirect.com/science/article/pii/S0016648012001827",
author = "Amanda M. Sparkman and Tonia S. Schwartz and Jill A. Madden and Scott E. Boyken and Neil B. Ford and Jeanne M. Serb and Anne M. Bronikowski",
keywords = "Insulin-like growth factor 1, IGF-1, Reptile, Molecular evolution, Protein structure",
abstract = "Insulin-like growth factor-1 (IGF-1) is a member of the vertebrate insulin/insulin-like growth factor/relaxin gene family necessary for growth, reproduction, and survival at both the cellular and organismal level. Its sequence, protein structure, and function have been characterized in mammals, birds, and fish; however, a notable gap in our current knowledge of the function of IGF-1 and its molecular evolution is information in ectothermic reptiles. To address this disparity, we sequenced the coding region of IGF-1 in 11 reptile species—one crocodilian, three turtles, three lizards, and four snakes. Complete sequencing of the full mRNA transcript of a snake revealed the Ea-isoform, the predominant isoform of IGF-1 also reported in other vertebrate groups. A gene tree of the IGF-1 protein-coding region that incorporated sequences from diverse vertebrate groups showed similarity to the species phylogeny, with the exception of the placement of Testudines as sister group to Aves, due to their high nucleotide sequence similarity. In contrast, long-branch lengths indicate more rapid divergence in IGF-1 among lizards and snakes. Additionally, lepidosaurs (i.e., lizards and snakes) had higher rates of non-synonymous:synonymous substitutions (dN/dS) relative to archosaurs (i.e., birds and crocodilians) and turtles. Tests for positive selection on specific codons within branches and evaluation of the changes in the amino acid properties, suggested positive selection in lepidosaurs on the C domain of IGF-1, which is involved in binding affinity to the IGF-1 receptor. Predicted structural changes suggest that major alterations in protein structure and function may have occurred in reptiles. These data propose new insights into the molecular co-evolution of IGF-1 and its receptors, and ultimately the evolution of IGF-1’s role in regulating life-history traits across vertebrates."
}
@article{STRUMSKY20151445,
title = "Identifying the sources of technological novelty in the process of invention",
journal = "Research Policy",
volume = "44",
number = "8",
pages = "1445 - 1461",
year = "2015",
issn = "0048-7333",
doi = "https://doi.org/10.1016/j.respol.2015.05.008",
url = "http://www.sciencedirect.com/science/article/pii/S0048733315000840",
author = "Deborah Strumsky and José Lobo",
keywords = "Patent technology codes, Technological novelty, Combination, Origination",
abstract = "Much work on technological change agrees that the combination of new and existing technological capabilities is one of the principal sources of inventive novelty, and that there have been instances in history when new inventions appear with few antecedents. The many discussions across research communities regarding the relative roles of combination and origination as sources of technological novelty have not provided much in the way of formal identification and quantification. By taking advantage of the technology codes used by the U.S. Patent Office to classify patents, we discretize technologies and identify four distinct sources of technological novelty. The resulting technological novelty taxonomy is then used to assess the relative importance of refining existing technologies, combining existing and new technologies, and de novo creation of technological capabilities as sources of new inventions. Our results clearly show that the process of invention has been primarily a combinatorial process accompanied by rare occurrences of technological origination. The importance of reusing existing technological capabilities to generate inventions has been steadily rising and recently overtook recombination as the source of novelty for most new inventions."
}
@article{VIHALEMM201638,
title = "Consumers, citizens or citizen-consumers? Domestic users in the process of Estonian electricity market liberalization",
journal = "Energy Research & Social Science",
volume = "13",
pages = "38 - 48",
year = "2016",
note = "Energy Transitions in Europe: Emerging Challenges, Innovative Approaches, and Possible Solutions",
issn = "2214-6296",
doi = "https://doi.org/10.1016/j.erss.2015.12.004",
url = "http://www.sciencedirect.com/science/article/pii/S2214629615300876",
author = "Triin Vihalemm and Margit Keller",
keywords = "Citizen-consumer, Energy citizen, Positioning theory, Practice theory, Estonia, Electricity market liberalisation",
abstract = "This study analyses the development of domestic customers’ energy-related performances and understandings during the transition from centralized, monopolist electricity provision to a liberal market in Estonia in 2012–2013. Liberalization brought about not only a new institutional and legal framework for electricity purchases, but also a significant price rise. The study proceeds from the assumption that these structural changes catalyzed shifts in the electricity-related practices of consumers and citizens. Theoretically, the analysis builds on practice theory and positioning analysis. We investigated how domestic electricity purchasing and consumption were positioned in media texts and consumers’ self-positionings vis-à-vis media discourse, including their resistance to what was interpreted as acceptable conduct. To code media texts, diaries and interviews, we employed the concept of performance positioning. The results reveal that learning the new social practice of purchasing electricity as a service made electricity more salient and visible, both as an object of consumption and as an object of media-inspired public discussion and critique, encouraging a search for new solutions, such as collective mobilization to bargain with suppliers. The paper’s further contribution lies in discussing the issue of a supportive communicative environment in the development of citizen-consumer self-positionings conducive to socially innovative forms of energy governance and usage."
}
@article{MAGHBOULI2013758,
title = "An advanced combustion model coupled with detailed chemical reaction mechanism for D.I diesel engine simulation",
journal = "Applied Energy",
volume = "111",
pages = "758 - 770",
year = "2013",
issn = "0306-2619",
doi = "https://doi.org/10.1016/j.apenergy.2013.05.031",
url = "http://www.sciencedirect.com/science/article/pii/S0306261913004327",
author = "Amin Maghbouli and Wenming Yang and Hui An and Jing Li and Siaw Kiang Chou and Kian Jon Chua",
keywords = "Diesel engine, Direct injection, KIVA-4, Multi-component combustion model",
abstract = "A multi-dimensional computational fluid dynamics (CFD) modeling was conducted on a direct injection turbo-charged diesel engine based on KIVA-4 code under full and mid engine loads. Multi-component fuel evaporation model of KIVA-4 was used and coupled with advanced combustion chemistry to generate a multi-component fuel combustion model by integrating CHEMKIN II into the KIVA-4 code. As the coding schema of KIVA-4 in the case of data/parameter allocation, etc. was different compared to previous version of KIVA-3V, a considerable amount of FORTRAN programming was performed in order to develop a multi-component fuel combustion model. The developed combustion model was capable of modeling combustion process of number of chemical species as the components of direct injected liquid fuel. Comparing to the single component fuel combustion model, new model is capable of comprehensive combustion modeling of blend fuel and heavy hydro-carbon fuels. Furthermore, spray breakup and collision models were changed to more advanced Kelvin–Helmholtz and Rayleigh–Taylor (KH–RT) and O’Rourke models, respectively. The model was used to simulate direct injected diesel engine under full and mid engine loads at three engine speed conditions. Extracted temporal and spatial results for equivalence ratio distribution inside the combustion chamber showed that under full load condition, a considerable amount of fuel was trapped in piston bowl after initiation of the injection process where such fuel rich local regions provide the potential for production of higher soot emission. Mean value of the fuel concentration history showed that the ignition delay was increased under mid engine load at all engine speeds producing higher amounts of unburned hydro carbons and carbon monoxide. By reducing engine load and speed, output power was decreased as well. However, same trend was not reported for the indicated thermal efficiency as the middle engine speed in considered engine loads, had slightly higher efficiency."
}
@article{GIRAUDO2015159,
title = "Chronic toxicity evaluation of the flame retardant tris (2-butoxyethyl) phosphate (TBOEP) using Daphnia magna transcriptomic response",
journal = "Chemosphere",
volume = "132",
pages = "159 - 165",
year = "2015",
issn = "0045-6535",
doi = "https://doi.org/10.1016/j.chemosphere.2015.03.028",
url = "http://www.sciencedirect.com/science/article/pii/S0045653515002386",
author = "Maeva Giraudo and Mélanie Douville and Magali Houde",
keywords = "Tris (2-butoxyethyl) phosphate, , Toxicogenomics, Microarray, Multi-level analysis",
abstract = "Tris (2-butoxyethyl) phosphate (TBOEP) is an organophosphorous-containing flame retardant (OPFR) of high production volume used in a broad range of applications. The use of TBOEP containing products has resulted in its release and ubiquitous occurrence in the aquatic environment. In this study, Daphnia magna transcriptomic response was measured by microarray to evaluate sublethal effects of TBOEP as part of a multi-level biological approach including specific gene transcription measured by qRT-PCR, enzyme activity, and life-history endpoints (i.e., survival, growth and reproduction). Chronic exposure (21 d) to a range of sublethal concentrations of TBOEP (14.7–1470μgL−1) did not impact growth, survival or reproduction, although the number of offspring decreased between the lowest and the highest dose. Gene transcription profiling by microarray analysis revealed that 101 genes were differentially transcribed in response to TBOEP (fold change treated/control ±1, p<0.05). Most of the responding genes were involved in protein metabolism (9), biosynthesis (4) and energy metabolism (6) indicating that TBOEP could have chronic toxic effects on aquatic organisms at sublethal doses by disrupting essential biological pathways. Nine genes were found to be commonly affected by more than one dose, including a gene coding for cathepsin D and multiple isoforms of genes coding for hemoglobin, suggesting potential biomarkers of interest. Microarray results were confirmed by qRT-PCR and measurements at the protein level as cathepsin D enzymatic activity increased significantly in the highest dose treatment. Results highlight the relevance of using the transcriptomic response of D. magna as a first line of evidence to unravel the mode of action of chemicals."
}
@article{CASSIDY2018503,
title = "A Perceptual Inference Mechanism for Hallucinations Linked to Striatal Dopamine",
journal = "Current Biology",
volume = "28",
number = "4",
pages = "503 - 514.e4",
year = "2018",
issn = "0960-9822",
doi = "https://doi.org/10.1016/j.cub.2017.12.059",
url = "http://www.sciencedirect.com/science/article/pii/S0960982218300046",
author = "Clifford M. Cassidy and Peter D. Balsam and Jodi J. Weinstein and Rachel J. Rosengard and Mark Slifstein and Nathaniel D. Daw and Anissa Abi-Dargham and Guillermo Horga",
keywords = "dopamine, hallucinations, schizophrenia, psychosis, sensory learning, Bayesian inference, amphetamine, PET imaging, predictive coding, illusion",
abstract = "Summary
Hallucinations, a cardinal feature of psychotic disorders such as schizophrenia, are known to depend on excessive striatal dopamine. However, an underlying cognitive mechanism linking dopamine dysregulation and the experience of hallucinatory percepts remains elusive. Bayesian models explain perception as an optimal combination of prior expectations and new sensory evidence, where perceptual distortions such as illusions and hallucinations may occur if prior expectations are afforded excessive weight. Such excessive weight of prior expectations, in turn, could stem from a gain-control process controlled by neuromodulators such as dopamine. To test for such a dopamine-dependent gain-control mechanism of hallucinations, we studied unmedicated patients with schizophrenia with varying degrees of hallucination severity and healthy individuals using molecular imaging with a pharmacological manipulation of dopamine, structural imaging, and a novel task designed to measure illusory changes in the perceived duration of auditory stimuli under different levels of uncertainty. Hallucinations correlated with a perceptual bias, reflecting disproportional gain on expectations under uncertainty. This bias could be pharmacologically induced by amphetamine, strongly correlated with striatal dopamine release, and related to cortical volume of the dorsal anterior cingulate, a brain region involved in tracking environmental uncertainty. These findings outline a novel dopamine-dependent mechanism for perceptual modulation in physiological conditions and further suggest that this mechanism may confer vulnerability to hallucinations in hyper-dopaminergic states underlying psychosis."
}
@article{CUI2018,
title = "The first draft genome of Lophophorus: A step forward for Phasianidae genomic diversity and conservation",
journal = "Genomics",
year = "2018",
issn = "0888-7543",
doi = "https://doi.org/10.1016/j.ygeno.2018.07.016",
url = "http://www.sciencedirect.com/science/article/pii/S0888754318301678",
author = "Kai Cui and Wujiao Li and Jake George James and Changjun Peng and Jiazheng Jin and Chaochao Yan and Zhenxin Fan and Lianming Du and Megan Price and Yongjie Wu and Bisong Yue",
keywords = "Chinese monal, , Genome,  assembly, Adaptation",
abstract = "The monal genus (Lophophorus) is a branch of Phasianidae and its species inhabit the high-altitude mountains of the Qinghai-Tibet Plateau. The Chinese monal, L. lhuysii, is a threatened endemic bird of China that possesses high-altitude adaptability, diversity of plumage color and potentially low reproductive life history. This is the first study to describe the monal genome using next generation sequencing technology. The Chinese monal genome size is 1.01 Gb, with 16,940 protein-coding genes. Gene annotation yielded 100.93 Mb (9.97%) repeat elements, 785 ncRNA, 5,465,549 bp (0.54%) SSR and 15,550 (92%) genes in public databases. Compared to other birds and mammals, the genome evolution analysis showed numerous expanded gene families and positive selected genes involved in high-altitude adaptation, especially related to the adaptation of low temperature and hypoxia. Consequently, this gene data can be used to investigate the molecular evolution of high-altitude adaptation in future bird research. Our first published genome of the genus Lophophorus will be integral for the study of monal population genetic diversity and conservation, genomic evolution and Galliformes species differentiation in the Qinghai-Tibetan Plateau."
}
@article{HENNESSEY2018503,
title = "Venous Thromboembolism in Female Adolescents: Patient Characteristics",
journal = "Journal of Pediatric and Adolescent Gynecology",
volume = "31",
number = "5",
pages = "503 - 508",
year = "2018",
issn = "1083-3188",
doi = "https://doi.org/10.1016/j.jpag.2018.06.007",
url = "http://www.sciencedirect.com/science/article/pii/S1083318818302481",
author = "Catherine A. Hennessey and Vrunda K. Patel and Eshetu A. Tefera and Veronica Gomez-Lobo",
keywords = "Adolescent, Pediatric, Venous thromboembolism, Pulmonary embolism, Estrogen",
abstract = "Study Objective
Our goal was to describe the period prevalence of venous thromboembolism (VTE) and characterize adolescent female patients diagnosed with VTE by describing their age, race, and number of comorbidities. Female adolescents with estrogen exposure were of particular interest because estrogen-containing contraceptives increase the risk of VTE.
Design, Setting, Participants, and Interventions
We queried the Pediatric Health Information System database for International Classification of Diseases, Ninth/Tenth Revision, Clinical Modification codes to identify female patients aged 12-18 years diagnosed with a VTE or pulmonary embolism from April 2006 to March 2016 in the United States. Patient demographic characteristics and comorbidities were also analyzed. We divided our study population into two five-year groups and calculated the change in period prevalence of VTE between those groups.
Main Outcome Measures
Primary diagnosis of VTE in the extremities, or pulmonary embolism.
Results
The period prevalence of VTE increased from 2.3 female adolescents per 10,000 hospitalized children (group 1) to 3.3 per 10,000 (group 2), representing a statistically significant increase of 0.010% (P < .001). Caucasian and black individuals were most commonly affected. The number of girls affected increased steadily from ages 12 to 16 years and a large percentage (59.6%) had four or more comorbidities. In patients (n = 32) with estrogen exposure, more than 96% had one or more comorbidity in addition to estrogen exposure.
Conclusion
Pediatric health care providers should be aware that the period prevalence of VTEs in female adolescents is increasing. Those with a history of estrogen exposure rarely develop VTEs from estrogen alone and they typically have multiple comorbidities."
}
@article{MANDEL20121100,
title = "Assimilation of Perimeter Data and Coupling with Fuel Moisture in a Wildland Fire–Atmosphere DDDAS",
journal = "Procedia Computer Science",
volume = "9",
pages = "1100 - 1109",
year = "2012",
note = "Proceedings of the International Conference on Computational Science, ICCS 2012",
issn = "1877-0509",
doi = "https://doi.org/10.1016/j.procs.2012.04.119",
url = "http://www.sciencedirect.com/science/article/pii/S1877050912002402",
author = "Jan Mandel and Jonathan D. Beezley and Adam K. Kochanski and Volodymyr Y. Kondratenko and Minjeong Kim",
keywords = "DDDAS, Data assimilation, Wildland fire, Wildfire, Weather, Filtering, Level set method, Parameter estimation, Fuel moisture 2010 MSC: 65C05, 65Z05",
abstract = "We present a methodology to change the state of the Weather Research Forecasting (WRF) model coupled with the fire spread code SFIRE, based on Rothermel's formula and the level set method, and with a fuel moisture model. The fire perimeter in the model changes in response to data while the model is running. However, the atmosphere state takes time to develop in response to the forcing by the heat ﬂux from the fire. Therefore, an artificial fire history is created from an earlier fire perimeter to the new perimeter, and replayed with the proper heat ﬂuxes to allow the atmosphere state to adjust. The method is an extension of an earlier method to start the coupled fire model from a developed fire perimeter rather than an ignition point. The level set method can be also used to identify parameters of the simulation, such as the fire spread rate. The coupled model is available from openwfm.org, and it extends the WRF-Fire code in WRF release."
}
@article{HU2015191,
title = "Simulation of wear evolution using fictitious eigenstrains",
journal = "Tribology International",
volume = "82",
pages = "191 - 194",
year = "2015",
issn = "0301-679X",
doi = "https://doi.org/10.1016/j.triboint.2014.10.015",
url = "http://www.sciencedirect.com/science/article/pii/S0301679X14003727",
author = "Zupan Hu and Wei Lu and M.D. Thouless and J.R. Barber",
keywords = "Wear simulation, Thermal expansion, Finite element method, Contact mechanics",
abstract = "A numerical algorithm is described in which changes of geometry caused by wear can be simulated by ascribing fictitious anisotropic eigenstrains to a set of surface nodes. These eigenstrains are related to the wear depth at any location, and can be incorporated into calculations using the existing expansion modules in commercial codes, such as anisotropic swelling or thermal expansion. The proposed algorithm has been implemented, and the results compared to those from a conventional wear model involving periodic re-meshing. It has been shown to be accurate and efficient. The method provides an alternative to the re-meshing technique, and may provide advantages in history-dependent problems such as those involving plasticity, hysteretic friction or micro-slip."
}
@article{BLAZUN2015359,
title = "Survey on specific nursing competences: Students' perceptions",
journal = "Nurse Education in Practice",
volume = "15",
number = "5",
pages = "359 - 365",
year = "2015",
issn = "1471-5953",
doi = "https://doi.org/10.1016/j.nepr.2015.02.002",
url = "http://www.sciencedirect.com/science/article/pii/S1471595315000293",
author = "Helena Blažun and Peter Kokol and Janez Vošner",
keywords = "Nursing, Competences, Learning outcomes, Tuning project",
abstract = "Introduction
The nursing profession requires sophisticated interdisciplinary knowledge and skills, which is why numerous nursing curricula are being developed all across the world. The aim of the study was to assess students' perspectives about competences, defined by the Tuning project, they acquired and developed since enrolment in the undergraduate nursing study programme.
Methods
A survey was performed amongst 69 postgraduate Master degree students at the Faculty of Health Sciences University of Maribor, Slovenia (nursing graduates) and the research results were analysed using conventional statistical and correspondence analysis.
Results
Most of the participants felt that they are more competent in their awareness of different roles, responsibilities and functions of a nurse together with the ability to practice within the context of professional, ethical, regulatory and legal codes. However they felt less competent in leadership, management, and team competences.
Conclusions
According to the students' perceptions the current Nursing curriculum should be more future oriented and needs some core changes regarding the scope and level competences taught."
}
@article{BLANCOMARTIN201764,
title = "Extension of TOUGH-FLAC to the finite strain framework",
journal = "Computers & Geosciences",
volume = "108",
pages = "64 - 71",
year = "2017",
note = "TOUGH Symposium 2015: recent enhancements to the TOUGH family of codes and coupled flow and geomechanics processes modeling",
issn = "0098-3004",
doi = "https://doi.org/10.1016/j.cageo.2016.10.015",
url = "http://www.sciencedirect.com/science/article/pii/S009830041630601X",
author = "Laura Blanco-Martín and Jonny Rutqvist and Jens T. Birkholzer",
keywords = "Finite strains, Coupled THM processes, TOUGH2, FLAC, Sequential modeling, Voro++",
abstract = "The TOUGH-FLAC simulator for coupled thermal-hydraulic-mechanical processes modeling has been extended to the finite strain framework. In the approach selected, this extension has required modifications to the flow simulator (TOUGH2) and to the coupling scheme between the geomechanics and the flow sub-problems. In TOUGH2, the mass and energy balance equations have been extended to account for volume changes. Additionally, as large deformations are computed by FLAC3D, the geometry is updated in the flow sub-problem. The Voronoi partition needed in TOUGH2 is computed using an external open source library (Voro++) that uses the centroids of the deformed geomechanics mesh as generators of the Voronoi diagram. TOUGH-FLAC in infinitesimal and finite strain frameworks is verified against analytical solutions and other approaches to couple flow and geomechanics. Within the finite strain framework, TOUGH-FLAC is also successfully applied to a large-scale case. The extension of TOUGH-FLAC to the finite strain framework has little impact to the user as only one additional executable is needed (for Voro++), and the input files and the workflow of a simulation are the same as in standard TOUGH-FLAC. With this new provision for finite strains, TOUGH-FLAC can be used in the analysis of a wider range of engineering problems, and the areas of application of this simulator are therefore broadened."
}
@article{OH2017192,
title = "Playing real-time strategy games by imitating human players’ micromanagement skills based on spatial analysis",
journal = "Expert Systems with Applications",
volume = "71",
pages = "192 - 205",
year = "2017",
issn = "0957-4174",
doi = "https://doi.org/10.1016/j.eswa.2016.11.026",
url = "http://www.sciencedirect.com/science/article/pii/S0957417416306613",
author = "In-Seok Oh and Hochul Cho and Kyung-Joong Kim",
keywords = "Imitation, Case-based reasoning, Influence map, Potential field, Real-time strategy, Micromanagement",
abstract = "Unlike the situation with board games, artificial intelligence (AI) for real-time strategy (RTS) games usually suffers from numerous possible future outcomes because the state of the game is continuously changing in real time. Furthermore, AI is also required to be able to handle the increased complexity within a small amount of time. This constraint makes it difficult to build AI for RTS games with current state-of-the art intelligence techniques. A human player, on the other hand, is proficient in dealing with this level of complexity, making him a better game player than AI bots. Human players are especially good at controlling many units at the same time. It is hard to explain the micro-level control skills needed with only a few rules programmed into the bots. The design of micromanagement skills is one of the most difficult parts in the StarCraft AI design because it must be able to handle different combinations of units, army size, and unit placement. The unit control skills can have a big effect on the final outcome of a full game in professional player matches. For StarCraft AI competitions, they employed a relatively simple scripted AI to implement the unit control strategy. However, it is difficult to generate cooperative behavior using the simple AI strategies. Although there has been a few research done on micromanagement skills, it is still a challenging problem to design human-like high-level control skills. In this paper, we proposed the use of imitation learning based on human replays and influence map representation. In this approach, we extracted huge numbers of cases from the replays of experts and used them to determine the actions of units in the current game case. This was done without using any hand-coded rules. Because this approach is data-driven, it was essential to minimize the case search times. To support fast and accurate matching, we chose to use influence maps and data hashing. They allowed the imitation system to respond within a small amount time (one frame, 0.042s). With a very large number of cases (up to 500,000 cases), we showed that it is possible to respond competitively in real-time, with a high winning percentage in micromanagement scenarios."
}
@article{WENZEL2014776,
title = "Specifying model changes with UMLchange to support security verification of potential evolution",
journal = "Computer Standards & Interfaces",
volume = "36",
number = "4",
pages = "776 - 791",
year = "2014",
note = "Security in Information Systems: Advances and new Challenges.",
issn = "0920-5489",
doi = "https://doi.org/10.1016/j.csi.2013.12.011",
url = "http://www.sciencedirect.com/science/article/pii/S0920548913001852",
author = "S. Wenzel and D. Poggenpohl and J. Jürjens and M. Ochoa",
keywords = "Model evolution, Security verification, UML profile, Tool support",
abstract = "In model-based development, quality properties such as consistency of security requirements are often verified prior to code generation. Changed models have to be re-verified before re-generation. If several alternative evolutions of a model are possible, each alternative has to be modeled and verified to find the best model for further development. We present a verification strategy to analyze whether evolution preserves given security properties. The UMLchange profile is used for specifying potential evolutions of a given model simultaneously. We present a tool that reads these annotations and computes a delta containing all possible evolution paths. The paths can be verified wrt. security properties, and for each successfully verified path a new model version is generated automatically."
}
@article{FOSBROOK2015416,
title = "Mental Snapshots: Creating an Organized Plan for Health Assessment",
journal = "Journal of Professional Nursing",
volume = "31",
number = "5",
pages = "416 - 423",
year = "2015",
issn = "8755-7223",
doi = "https://doi.org/10.1016/j.profnurs.2015.04.004",
url = "http://www.sciencedirect.com/science/article/pii/S8755722315000496",
author = "Susan Curro Fosbrook",
keywords = "Mental snapshots, Health assessment, Quality & safety",
abstract = "Beginning nursing students enter a rapidly moving and changing health care climate. Multiple stimulations can frighten and overwhelm the student's ability to find order of essential patient information. Students need to know how to collect, process, and manage important health data accurately and efficiently in the clinical setting. An integrative method for teaching nursing students to walk into the patient's room and construct a patterned sequence of focused assessments assists students in creating an organized plan for health assessment. The Mental Snapshots Method includes three components for health assessment: (a) sequential assessment steps of the patient; (b) color-coded visual images of the patient representing a bodily condition; and (c) focused assessment questions of primary health complaint(s) with a plan for nursing care. This mental snapshots strategy employs an information processing model of sensory, memory, and motor functioning, which enable students to maintain patient quality and safety."
}
@article{MEDIC2013158,
title = "Beam model refinement and reduction",
journal = "Engineering Structures",
volume = "50",
pages = "158 - 169",
year = "2013",
note = "Engineering Structures: Modelling and Computations (special issue IASS-IACM 2012)",
issn = "0141-0296",
doi = "https://doi.org/10.1016/j.engstruct.2012.10.004",
url = "http://www.sciencedirect.com/science/article/pii/S0141029612005226",
author = "Senad Medić and Samir Dolarević and Adnan Ibrahimbegovic",
keywords = "Beam model reduction, Shear deformation, Hinges, Length-invariance",
abstract = "In this paper we present a method for systematic construction of the stiffness matrix of an arbitrary spatial frame element by performing a series of elementary transformations. The procedure of this kind is capable of including a number of element refinements (addition of shear deformation, variable cross-section, etc.) that are not easily accessible to standard displacement-based method. We also discuss the necessary modifications of the element stiffness matrix in order to accommodate different constraints, such as point constraints in terms of joint releases (or hinges) for moments or shear forces. This is obtained by means of model reduction providing a more effective approach than the alternative one in which the global number of degrees of freedom has to be increased by one for each new release. Finally, we elaborate upon the global constraints imposing the length-invariant deformation of frame elements with an arbitrary position in space. Several numerical examples are used to illustrate the performance of the proposed procedures. The computations are carried out by a modified version of computer code CAL."
}
@article{MCCORD2016397,
title = "Phylogenetic relationships and the evolution of BMP4 in triggerfishes and filefishes (Balistoidea)",
journal = "Molecular Phylogenetics and Evolution",
volume = "94",
pages = "397 - 409",
year = "2016",
issn = "1055-7903",
doi = "https://doi.org/10.1016/j.ympev.2015.09.014",
url = "http://www.sciencedirect.com/science/article/pii/S1055790315002808",
author = "Charlene L. McCord and Mark W. Westneat",
keywords = "Balistoidea, Taxonomy, Phylogenetics, Molecular evolution, ",
abstract = "The triggerfishes (family Balistidae) and filefishes (family Monacanthidae) comprise a charismatic superfamily (Balistoidea) within the diverse order Tetraodontiformes. This group of largely marine fishes occupies an impressive ecological range across the world’s oceans, and is well known for its locomotor and feeding diversity, unusual body shapes, small genome size, and ecological and economic importance. In order to investigate the evolutionary history of these important fish families, we used multiple phylogenetic methods to analyze molecular data from 86 species spanning the extant biodiversity of Balistidae and Monacanthidae. In addition to three gene regions that have been used extensively in phylogenetic analyses, we include sequence data for two mitochondrial regions, two nuclear markers, and the growth factor gene bmp4, which is involved with cranial development. Phylogenetic analyses strongly support the monophyly of the superfamily Balistoidea, the sister-family relationship of Balistidae and Monacanthidae, as well as three triggerfish and four filefish clades that are well resolved. A new classification for the Balistidae is proposed based on phylogenetic groups. Bayesian topology, as well as the timing of major cladogenesis events, is largely congruent with previous hypotheses of balistid phylogeny. However, we present a novel topology for major clades in the filefish family that illustrate the genera Aluterus and Stephanolepis are more closely related than previously posited. Molecular rates suggest a Miocene and Oligocene origin for the families Balistidae and Monacanthidae, respectively, and significant divergence of species in both families within the past 5million years. A second key finding of this study is that, relative to the other protein-coding gene regions in our DNA supermatrix, bmp4 shows a rapid accumulation of both synonymous and non-synonymous substitutions, especially within the family Monacanthidae. Overall substitution patterns in bmp4 support the hypothesis of stabilizing selection during the evolutionary history of regulatory genes, with a small number of isolated examples of accelerated non-synonymous changes detected in our phylogeny."
}
@article{SINGH2018331,
title = "A segmental duplication in the common ancestor of Brassicaceae is responsible for the origin of the paralogs KCS6-KCS5, which are not shared with other angiosperms",
journal = "Molecular Phylogenetics and Evolution",
volume = "126",
pages = "331 - 345",
year = "2018",
issn = "1055-7903",
doi = "https://doi.org/10.1016/j.ympev.2018.04.018",
url = "http://www.sciencedirect.com/science/article/pii/S1055790318300113",
author = "Swati Singh and Sandip Das and R. Geeta",
keywords = ", , Brassicaceae, Cuticular wax",
abstract = "Novel morphological structures allowed adaptation to dry conditions in early land plants. The cuticle, one such novelty, plays diverse roles in tolerance to abiotic and biotic stresses and plant development. Cuticular waxes represent a major constituent of the cuticle and are comprised of an assortment of chemicals that include, among others, very long chain fatty acids (VLCFAs). Members of the β-ketoacyl coenzyme A synthases (KCS) gene family code for enzymes that are essential for fatty acid biosynthesis. The gene KCS6 (CUT1) is known to be a key player in the production of VLCFA precursors essential for the synthesis of cuticular waxes in the model plant Arabidopsis thaliana (Brassicaceae). Despite its functional importance, relatively little is known about the evolutionary history of KCS6 or its paralog KCS5 in Brassicaceae or beyond. This lacuna becomes important when we extrapolate understanding of mechanisms gained from the model plant to its containing clades Brassicaceae, flowering plants, or beyond. The Brassicaceae, with several sequenced genomes and a known history of paleoploidy, mesopolyploidy and neopolyploidy, offer a system in which to study the evolution and diversification of the KCS6-KCS5 paralogy. Our phylogenetic analyses across green plants, combined with comparative genomic, microsynteny and evolutionary rates analyses across nine genomes of Brassicaceae, reveal that (1) the KCS6-KCS5 paralogy arose as the result of a large segmental duplication in the ancestral Brassicaceae, (2) the KCS6-KCS5 lineage is represented by a single copy in other flowering plant lineages, (3) the duplicated segments undergo different degrees of retention and loss, and (4) most of the genes in the KCS6 and KCS5 gene blocks (including KCS6 and KCS5 themselves) are under purifying selection. The last also true for most members of the KCS gene family in Brassicaceae, except for KCS8, KCS9 and KCS17, which are under positive selection and may be undergoing functional evolution, meriting further investigation. Overall, our results clearly establish that the ancestral KCS6/5 gene duplicated in the Brassicaceae lineage. It is possible that any specialized functions of KCS5 found in Brassicaceae are either part of a set of KCS6/5 gene functions in the rest of the flowering plants, or unique to Brassicaceae."
}
@article{BOROWKA20132552,
title = "Massive non-planar two-loop four-point integrals with SecDec 2.1",
journal = "Computer Physics Communications",
volume = "184",
number = "11",
pages = "2552 - 2561",
year = "2013",
issn = "0010-4655",
doi = "https://doi.org/10.1016/j.cpc.2013.05.022",
url = "http://www.sciencedirect.com/science/article/pii/S0010465513001926",
author = "Sophia Borowka and Gudrun Heinrich",
keywords = "Perturbation theory, Feynman diagrams, Multi-loop, Numerical integration, Top quark pair production",
abstract = "We present numerical results for massive non-planar two-loop box integrals entering heavy quark pair production at NNLO, some of which are not known analytically yet. The results have been obtained with the program SecDec 2.1, based on sector decomposition and contour deformation, in combination with new types of transformations. Among the new features of version 2.1 is also the possibility to evaluate contracted tensor integrals, with no limitation on the rank.
Program Summary
Program title: SecDec 2.1 Catalogue identifier: AEIR_v2_1 Program summary URL:http://cpc.cs.qub.ac.uk/summaries/AEIR_v2_1.html Program obtainable from: CPC Program Library, Queen’s University, Belfast, N. Ireland Licensing provisions: Standard CPC licence, http://cpc.cs.qub.ac.uk/licence/licence.html No. of lines in distributed program, including test data, etc.: 127558 No. of bytes in distributed program, including test data, etc.: 2506220 Distribution format: tar.gz Programming language: Wolfram Mathematica, Perl, Fortran/C++. Computer: From a single PC to a cluster, depending on the problem. Operating system: Unix, Linux. RAM: Depends on the complexity of the problem Classification: 4.4, 5, 11.1. Catalogue identifier of previous version: AEIR_v2_0 Journal reference of previous version: Comput. Phys. Comm. 184 (2013) 396 External routines: BASES [1], CUBA [2]. The codes for both are included in the SecDec 2.1 distribution file. Does the new version supersede the previous version?: Yes Nature of problem: Extraction of ultraviolet and infrared singularities from parametric integrals appearing in higher order perturbative calculations in gauge theories. Numerical integration in the presence of integrable singularities (e.g. kinematic thresholds in massive multi-loop integrals). Flexibility to treat non-standard user defined functions. Solution method: Algebraic extraction of singularities in dimensional regularisation using iterated sector decomposition. This leads to a Laurent series in the dimensional regularisation parameter ε, where the coefficients are finite integrals over the unit-hypercube. Those integrals are evaluated numerically by Monte Carlo integration. The integrable singularities are handled by choosing a suitable integration contour in the complex plane, in an automated way. Reasons for new version: Several improvements and new features. Summary of revisions: Extended tensor integral option, flexibility to evaluate non-standard loop integral functions and to skip primary decomposition step, improvements in the user interface and the error treatment. Restrictions: Depending on the complexity of the problem, limited by CPU time or memory. Running time: Between a few minutes and several days, depending on the complexity of the problem. References:[1]S. Kawabata, A New version of the multidimensional integration and event generation package BASES/SPRING, Comput. Phys. Comm. 88 (1995) 309.[2]T. Hahn, CUBA: A Library for multidimensional numerical integration, Comput. Phys. Comm. 168 (2005) 78."
}
@article{SIDEK201788,
title = "Perceived critical success factors of electronic health record system implementation in a dental clinic context: An organisational management perspective",
journal = "International Journal of Medical Informatics",
volume = "107",
pages = "88 - 100",
year = "2017",
issn = "1386-5056",
doi = "https://doi.org/10.1016/j.ijmedinf.2017.08.007",
url = "http://www.sciencedirect.com/science/article/pii/S1386505617302204",
author = "Yusof Haji Sidek and Jorge Tiago Martins",
keywords = "Electronic health record system, Health information system, Health information technology, Dental clinic, Organizational management, Grounded theory",
abstract = "Background
Electronic health records (EHR) make health care more efficient. They improve the quality of care by making patients’ medical history more accessible. However, little is known about the factors contributing to the successful EHR implementation in dental clinics.
Objectives
This article aims to identify the perceived critical success factors of EHR system implementation in a dental clinic context.
Methods
We used Grounded Theory to analyse data collected in the context of Brunei’s national EHR − the Healthcare Information and Management System (Bru-HIMS). Data analysis followed the stages of open, axial and selective coding.
Results
Six perceived critical success factors emerged: usability of the system, emergent behaviours, requirements analysis, training, change management, and project organisation. The study identified a mismatch between end-users and product owner/vendor perspectives.
Discussion
Workflow changes were significant challenges to clinicians’ confident use, particularly as the system offered limited modularity and configurability. Recommendations are made for all the parties involved in healthcare information systems implementation to manage the change process by agreeing system goals and functionalities through wider consensual debate, and participated supporting strategies realised through common commitment."
}
@article{LIU2015871,
title = "Genomic, Transcriptomic, and Phenomic Variation Reveals the Complex Adaptation of Modern Maize Breeding",
journal = "Molecular Plant",
volume = "8",
number = "6",
pages = "871 - 884",
year = "2015",
issn = "1674-2052",
doi = "https://doi.org/10.1016/j.molp.2015.01.016",
url = "http://www.sciencedirect.com/science/article/pii/S1674205215001033",
author = "Haijun Liu and Xiaqing Wang and Marilyn L. Warburton and Weiwei Wen and Minliang Jin and Min Deng and Jie Liu and Hao Tong and Qingchun Pan and Xiaohong Yang and Jianbing Yan",
keywords = "temperate adaptation, positive selection, regulatory evolution, ",
abstract = "The temperate-tropical division of early maize germplasms to different agricultural environments was arguably the greatest adaptation process associated with the success and near ubiquitous importance of global maize production. Deciphering this history is challenging, but new insight has been gained from examining 558 529 single nucleotide polymorphisms, expression data of 28 769 genes, and 662 traits collected from 368 diverse temperate and tropical maize inbred lines in this study. This is a new attempt to systematically exploit the mechanisms of the adaptation process in maize. Our results indicate that divergence between tropical and temperate lines apparently occurred 3400–6700 years ago. Seven hundred and one genomic selection signals and transcriptomic variants including 2700 differentially expressed individual genes and 389 rewired co-expression network genes were identified. These candidate signals were found to be functionally related to stress responses, and most were associated with directionally selected traits, which may have been an advantage under widely varying environmental conditions faced by maize as it was migrated away from its domestication center. Our study also clearly indicates that such stress adaptation could involve evolution of protein-coding sequences as well as transcriptome-level regulatory changes. The latter process may be a more flexible and dynamic way for maize to adapt to environmental changes along its short evolutionary history."
}
@article{LICHTENBERG2016350,
title = "The effects of short-lived radionuclides and porosity on the early thermo-mechanical evolution of planetesimals",
journal = "Icarus",
volume = "274",
pages = "350 - 365",
year = "2016",
issn = "0019-1035",
doi = "https://doi.org/10.1016/j.icarus.2016.03.004",
url = "http://www.sciencedirect.com/science/article/pii/S001910351600138X",
author = "Tim Lichtenberg and Gregor J. Golabek and Taras V. Gerya and Michael R. Meyer",
keywords = "Planetary formation, Terrestrial planets, Planetesimals, Interiors, Thermal histories",
abstract = "The thermal history and internal structure of chondritic planetesimals, assembled before the giant impact phase of chaotic growth, potentially yield important implications for the final composition and evolution of terrestrial planets. These parameters critically depend on the internal balance of heating versus cooling, which is mostly determined by the presence of short-lived radionuclides (SLRs), such as 26Al and 60Fe, as well as the heat conductivity of the material. The heating by SLRs depends on their initial abundances, the formation time of the planetesimal and its size. It has been argued that the cooling history is determined by the porosity of the granular material, which undergoes dramatic changes via compaction processes and tends to decrease with time. In this study we assess the influence of these parameters on the thermo-mechanical evolution of young planetesimals with both 2D and 3D simulations. Using the code family i2elvis/i3elvis we have run numerous 2D and 3D numerical finite-difference fluid dynamic models with varying planetesimal radius, formation time and initial porosity. Our results indicate that powdery materials lowered the threshold for melting and convection in planetesimals, depending on the amount of SLRs present. A subset of planetesimals retained a powdery surface layer which lowered the thermal conductivity and hindered cooling. The effect of initial porosity was small, however, compared to those of planetesimal size and formation time, which dominated the thermo-mechanical evolution and were the primary factors for the onset of melting and differentiation. We comment on the implications of this work concerning the structure and evolution of these planetesimals, as well as their behavior as possible building blocks of terrestrial planets."
}
@article{LUIS2013406,
title = "Real Object Mapping Technologies Applied to Marine Engineering Learning Process within a CBL Methodology",
journal = "Procedia Computer Science",
volume = "25",
pages = "406 - 410",
year = "2013",
note = "2013 International Conference on Virtual and Augmented Reality in Education",
issn = "1877-0509",
doi = "https://doi.org/10.1016/j.procs.2013.11.051",
url = "http://www.sciencedirect.com/science/article/pii/S1877050913012568",
author = "Carlos Efrén Mora Luis and Antonio Manuel González Marrero",
keywords = "Augmented Reality in education, Challenge Based Learning, Real objects mapping, Marine Engineering training",
abstract = "A proper operation and maintenance of marine systems require give specific instructions and descriptions focused on the parts of any device. This is usually taught by the use of texts and figure descriptions, but the learning process is not as immersive as reality itself. Augmented reality over real objects with mobile devices can change this learning process into a more immersive and engaging experience for the students. This technology permits the use of instructional information like texts, videos and 3D virtual objects even with animations over real elements. This powerful tool lets the student recognize any drawings and real objects in one step, and also any specific operating and/or maintenance instructions can be given. For creating these augmented reality experiences we pretend to use metaio Creator combined with metaio Toolbox. Metaio GmbH firstly released this free app on October 2012 in the Apple App Store. It lets capturing a real object (mapping) in order to easily create augmented realty experiences using real objects as references. On a first instance, we pretend to map objects like valves, pumps and other piping elements, so small groups of students will be able to observe and study this objects through their own mobile devices using a QR code for object recognition. The understanding of every object by every group of students becomes their challenge. First every group will have to discuss every relevant aspect they have discovered: working principles, operating and maintenance. Secondly they should discuss their results with other team members. Finally they will explain what they have learned to their instructor using the same AR technology."
}
@article{PINTO201559,
title = "A large-scale study on the usage of Java’s concurrent programming constructs",
journal = "Journal of Systems and Software",
volume = "106",
pages = "59 - 81",
year = "2015",
issn = "0164-1212",
doi = "https://doi.org/10.1016/j.jss.2015.04.064",
url = "http://www.sciencedirect.com/science/article/pii/S0164121215000849",
author = "Gustavo Pinto and Weslley Torres and Benito Fernandes and Fernando Castor and Roberto S.M. Barros",
keywords = "Java, Concurrency, Software evolution",
abstract = "In both academia and industry, there is a strong belief that multicore technology will radically change the way software is built. However, little is known about the current state of use of concurrent programming constructs. In this work we present an empirical work aimed at studying the usage of concurrent programming constructs of 2227 real world, stable and mature Java projects from SourceForge. We have studied the usage of concurrent techniques in the most recent versions of these applications and also how usage has evolved along time. The main findings of our study are: (I) More than 75% of the latest versions of the projects either explicitly create threads or employ some concurrency control mechanism. (II) More than half of these projects exhibit at least 47 synchronized methods and 3 implementations of the Runnable interface per 100,000 LoC, which means that not only concurrent programming constructs are used often but they are also employed intensively. (III) The adoption of the java.util.concurrent library is only moderate (approximately 23% of the concurrent projects employ it). (IV) Efficient and thread-safe data structures, such as ConcurrentHashMap, are not yet widely used, despite the fact that they present numerous advantages."
}
@article{KHERADPISHEH2016382,
title = "Bio-inspired unsupervised learning of visual features leads to robust invariant object recognition",
journal = "Neurocomputing",
volume = "205",
pages = "382 - 392",
year = "2016",
issn = "0925-2312",
doi = "https://doi.org/10.1016/j.neucom.2016.04.029",
url = "http://www.sciencedirect.com/science/article/pii/S0925231216302880",
author = "Saeed Reza Kheradpisheh and Mohammad Ganjtabesh and Timothée Masquelier",
keywords = "View-Invariant object recognition, Visual cortex, STDP, Spiking neurons, Temporal coding",
abstract = "Retinal image of surrounding objects varies tremendously due to the changes in position, size, pose, illumination condition, background context, occlusion, noise, and non-rigid deformations. But despite these huge variations, our visual system is able to invariantly recognize any object in just a fraction of a second. To date, various computational models have been proposed to mimic the hierarchical processing of the ventral visual pathway, with limited success. Here, we show that the association of both biologically inspired network architecture and learning rule significantly improves the models׳ performance when facing challenging invariant object recognition problems. Our model is an asynchronous feedforward spiking neural network. When the network is presented with natural images, the neurons in the entry layers detect edges, and the most activated ones fire first, while neurons in higher layers are equipped with spike timing-dependent plasticity. These neurons progressively become selective to intermediate complexity visual features appropriate for object categorization. The model is evaluated on 3D-Object and ETH-80 datasets which are two benchmarks for invariant object recognition, and is shown to outperform state-of-the-art models, including DeepConvNet and HMAX. This demonstrates its ability to accurately recognize different instances of multiple object classes even under various appearance conditions (different views, scales, tilts, and backgrounds). Several statistical analysis techniques are used to show that our model extracts class specific and highly informative features."
}
@article{AMBROSE20161124,
title = "Reverse Replay of Hippocampal Place Cells Is Uniquely Modulated by Changing Reward",
journal = "Neuron",
volume = "91",
number = "5",
pages = "1124 - 1136",
year = "2016",
issn = "0896-6273",
doi = "https://doi.org/10.1016/j.neuron.2016.07.047",
url = "http://www.sciencedirect.com/science/article/pii/S0896627316304639",
author = "R. Ellen Ambrose and Brad E. Pfeiffer and David J. Foster",
abstract = "Summary
Hippocampal replays are episodes of sequential place cell activity during sharp-wave ripple oscillations (SWRs). Conflicting hypotheses implicate awake replay in learning from reward and in memory retrieval for decision making. Further, awake replays can be forward, in the same order as experienced, or reverse, in the opposite order. However, while the presence or absence of reward has been reported to modulate SWR rate, the effect of reward changes on replay, and on replay direction in particular, has not been examined. Here we report divergence in the response of forward and reverse replays to changing reward. While both classes of replays were observed at reward locations, only reverse replays increased their rate at increased reward or decreased their rate at decreased reward, while forward replays were unchanged. These data demonstrate a unique relationship between reverse replay and reward processing and point to a functional distinction between different directions of replay.
Video Abstract
"
}
@article{SLAVOVA2017120,
title = "Heroin and fentanyl overdoses in Kentucky: Epidemiology and surveillance",
journal = "International Journal of Drug Policy",
volume = "46",
pages = "120 - 129",
year = "2017",
issn = "0955-3959",
doi = "https://doi.org/10.1016/j.drugpo.2017.05.051",
url = "http://www.sciencedirect.com/science/article/pii/S095539591730155X",
author = "Svetla Slavova and Julia F. Costich and Terry L. Bunn and Huong Luu and Michael Singleton and Sarah L. Hargrove and Jeremy S. Triplett and Dana Quesinberry and William Ralston and Van Ingram",
keywords = "Heroin, Fentanyl, Overdose, Surveillance",
abstract = "Background
The study aims to describe recent changes in Kentucky's drug overdose trends related to increased heroin and fentanyl involvement, and to discuss future directions for improved drug overdose surveillance.
Methods
The study used multiple data sources (death certificates, postmortem toxicology results, emergency department [ED] records, law enforcement drug submissions, and prescription drug monitoring records) to describe temporal, geographic, and demographic changes in drug overdoses in Kentucky.
Results
Fentanyl- and heroin-related overdose death rates increased across all age groups from years 2011 to 2015 with the highest rates consistently among 25–34-year-olds. The majority of the heroin and fentanyl overdose decedents had histories of substantial exposures to legally acquired prescription opioids. Law enforcement drug submission data were strongly correlated with drug overdose ED and mortality data. The 2016 crude rate of heroin-related overdose ED visits was 104/100,000, a 68% increase from 2015 (62/100,000). More fentanyl-related overdose deaths were reported between October, 2015, and September, 2016, than ED visits, in striking contrast with the observed ratio of >10 to 1 heroin-related overdose ED visits to deaths. Many fatal fentanyl overdoses were associated with heroin adulterated with fentanyl; <40% of the heroin overdose ED discharge records listed procedure codes for drug screening.
Conclusions
The lack of routine ED drug testing likely resulted in underreporting of non-fatal overdoses involving fentanyl and other synthetic drugs. In order to inform coordinated public health and safety responses, drug overdose surveillance must move from a reactive to a proactive mode, utilizing the infrastructure for electronic health records."
}
@article{YANG201862,
title = "A critical examination of the relationship among research, theory, and practice: Technology and reading instruction",
journal = "Computers & Education",
volume = "125",
pages = "62 - 73",
year = "2018",
issn = "0360-1315",
doi = "https://doi.org/10.1016/j.compedu.2018.03.009",
url = "http://www.sciencedirect.com/science/article/pii/S0360131518300629",
author = "Xinyuan Yang and Li-Jen Kuo and Xuejun Ji and Erin McTigue",
keywords = "Technology, Reading instruction, Digital literacy, Theory and practice, Systematic review",
abstract = "Recent technological advancements have changed how literacy is perceived, and it is no longer confined to the interaction with print text. The evolving definition of literacy has been reflected in the increasing number of teachers who are incorporating technology into their reading instruction. However, less is known about the extent to which these technology-integrated instructional practices are supported by reading theories. The purpose of this study is to systematically review how technology has been implemented in reading instruction and to explore how transitions of instructional practice from traditional classrooms to digital settings have been grounded in reading theories. The present study reviewed articles published over the past twelve years in flagship practitioner journals to examine the connections and the gaps between theory and practice. Our review uncovered that technology has served in reading instruction primarily in three ways: 1) to increase reading motivation, 2) to present information in multi-modalities, and 3) to promote collaborative learning. Consistent with other domains of reading instruction, social theories were found to be the prominent theoretical bases supporting technology-integrated practices; dual-coding theory has also emerged in recent years as the theoretical basis for technology use in reading instruction. However, most of the theories were rarely referred explicitly. Implications for researchers and practitioners were provided based on the gaps between theory and practice revealed in the current review."
}
@article{ZANCHETTA2013757,
title = "An international internship on social development led by Canadian nursing students: Empowering learning",
journal = "Nurse Education Today",
volume = "33",
number = "7",
pages = "757 - 764",
year = "2013",
note = "Special Issue: NETNEP2012",
issn = "0260-6917",
doi = "https://doi.org/10.1016/j.nedt.2013.04.019",
url = "http://www.sciencedirect.com/science/article/pii/S0260691713001561",
author = "Margareth Zanchetta and Jasna Schwind and Kateryna Aksenchuk and Franklin F. Gorospe, and Lira Santiago",
keywords = "Social development, International internship, Undergraduate nursing students, Canada, Brazil",
abstract = "Summary
Background
A Canadian nursing student-led knowledge dissemination project on health promotion for social development was implemented with local professionals and communities in Brazil.
Objectives
(a) to identify how student-interns contrasted Canadian and Brazilian cultural and social realities within a primary healthcare context from a social development perspective; (b) to examine how philosophical underpinnings, including social critical theory and notions of social justice, guided student-interns in acknowledging inequalities in primary healthcare in Brazil; and (c) to participate in the debate on the contribution of Canadian nursing students to the global movement for social development.
Design and Setting
A qualitative appraisal of short-term outcomes of an international internship in the cities of Birigui & Araçatuba (São Paulo-Brazil).
Participants
Four Canadian fourth-year undergraduate nursing students enrolled in a metropolitan university program.
Methods
Recruitment was through an email invitation to the student-interns, who accepted, and signed informed consent forms. Their participation was unpaid and voluntary. One-time individual interviews were conducted at the end of their internships. Transcriptions of the audio-recorded interviews were coded using the qualitative software program ATLAS ti 6.0. The findings were analyzed using thematic analysis.
Results
Student-interns' learning unfolded from making associations among concepts, new ideas, and their previous experiences, leading to a personal transformation through which they established new conceptual and personal connections. The two main themes revealed by the thematic analysis were dichotomizing realities, that is, acknowledging the existence of “two sides of each situation,” and discovering an unexpected reciprocity between global and urban health. Furthermore, the student-interns achieved personal and professional empowerment.
Conclusions
The knowledge gained from the international experience helped the student-interns learn how to collaborate with Brazilian society's sectors to improve the social conditions of a “marginalized population”. Student-interns became aware of their inner power to promote change by making invisible inequity visible in their own terms."
}
@article{GANTE201797,
title = "Hysterectomies in Portugal (2000–2014): What has changed?",
journal = "European Journal of Obstetrics & Gynecology and Reproductive Biology",
volume = "208",
pages = "97 - 102",
year = "2017",
issn = "0301-2115",
doi = "https://doi.org/10.1016/j.ejogrb.2016.11.021",
url = "http://www.sciencedirect.com/science/article/pii/S0301211516310338",
author = "Inês Gante and Cláudia Medeiros-Borges and Fernanda Águas",
keywords = "Hysterectomy, Portugal, Leiomyoma, Salpingectomy, Adnexectomy",
abstract = "Objective
To describe conditions regarding hysterectomies during the past 15 years in Portugal.
Study design
Nationwide retrospective study of women who underwent hysterectomy in Portuguese public hospitals in the period between 2000 and 2014. Patient data regarding hospital codes, geography, patient age, indications, operative techniques, associated procedures, complications, admission dates, discharge dates and 30-day postoperative readmissions were extracted from the national database with information regarding all public hospitals in Portugal. For calculation of hysterectomy rates, the total number of women was found using the Statistics Portugal website. Data were analysed using STATA version 13.1.
Results
A total of 166 177 hysterectomies were performed between 2000 and 2014 in public hospitals in Portugal. The overall rate of hysterectomy decreased 19.3% (from 212/100 000 to 171/100 000 women per year). The average age of women at time of hysterectomy increased from 51.6±11.4 to 55.2±12.3years (p<0.001). There was an increase in laparoscopic [1.2%–9.5%, p<0.001] and vaginal route [13.3%–21.2%, p<0.001], with a consequent decrease in laparotomic route [85.5%–69.1%, p<0.001]. There was a change in the pattern of indications for hysterectomy; however, uterine fibroids remain the major indication for hysterectomy [45.3%–37.6%, p<0.001]. In women with hysterectomy for benign pathology, the rate of bilateral adnexectomy decreased from 71.0% to 51.9% (p<0.001) and the rate of bilateral salpingectomy increased from 1.0% to 15.1% (p<0.001). The mean number of hospitalization days decreased from 7.1±6.1 (in 2000–2004) to 5.4±5.0 (in 2010–2014) (p<0.001). Globally, the rate of complications increased from 3.3% in 2000–2004 to 3.6% in 2010–2014 (p<0.01).
Conclusion
In Portugal, the rate of hysterectomies decreased in the last 15 years with an increase in age at the time of the procedure and a change towards less invasive routes. Uterine fibroids remain the major indication for hysterectomy. Additionally, we noted a significant shift towards more concomitant bilateral salpingectomy (and less bilateral adnexectomy) during hysterectomy for benign indications, according to the evidence suggesting the fallopian tube as the origin of ovarian cancer."
}
@article{RAMIREZCOBO201371,
title = "A 2D wavelet-based multiscale approach with applications to the analysis of digital mammograms",
journal = "Computational Statistics & Data Analysis",
volume = "58",
pages = "71 - 81",
year = "2013",
note = "The Third Special Issue on Statistical Signal Extraction and Filtering",
issn = "0167-9473",
doi = "https://doi.org/10.1016/j.csda.2011.09.009",
url = "http://www.sciencedirect.com/science/article/pii/S0167947311003288",
author = "Pepa Ramírez-Cobo and Brani Vidakovic",
keywords = "Breast cancer diagnostic, Image multifractal analysis, Wavelet transform",
abstract = "A wavelet-based multifractal spectrum (MFS) for the analysis of images that possess an erratically changing oscillatory behavior at various scales is constructed and estimated. The methodology is applied to the analysis of mammograms. The key contribution is that the analysis is not focused on microcalcifications, but on the background of the image, thus presenting a new modality to be combined with other diagnostic tools. Differences in image backgrounds between malignant and normal cases are found, in terms of multifractal descriptors. The new tool is compared with another spectral method, based on monofractal descriptors.11All codes utilized in this work are available as a supplementary material with the electronic version of the paper."
}
@article{HSU2015489,
title = "Evident cognitive impairments in seemingly recovered patients after midazolam-based light sedation during diagnostic endoscopy",
journal = "Journal of the Formosan Medical Association",
volume = "114",
number = "6",
pages = "489 - 497",
year = "2015",
issn = "0929-6646",
doi = "https://doi.org/10.1016/j.jfma.2013.07.018",
url = "http://www.sciencedirect.com/science/article/pii/S0929664613002659",
author = "Yen-Hsuan Hsu and Feng-Sheng Lin and Chi-Cheng Yang and Chih-Peng Lin and Mau-Sun Hua and Wei-Zen Sun",
keywords = "cognitive function, endoscopy, midazolam, reliable change index",
abstract = "Background/Purpose
Midazolam is a widely used sedative agent during colonoscopy, with cognitive toxicity. However, the potential cognitive hazard of midazolam-based light sedation has not been sufficiently examined. We aimed to examine the cognitive safety and vulnerability profile under midazolam light sedation, with a particular focus on individual variations.
Methods
We conducted a prospective case-controlled study in an academic hospital. In total, 30 patients undergoing sedative colonoscopy as part of a health check-up were recruited. Neuropsychological testing on the full cognitive spectrum was evaluated at 15 minutes and 120 minutes after low-dose midazolam administration. The modified reliable change index (RCI) was used for intrapersonal comparisons and controlling for practice effects.
Results
Midazolam affected psychomotor speed (48%), memory (40%), learning (32%), working memory (17%), and sustained attention (11%), while sparing orientation and the fluency aspect of executive function at the acute stage. Residual memory (10%) and learning (10%) impairments at 2 hours after administration were evidenced in some patients. The three object recall and digit symbol coding tests can serve as useful screening tools.
Conclusion
Midazolam-based light sedation induced selective cognitive impairments and prolonged cognitive impairments occurred in patients with advanced age. A longer observation time and further screening were recommended for patients due to their at risk state."
}
@article{MORI2013875,
title = "Assessing possible shifts in wildfire regimes under a changing climate in mountainous landscapes",
journal = "Forest Ecology and Management",
volume = "310",
pages = "875 - 886",
year = "2013",
issn = "0378-1127",
doi = "https://doi.org/10.1016/j.foreco.2013.09.036",
url = "http://www.sciencedirect.com/science/article/pii/S0378112713006506",
author = "Akira S. Mori and Edward A. Johnson",
keywords = "Ecosystem-based management, Extreme drought, Future climate and fire scenarios, Natural disturbance, Wildfire",
abstract = "Climate change may affect the probability of extreme events such as wildfires. Although wildfires are some of the most important ecological processes in forest ecosystems, large-scale wildfires are often perceived as an environmental disaster. Since failure to include the dynamic nature of ecosystems in planning will inevitably lead to unexpected outcomes, we need to enhance our ability to cope with future extreme events coupled with climate change. This study presents several future scenarios in three different time periods for Canada’s Columbia Montane Cordillera Ecoprovince, which is prone to wildfires. These scenarios predict the probability of occurrence of widespread wildfires based on the hierarchical Bayesian model. The model was based on the relationships between wildfires and the Monthly Drought Code (MDC). The MDC is a generalized monthly version of the Daily Drought Code widely used across Canada by forest fire management agencies for monitoring of wildfire risk. To calculate future MDC values, we relied on different possible future conditions of climate, given by the Global Circulation Models. We found a regime shift in drought intensity with abrupt decreases in lightning-caused wildfire activity around 1940, suggesting that future wildfire risks can be inferred primarily from the summer drought code. For future periods, we found increasing trends in the probabilities of large-scale fires with time in most areas. It should be notable that, by the 2080s, there is a probability of some areas having more than 50% of large-scale wildfires under the “average” climatic conditions in the future, indicating that, even without “extreme” weather conditions, some ecosystems will have a fundamental probability of experiencing catastrophic fires under the condition of average summer. However, the rate of progression toward a fire-prone condition is quite different among the three climate change scenarios and among the region analyzed. Given such scenario-sensitive, spatially-heterogeneous patterns of wildfire probability in response to climate variability, management strategy should be flexible and more localized. By drawing on this knowledge, it may be possible to mitigate climate change impacts both before they arise and once they have occurred. These considerations are critical for maintaining the integrity of systems shaped by large-scale natural disturbances to increase their resilience to the changing climate while protecting human society and infrastructures. Working with alternative scenarios will facilitate our adaptation to climate change in managing fire-prone forest ecosystems."
}
@article{GILBERT2013399,
title = "Cladistic analysis of extant and fossil African papionins using craniodental data",
journal = "Journal of Human Evolution",
volume = "64",
number = "5",
pages = "399 - 433",
year = "2013",
issn = "0047-2484",
doi = "https://doi.org/10.1016/j.jhevol.2013.01.013",
url = "http://www.sciencedirect.com/science/article/pii/S0047248413000316",
author = "Christopher C. Gilbert",
keywords = "Allometry, Phylogeny, General allometric coding method, , , , , , , Papionin evolution",
abstract = "This study examines African papionin phylogenetic history through a comprehensive cladistic analysis of extant and fossil craniodental morphology using both quantitative and qualitative characters. To account for the well-documented influence of allometry on the papionin skull, the general allometric coding method was applied to characters determined to be significantly affected by allometry. Results of the analyses suggest that Parapapio, Pliopapio, and Papio izodi are stem African papionin taxa. Crown Plio-Pleistocene African papionin taxa include Gorgopithecus, Lophocebus cf. albigena, Procercocebus, Soromandrillus (new genus defined herein) quadratirostris, and, most likely, Dinopithecus. Furthermore, S. quadratirostris is a member of a clade also containing Mandrillus, Cercocebus, and Procercocebus; ?Theropithecus baringensis is strongly supported as a primitive member of the genus Theropithecus; Gorgopithecus is closely related to Papio and Lophocebus; and Theropithecus is possibly the most primitive crown African papionin taxon. Finally, character transformation analyses identify a series of morphological transformations during the course of papionin evolution. The origin of crown African papionins is diagnosed, at least in part, by the appearance of definitive and well-developed male maxillary ridges and maxillary fossae. Among crown African papionins, Papio, Lophocebus, and Gorgopithecus are further united by the most extensive development of the maxillary fossae. The Soromandrillus/Mandrillus/Cercocebus/Procercocebus clade is diagnosed by upturned nuchal crests (especially in males), widely divergent temporal lines (especially in males), medially oriented maxillary ridges in males, medially oriented inferior petrous processes, and a tendency to enlarge the premolars as an adaptation for hard-object food processing. The adaptive origins of the genus Theropithecus appear associated with a diet requiring an increase in size of the temporalis, the optimal placement of occlusal forces onto the molar battery, and an increase in the life of the posterior dentition. This shift is associated with the evolution of distinctive morphological features such as the anterior union of the temporal lines, increased enamel infoldings on the premolars and molars, a reversed curve of Spee, and delayed molar eruption."
}
@article{ROWE2015121,
title = "GalSim: The modular galaxy image simulation toolkit",
journal = "Astronomy and Computing",
volume = "10",
pages = "121 - 150",
year = "2015",
issn = "2213-1337",
doi = "https://doi.org/10.1016/j.ascom.2015.02.002",
url = "http://www.sciencedirect.com/science/article/pii/S221313371500013X",
author = "B.T.P. Rowe and M. Jarvis and R. Mandelbaum and G.M. Bernstein and J. Bosch and M. Simet and J.E. Meyers and T. Kacprzak and R. Nakajima and J. Zuntz and H. Miyatake and J.P. Dietrich and R. Armstrong and P. Melchior and M.S.S. Gill",
keywords = "Methods: data analysis, Techniques: image processing, Gravitational lensing, Cosmology: observations",
abstract = "GalSim is a collaborative, open-source project aimed at providing an image simulation tool of enduring benefit to the astronomical community. It provides a software library for generating images of astronomical objects such as stars and galaxies in a variety of ways, efficiently handling image transformations and operations such as convolution and rendering at high precision. We describe the GalSim software and its capabilities, including necessary theoretical background. We demonstrate that the performance of GalSim meets the stringent requirements of high precision image analysis applications such as weak gravitational lensing, for current datasets and for the Stage IV dark energy surveys of the Large Synoptic Survey Telescope, ESA’s Euclid mission, and NASA’s WFIRST-AFTA mission. The GalSim project repository is public and includes the full code history, all open and closed issues, installation instructions, documentation, and wiki pages (including a Frequently Asked Questions section). The GalSim repository can be found at https://github.com/GalSim-developers/GalSim."
}
@article{LUDWIG2012S164,
title = "REAS3: A revised implementation of the geosynchrotron model for radio emission from air showers",
journal = "Nuclear Instruments and Methods in Physics Research Section A: Accelerators, Spectrometers, Detectors and Associated Equipment",
volume = "662",
pages = "S164 - S167",
year = "2012",
note = "4th International workshop on Acoustic and Radio EeV Neutrino detection Activities",
issn = "0168-9002",
doi = "https://doi.org/10.1016/j.nima.2010.10.115",
url = "http://www.sciencedirect.com/science/article/pii/S0168900210024009",
author = "M. Ludwig and T. Huege",
keywords = "Radio emission, Extensive air showers, Modelling and simulation, Endpoint contribution, Geosynchrotron model",
abstract = "Over the past years, the freely available Monte Carlo-code REAS which simulates radio emission from air showers based on the geosynchrotron model, was used regularly for comparisons with data. However, it emerged that in the previous version of the code, emission due to the variation of the number of charged particles within an air shower was not taken into account. In the following article, we show the implementation of these emission contributions in REAS3 by the inclusion of “end-point contributions” and discuss the changes on the predictions of REAS obtained by this revision. The basis for describing radiation processes is an universal description which is gained by the use of the end-point formulation. Hence, not only pure geomagnetic radiation is simulated with REAS3 but also radiation due to the variation of the net charge excess in the air shower, independent of the Earth's magnetic field. Furthermore, we present a comparison of lateral distributions of LOPES data with REAS3-simulated distributions. The comparison shows a good agreement between both, data and REAS3 simulations."
}
@article{FABRE2013129,
title = "Prediction of microgeometrical influences on micropitting fatigue damage on 32CrMoV13 steel",
journal = "Tribology International",
volume = "59",
pages = "129 - 140",
year = "2013",
note = "ENERGY AND HEALTH",
issn = "0301-679X",
doi = "https://doi.org/10.1016/j.triboint.2012.07.018",
url = "http://www.sciencedirect.com/science/article/pii/S0301679X12002654",
author = "A. Fabre and H.P. Evans and L. Barrallier and K.J. Sharif and M. Desvignes",
keywords = "Micropitting, Fatigue damage, Microgeometry, Gear",
abstract = "Micropitting is a form of surface fatigue damage that occurs in the gear teeth. It is due to the effect of variation in the mechanical loading in the contact zone between the two teeth, induced especially by flank roughness. In this study, generic roughness profiles were built with geometrical parameters to simulate the contact between two rough surfaces. Using elastohydrodynamic lubrication code and Crossland's fatigue criteria, the influence on fatigue lifetime was analysed for changes in each parameter. The relevant parameters were determined that influence (i) the conventional pitting, (ii) the extent to which the von Mises equivalent stress exceeds the material yield stress in the zone where micropitting occurs, and (iii) the fatigue lifetime for steel teeth. With nitriding benefits, the same trends were shown with weaker effects."
}
@article{CORNWELL2017447,
title = "The Unpredictive Brain Under Threat: A Neurocomputational Account of Anxious Hypervigilance",
journal = "Biological Psychiatry",
volume = "82",
number = "6",
pages = "447 - 454",
year = "2017",
note = "Computational Psychiatry",
issn = "0006-3223",
doi = "https://doi.org/10.1016/j.biopsych.2017.06.031",
url = "http://www.sciencedirect.com/science/article/pii/S0006322317317602",
author = "Brian R. Cornwell and Marta I. Garrido and Cassie Overstreet and Daniel S. Pine and Christian Grillon",
keywords = "Anxiety, Dynamic causal modeling, GABA, Hypervigilance, Magnetoencephalography, Mismatch negativity",
abstract = "Background
Anxious hypervigilance is marked by sensitized sensory-perceptual processes and attentional biases to potential danger cues in the environment. How this is realized at the neurocomputational level is unknown but could clarify the brain mechanisms disrupted in psychiatric conditions such as posttraumatic stress disorder. Predictive coding, instantiated by dynamic causal models, provides a promising framework to ground these state-related changes in the dynamic interactions of reciprocally connected brain areas.
Methods
Anxiety states were elicited in healthy participants (n = 19) by exposure to the threat of unpredictable, aversive shocks while undergoing magnetoencephalography. An auditory oddball sequence was presented to measure cortical responses related to deviance detection, and dynamic causal models quantified deviance-related changes in effective connectivity. Participants were also administered alprazolam (double-blinded, placebo-controlled crossover) to determine whether the cortical effects of threat-induced anxiety are reversed by acute anxiolytic treatment.
Results
Deviant tones elicited increased auditory cortical responses under threat. Bayesian analyses revealed that hypervigilant responding was best explained by increased postsynaptic gain in primary auditory cortex activity as well as modulation of feedforward, but not feedback, coupling within a temporofrontal cortical network. Increasing inhibitory gamma-aminobutyric acidergic action with alprazolam reduced anxiety and restored feedback modulation within the network.
Conclusions
Threat-induced anxiety produced unbalanced feedforward signaling in response to deviations in predicable sensory input. Amplifying ascending sensory prediction error signals may optimize stimulus detection in the face of impending threats. At the same time, diminished descending sensory prediction signals impede perceptual learning and may, therefore, underpin some of the deleterious effects of anxiety on higher-order cognition."
}
@article{GANDIA201458,
title = "The myosin motor domain-containing chitin synthase PdChsVII is required for development, cell wall integrity and virulence in the citrus postharvest pathogen Penicillium digitatum",
journal = "Fungal Genetics and Biology",
volume = "67",
pages = "58 - 70",
year = "2014",
issn = "1087-1845",
doi = "https://doi.org/10.1016/j.fgb.2014.04.002",
url = "http://www.sciencedirect.com/science/article/pii/S1087184514000565",
author = "Mónica Gandía and Eleonora Harries and Jose F. Marcos",
keywords = "Chitin synthase, Cell wall, , Postharvest pathology, Citrus",
abstract = "Chitin is an essential component of the fungal cell wall and a potential target in the development of new antifungal compounds, due to its presence in fungi and not in plants or vertebrates. Chitin synthase genes (chs) constitute a complex family in filamentous fungi and are involved in fungal development, morphogenesis, pathogenesis and virulence. In this study, additional chs genes in the citrus postharvest pathogen Penicillium digitatum have been identified. Comparative analyses included each PdChs in each one of the classes I to VII previously established, and support the grouping of these into three divisions. Disruption of the gene coding PdChsVII, which contains a short version of a myosin motor domain, has been achieved by using Agrobacterium tumefaciens-mediated transformation and revealed its role in the life cycle of the fungus. Disruption strains were viable but showed reduced growth and conidia production. Moreover, Pdchs mutants developed morphological defects as balloon-like enlarged cells and increased chitin content, indicative of an altered cell wall structure. Gene disruption also increased susceptibility to antifungal compounds such as calcofluor white (CFW), sodium dodecyl sulfate (SDS), hydroxide peroxide (H2O2) and commercial fungicides, but significantly no change was observed in the sensitivity to antifungal peptides. The PdchsVII mutants were able to infect citrus fruit and produced tissue maceration, although had reduced virulence and most importantly were greatly impaired in the production of visible mycelium and conidia on the fruit."
}
@article{COBAN2015707,
title = "Analysis and Training of the Required Abilities and Skills in Translation in the Light of Translation Models and General Theories of Translation Studies",
journal = "Procedia - Social and Behavioral Sciences",
volume = "197",
pages = "707 - 714",
year = "2015",
note = "7th World Conference on Educational Sciences",
issn = "1877-0428",
doi = "https://doi.org/10.1016/j.sbspro.2015.07.074",
url = "http://www.sciencedirect.com/science/article/pii/S1877042815040689",
author = "Fadime Coban",
keywords = "Translation, Teaching, Text Types, Philosophical Texts, Translation of Texts in Areas of Specialization",
abstract = "The aim of this study is to examine abilities and skills that a translator needs to develop in the light of general translation theories and models. Translation contains different mental activities such as language, thinking, problem solving, memory, conceptualization, learning, information processing, perception, understanding, re-expression etc., which makes translation a complex phenomenon. Translator is not a passive element but an expert, who senses, processes the stimuli, signifies, and produces meanings again in another language. In order to make these entire operations a translator should equip herself/ himself with translation skills and abilities. Considering within this context, the topic of skills and abilities translators need to acquire was discussed in the light of the translation competence models created by the PACTE group and Gopferich and general translation theories. It was found out that there are so many different skills (e.g. the National Job Qualifications Authority defined 42 skills for translators) to be acquired which differ in text types, medium, code and field and also new developments in the technology bring with it new required skills to be acquired. Thus the departments of Translation Studies should take these new skills into consideration in the translator training and accordingly plan their academic programs as the world is always changing and so is the translation environment."
}
@article{DAVID2013201,
title = "A software engineering perspective on environmental modeling framework design: The Object Modeling System",
journal = "Environmental Modelling & Software",
volume = "39",
pages = "201 - 213",
year = "2013",
note = "Thematic Issue on the Future of Integrated Modeling Science and Technology",
issn = "1364-8152",
doi = "https://doi.org/10.1016/j.envsoft.2012.03.006",
url = "http://www.sciencedirect.com/science/article/pii/S1364815212000886",
author = "O. David and J.C. Ascough and W. Lloyd and T.R. Green and K.W. Rojas and G.H. Leavesley and L.R. Ahuja",
keywords = "Object Modeling System, Environmental modeling frameworks, Modeling and simulation, Software engineering, Software design",
abstract = "The environmental modeling community has historically been concerned with the proliferation of models and the effort associated with collective model development tasks (e.g., code generation, data transformation, etc.). Environmental modeling frameworks (EMFs) have been developed to address this problem, but much work remains before EMFs are adopted as mainstream modeling tools. Environmental model development requires both scientific understanding of environmental phenomena and software developer proficiency. EMFs support the modeling process through streamlining model code development, allowing seamless access to data, and supporting data analysis and visualization. EMFs also support aggregation of model components into functional units, component interaction and communication, temporal-spatial stepping, scaling of spatial data, multi-threading/multi-processor support, and cross-language interoperability. Some EMFs additionally focus on high-performance computing and are tailored for particular modeling domains such as ecosystem, socio-economic, or climate change research. The Object Modeling System Version 3 (OMS3) EMF employs new advances in software framework design to better support the environmental model development process. This paper discusses key EMF design goals/constraints and addresses software engineering aspects that have made OMS3 framework development efficacious and its application practical, as demonstrated by leveraging software engineering efforts outside of the modeling community and lessons learned from over a decade of EMF development. Software engineering approaches employed in OMS3 are highlighted including a non-invasive lightweight framework design supporting component-based model development, use of implicit parallelism in system design, use of domain specific language design patterns, and cloud-based support for computational scalability. The key advancements in EMF design presented herein may be applicable and beneficial for other EMF developers seeking to better support environmental model development through improved framework design."
}
@article{TELESE2015696,
title = "LRP8-Reelin-Regulated Neuronal Enhancer Signature Underlying Learning and Memory Formation",
journal = "Neuron",
volume = "86",
number = "3",
pages = "696 - 710",
year = "2015",
issn = "0896-6273",
doi = "https://doi.org/10.1016/j.neuron.2015.03.033",
url = "http://www.sciencedirect.com/science/article/pii/S0896627315002573",
author = "Francesca Telese and Qi Ma and Patricia Montilla Perez and Dimple Notani and Soohwan Oh and Wenbo Li and Davide Comoletti and Kenneth A. Ohgi and Havilah Taylor and Michael G. Rosenfeld",
abstract = "Summary
One of the exceptional properties of the brain is its ability to acquire new knowledge through learning and to store that information through memory. The epigenetic mechanisms linking changes in neuronal transcriptional programs to behavioral plasticity remain largely unknown. Here, we identify the epigenetic signature of the neuronal enhancers required for transcriptional regulation of synaptic plasticity genes during memory formation, linking this to Reelin signaling. The binding of Reelin to its receptor, LRP8, triggers activation of this cohort of LRP8-Reelin-regulated neuronal (LRN) enhancers that serve as the ultimate convergence point of a novel synapse-to-nucleus pathway. Reelin simultaneously regulates NMDA-receptor transmission, which reciprocally permits the required γ-secretase-dependent cleavage of LRP8, revealing an unprecedented role for its intracellular domain in the regulation of synaptically generated signals. These results uncover an in vivo enhancer code serving as a critical molecular component of cognition and relevant to psychiatric disorders linked to defects in Reelin signaling."
}
@article{TOTH201590,
title = "Analytical description of coincidence detection synaptic mechanisms in the auditory pathway",
journal = "Biosystems",
volume = "136",
pages = "90 - 98",
year = "2015",
note = "Selected papers presented at the Eleventh International Workshop on Neural Coding, Versailles, France, 2014",
issn = "0303-2647",
doi = "https://doi.org/10.1016/j.biosystems.2015.07.006",
url = "http://www.sciencedirect.com/science/article/pii/S0303264715001070",
author = "Peter G. Toth and Petr Marsalek",
keywords = "Auditory pathway, Coincidence detection, Coincidence window, Medial superior olive, Postsynaptic potential, Sound localization, Spike timing jitter",
abstract = "Localization of sound source azimuth within horizontal plane uses interaural time differences (ITDs) between sounds arriving through the left and right ear. In mammals, ITDs are processed primarily in the medial superior olive (MSO) neurons. These are the first binaural neurons in the auditory pathway. The MSO neurons are notable because they possess high time precision in the range of tens of microseconds. Several theories and experimental studies explain how neurons are able to achieve such precision. In most theories, neuronal coincidence detection processes the ITDs and encodes azimuth in ascending neurons of the auditory pathway using modalities that are more tractable than the ITD. These modalities have been described as firing rate codes, place codes (labeled line codes) and similarly. In this theoretical model it is described how the ITD is processed by coincidence detection and converted into spikes by summing the postsynaptic potentials. Particular postsynaptic conductance functions are used in order to obtain an analytical solution in a closed form. Specifically, postsynaptic response functions are derived from the exponential decay of postsynaptic conductances and the MSO neuron is modeled as a simplified version of the Spike Response Model (SRM0) which uses linear summations of the membrane responses to synaptic inputs. For plausible ratios of time constants, an analytical solution used to describe properties of coincidence detection window is obtained. The parameter space is then explored in the vicinity of the analytical solution. The variation of parameters does not change the solution qualitatively."
}
@article{LUNDE2017395,
title = "“Just Wear Dark Underpants Mainly”: Learning from Adolescents' and Young Adults' Experiences with Early Discontinuation of the Contraceptive Implant",
journal = "Journal of Pediatric and Adolescent Gynecology",
volume = "30",
number = "3",
pages = "395 - 399",
year = "2017",
issn = "1083-3188",
doi = "https://doi.org/10.1016/j.jpag.2016.12.006",
url = "http://www.sciencedirect.com/science/article/pii/S1083318817300013",
author = "Britt Lunde and Lisa Littman and Samantha Stimmel and Rima Rana and Adam Jacobs and Carol R. Horowitz",
keywords = "Adolescents, Contraceptive implant, Contraceptive discontinuation, Contraceptive counseling",
abstract = "Study Objective
Long-acting reversible contraception, including the contraceptive implant, is recommended for teens and young women. However, some young women discontinue the implant early, and we seek to better understand their experiences.
Design, Setting, and Participants
We conducted interviews with 16 young women ages 14 to 24 who presented for removal of the contraceptive implant within 6 months after placement at outpatient adolescent, family medicine, and obstetrics and gynecology clinics. We coded and analyzed transcripts to identify themes and develop a thematic framework.
Interventions and Main Outcome Measures
We explored decision-making regarding placement and removal of the implant, differences between anticipated and experienced side effects, and recommendations for counseling.
Results
The participants reported experiencing significant side effects that led to removal, most often frequent or heavy bleeding or mood changes. These healthy young women were unprepared for these symptoms, despite remembering being told about possible side effects. Participants wanted more concrete examples of possible side effects, and personal stories of side effects experienced by others, rather than general terms such as irregular bleeding or mood changes. Few discussed problems with their providers; instead, they relied on the Internet or friends to help decide when to remove the implant. Nearly half of the participants did not start new contraception after removal, although they voiced a continued desire to avoid pregnancy.
Conclusion
We identified a need for more descriptive counseling about side effects experienced by individuals, and guidance on what to do about problems encountered after placement."
}
@article{BENACEK201822,
title = "P4-To-VHDL: Automatic generation of high-speed input and output network blocks",
journal = "Microprocessors and Microsystems",
volume = "56",
pages = "22 - 33",
year = "2018",
issn = "0141-9331",
doi = "https://doi.org/10.1016/j.micpro.2017.10.012",
url = "http://www.sciencedirect.com/science/article/pii/S0141933117304787",
author = "Pavel Benáček and Viktor Puš and Hana Kubátová and Tomáš Čejka",
keywords = "FPGA, High-level language, P4, 100 Gbps, Parser, Deparser",
abstract = "High-performance embedded architectures typically contain many stand-alone blocks which communicate and exchange data; additionally a high-speed network interface is usually needed at the boundary of the system. The software-based data processing is typically slow which leads to a need for hardware accelerated approaches. The problem is getting harder if the supported protocol stack is rapidly changing. Such problem can be effectively solved by the Field Programmable Gate Arrays and high-level synthesis which together provide a high degree of generality. This approach has several advantages like fast development or possibility to enable the area of packet-oriented communication to domain oriented experts. However, the typical disadvantage of this approach is the insufficient performance of generated system from a high-level description. This can be a serious problem in the case of a system which is required to process data at high packet rates. This work presents a generator of high-speed input (Parser) and output (Deparser) network blocks from the P4 language which is designed for the description of modern packet processing devices. The tool converts a P4 description to a synthesizable VHDL code suitable for the FPGA implementation. We present design, analysis and experimental results of our generator. Our results show that the generated circuits are able to process 100 Gbps traffic with fairly complex protocol structure at line rate on Xilinx Virtex-7 XCVH580T FPGA. The approach can be used not only in networking devices but also in other applications like packet processing engines in embedded cores because the P4 language is device and protocol independent."
}
@article{KWON201680,
title = "Older Ethnic Minority Women's Perceptions of Stroke Prevention and Walking",
journal = "Women's Health Issues",
volume = "26",
number = "1",
pages = "80 - 86",
year = "2016",
issn = "1049-3867",
doi = "https://doi.org/10.1016/j.whi.2015.08.003",
url = "http://www.sciencedirect.com/science/article/pii/S1049386715001280",
author = "Ivy Kwon and Nazleen Bharmal and Sarah Choi and Daniel Araiza and Mignon R. Moore and Laura Trejo and Catherine A. Sarkisian",
abstract = "Objective
To inform the development of a tailored behavioral stroke risk reduction intervention for ethnic minority seniors, we sought to explore gender differences in perceptions of stroke prevention and physical activity (walking).
Methods
In collaboration with community-based organizations, we conducted 12 mixed-gender focus groups of African American, Latino, Chinese, and Korean seniors aged 60 years and older with a history of hypertension (89 women and 42 men). Transcripts were coded and recurring topics compared by gender.
Results
Women expressed beliefs that differed from men in 4 topic areas: 1) stroke-related interest, 2) barriers to walking, 3) facilitators to walking, and 4) health behavior change attitudes. Compared with men, women were more interested in their role in response to a stroke and post-stroke care. Women described walking as an acceptable form of exercise, but cited neighborhood safety and pain as walking barriers. Fear of nursing home placement and weight loss were identified as walking facilitators. Women were more prone than men to express active/control attitudes toward health behavior change.
Conclusions
Older ethnic minority women, a high-risk population for stroke, may be more receptive to behavioral interventions that address the gender-specific themes identified by this study."
}
@article{KULIKOV201571,
title = "AstroPhi: A code for complex simulation of the dynamics of astrophysical objects using hybrid supercomputers",
journal = "Computer Physics Communications",
volume = "186",
pages = "71 - 80",
year = "2015",
issn = "0010-4655",
doi = "https://doi.org/10.1016/j.cpc.2014.09.004",
url = "http://www.sciencedirect.com/science/article/pii/S0010465514003099",
author = "I.M. Kulikov and I.G. Chernykh and A.V. Snytnikov and B.M. Glinskiy and A.V. Tutukov",
keywords = "Numerical astrophysics, Astrophysical objects, Dynamics simulation, Hybrid supercomputers",
abstract = "We propose a new code named AstroPhi for simulation of the dynamics of astrophysical objects on hybrid supercomputers equipped with Intel Xenon Phi computation accelerators. The details of parallel implementation are described, as well as changes to the computational algorithm that facilitate efficient parallel implementation. A single Xeon Phi accelerator yielded 27-fold acceleration. The use of 32 Xeon Phi accelerators resulted in 94% parallel efficiency. Several collapse problems are simulated using the AstroPhi code.
Program summary
Program title: AstroPhi Catalogue identifier: AEUM_v1_0 Program summary URL:http://cpc.cs.qub.ac.uk/summaries/AEUM_v1_0.html Program obtainable from: CPC Program Library, Queen’s University, Belfast, N. Ireland Licensing provisions: Standard CPC licence, http://cpc.cs.qub.ac.uk/licence/licence.html No. of lines in distributed program, including test data, etc.: 99604 No. of bytes in distributed program, including test data, etc.: 305433 Distribution format: tar.gz Programming language: C++. Computer: MVS-10P - RSC Tornado, Xeon E5-2690 8C 2.900 GHz, Infiniband FDR, Intel Xeon Phi SE10X. Operating system: Linux. Has the code been vectorized or parallelized?: Parallelized on MPI + OpenMP for Intel MIC architecture, 32 Intel Xeon Phi (60 cores per 1 Intel Xeon Phi = 1920 cores of Intel Xeon Phi). RAM: 137438953472 bytes (128 GB) bytes Classification: 1.9. External routines: MPI, OpenMP for Intel Xeon Phi, FFTW 2.1.5 Nature of problem: Complex numerical simulation of dynamics of astrophysical objects plays an important role due to significant growth of observational astronomic data. The new astrophysical models and codes need to be developed for detailed simulation of different physical effects in astrophysics with the use of modern supercomputers with hybrid architecture. Solution method: AstroPhi code consisting of particle-in-cell and Godunov methods combination adapted for hybrid supercomputer architecture. Restrictions: For this version maximum grid size is restricted to 10243. Running time: Typical running on MVS-10P is 24 h. The test provided only takes a few minutes."
}
@article{MILAZZO2015277,
title = "Modelling of ejector chillers with steam and other working fluids",
journal = "International Journal of Refrigeration",
volume = "57",
pages = "277 - 287",
year = "2015",
issn = "0140-7007",
doi = "https://doi.org/10.1016/j.ijrefrig.2015.05.015",
url = "http://www.sciencedirect.com/science/article/pii/S0140700715001541",
author = "Adriano Milazzo and Andrea Rocchetti",
keywords = "Ejector chiller, Jet pump, Thermodynamic simulation, Refrigerants, GWP, Refroidisseur à éjecteur, Pompe à jet, Simulation thermodynamique, Frigorigènes, GWP",
abstract = "The Constant Rate of Momentum Change (CRMC) criterion attempts to improve the design of supersonic ejectors, that can be used in heat-powered chillers for industrial or air-conditioning use. Moving from its original formulation, the CRMC design method can be advanced accounting for friction irreversibilities and real gas behaviour, as done in a previous work by our research group. Here we present an upgraded version of this analysis, supported by experimental data from a prototype chiller using R245fa as working fluid. The analysis is extended to other fluids (water, isobutane, 5 HFCs and 3 HFOs) whose performance is calculated on a wide range of heat source/sink temperatures. The existing literature, based generally on ideal gas simulations, suggests that water yields poor results in terms of COP. This paper shows that this result may be argued. Low GWP fluid HFO1233zd also gives good results."
}
@article{DELANGE201498,
title = "An operational, multi-scale, multi-model system for consensus-based, integrated water management and policy analysis: The Netherlands Hydrological Instrument",
journal = "Environmental Modelling & Software",
volume = "59",
pages = "98 - 108",
year = "2014",
issn = "1364-8152",
doi = "https://doi.org/10.1016/j.envsoft.2014.05.009",
url = "http://www.sciencedirect.com/science/article/pii/S1364815214001406",
author = "Willem J. De Lange and Geert F. Prinsen and Jacco C. Hoogewoud and Albert A. Veldhuizen and Jarno Verkaik and Gualbert H.P. Oude Essink and Paul E.V. van Walsum and Joost R. Delsman and Joachim C. Hunink and Harry Th.L. Massop and Timo Kroon",
keywords = "National cooperation, Integrated model, Surface water, Groundwater, Scaling, The Netherlands",
abstract = "Water management in the Netherlands applies to a dense network of surface waters for discharge, storage and distribution, serving highly valuable land-use. National and regional water authorities develop long-term plans for sustainable water use and safety under changing climate conditions. The decisions about investments on adaptive measures are based on analysis supported by the Netherlands Hydrological Instrument NHI based on the best available data and state-of-the-art technology and developed through collaboration between national research institutes. The NHI consists of various physical models at appropriate temporal and spatial scales for all parts of the water system. Intelligent connectors provide transfer between different scales and fast computation, by coupling model codes at a deep level in software. A workflow and version management system guarantees consistency in the data, software, computations and results. The NHI is freely available to hydrologists via an open web interface that enables exchange of all data and tools."
}
@article{SUVOROVA201258,
title = "Detection change points of triplet periodicity of gene",
journal = "Gene",
volume = "491",
number = "1",
pages = "58 - 64",
year = "2012",
issn = "0378-1119",
doi = "https://doi.org/10.1016/j.gene.2011.08.032",
url = "http://www.sciencedirect.com/science/article/pii/S0378111911005014",
author = "Yulia M. Suvorova and Valentina M. Rudenko and Eugene V. Korotkov",
keywords = "Triplet periodicity, Triplet periodicity change point, Gene sequence, Fusion event",
abstract = "The triplet periodicity (TP) is a distinguished property of protein coding sequences. There are complex genes with more than one TP type along their sequence. We say that these genes contain a triplet periodicity change point. The aim of the work is to find all genes that contain TP change point and attempt to compare the positions of change point in genes with known biological data. We have developed a mathematical method to identify triplet periodicity changes along a sequence. We have found 311,221 genes with the TP change point in the KEGG/Genes database (version 48). It is about 8% from the total database volume (4013150). We showed that the repetitive sequences are not the only cause of such events. We suppose that the TP change point may indicate a fusion of genes or domains. We performed BLAST analysis to find potential ancestral genes for the parts of genes with TP change point. As a result we found that in 131323 cases sequences with TP change point have proper similarities for one or both parts. The relationship between TP change point and the fusion events in genes is discussed. The program realization of the method is available by request to authors."
}
@article{HAASE2013236,
title = "How to Save Expert Knowledge for the Organization: Methods for Collecting and Documenting Expert Knowledge Using Virtual Reality based Learning Environments",
journal = "Procedia Computer Science",
volume = "25",
pages = "236 - 246",
year = "2013",
note = "2013 International Conference on Virtual and Augmented Reality in Education",
issn = "1877-0509",
doi = "https://doi.org/10.1016/j.procs.2013.11.029",
url = "http://www.sciencedirect.com/science/article/pii/S1877050913012349",
author = "Tina Haase and Wilhelm Termath and Marcel Martsch",
keywords = "Virtual Reality, Expert knowledge, Triad interview, Knowledge documentation, Collecting knowledge, Tacit knowledge",
abstract = "The current demographic development will lead to changing working conditions. The paper at hand presents methods for the investigation of expert knowledge within the company and how to document these information, widely independent from individuals, within a technology based learning environment, using virtual reality (VR) technologies and other media. Expert knowledge is often coded as tacit knowledge [1] and can be hardly verbalized by experts. The extraction of tacit knowledge requires methods that are based on stories. Beyond facts these stories also include tacit knowledge driven by emotions. One of the narrative methods presented in the paper will be the »triad interview« [2]. The documentation of these interviews within texts is not very sustainable and other methods for the documentation of expert knowledge are required. Especially in the field of maintenance that is focused in the paper, virtual reality is a suitable method for the documentation as technicians are familiar with drawings and visual content representations. Virtual reality learning environment can visualize working processes and keep the narrative structure that is required for transferring tacit knowledge. Besides, interactions as a typical characteristic of virtual reality applications allow the design of problem solving tasks. The paper presents the »triad interview« and the »working process analysis« [3] that are used for extracting the relevant information of a working process. For the didactical design of the learning tasks the method of the »complete action« [4] is applied. The paper will present the design of the several phases and their benefit for the learning process. Finally the results and experiences from an evaluation study within the organization will be presented."
}
@article{MORRISON201691,
title = "Parvalbumin interneurons constrain the size of the lateral amygdala engram",
journal = "Neurobiology of Learning and Memory",
volume = "135",
pages = "91 - 99",
year = "2016",
note = "MCCS 2016",
issn = "1074-7427",
doi = "https://doi.org/10.1016/j.nlm.2016.07.007",
url = "http://www.sciencedirect.com/science/article/pii/S1074742716301071",
author = "Dano J. Morrison and Asim J. Rashid and Adelaide P. Yiu and Chen Yan and Paul W. Frankland and Sheena A. Josselyn",
keywords = "Engram, Parvalbumin, Lateral amygdala, Sparse coding, Memory, Fear",
abstract = "Memories are thought to be represented by discrete physiological changes in the brain, collectively referred to as an engram, that allow patterns of activity present during learning to be reactivated in the future. During the formation of a conditioned fear memory, a subset of principal (excitatory) neurons in the lateral amygdala (LA) are allocated to a neuronal ensemble that encodes an association between an initially neutral stimulus and a threatening aversive stimulus. Previous experimental and computational work suggests that this subset consists of only a small proportion of all LA neurons, and that this proportion remains constant across different memories. Here we examine the mechanisms that contribute to the stability of the size of the LA component of an engram supporting a fear memory. Visualizing expression of the activity-dependent gene Arc following memory retrieval to identify neurons allocated to an engram, we first show that the overall size of the LA engram remains constant across conditions of different memory strength. That is, the strength of a memory was not correlated with the number of LA neurons allocated to the engram supporting that memory. We then examine potential mechanisms constraining the size of the LA engram by expressing inhibitory DREADDS (designer receptors exclusively activated by designer drugs) in parvalbumin-positive (PV+) interneurons of the amygdala. We find that silencing PV+ neurons during conditioning increases the size of the engram, especially in the dorsal subnucleus of the LA. These results confirm predictions from modeling studies regarding the role of inhibition in shaping the size of neuronal memory ensembles and provide additional support for the idea that neurons in the LA are sparsely allocated to the engram based on relative neuronal excitability."
}
@article{KAPOOR2016230,
title = "Pattern of socio-economic and health aspects among TB patients and controls",
journal = "Indian Journal of Tuberculosis",
volume = "63",
number = "4",
pages = "230 - 235",
year = "2016",
issn = "0019-5707",
doi = "https://doi.org/10.1016/j.ijtb.2016.09.011",
url = "http://www.sciencedirect.com/science/article/pii/S0019570716301536",
author = "A.K. Kapoor and Vijit Deepani and Meenal Dhall and Satwanti Kapoor",
keywords = "Socio-economic determinants, Tuberculosis, Co-morbidities, DOTs centre",
abstract = "Background
Socio-economic and health-related factors have a significant impact on tuberculosis (TB) incidence among population residing in resource-scare settings.
Objective
To evaluate the pattern of socio-economic and health-related factors among TB patients and control in Delhi, India.
Methods
The present cross-sectional study was performed among 893 TB patients (or cases) and 333 healthy disease-free controls. The data for the present study was obtained from several district TB centres in north, west and south Delhi. The collected data was edited, coded and statistical analysed with the help of SPSS 20.0 version.
Results
Illiteracy and primary education were significant risk factors being associated with a TB. Rented housing condition had an odds ratio (OR) of 1.4 (95% confidence interval [CI]: 1.09–1.89) compared to owned housing condition. 3–5 individuals per room were 3 times more likely to be associated with a case of TB (95% CI: 2.49–4.41). Migrant individuals were 13 times more likely to be associated with a case of TB (95% CI: 8.77–19.78) in comparison to settled population. Daily consumption of non-vegetarian food also significantly contributed to case of TB with an OR of 3.4 (95% CI: 2.51–4.72). Loss of appetite and family TB served as significant health-related factors associated with TB risk.
Conclusion
Lower educational status, rented household, individuals per room (as a measure of overcrowding) and migratory status served as prominent risk factors for TB disease. Preference and frequency of non-vegetarian food being consumed, night sweating, weight loss, loss of appetite, earlier TB and family TB were principle health-related risk factors associated with TB disease."
}
@article{KASABOV2013188,
title = "Dynamic evolving spiking neural networks for on-line spatio- and spectro-temporal pattern recognition",
journal = "Neural Networks",
volume = "41",
pages = "188 - 201",
year = "2013",
note = "Special Issue on Autonomous Learning",
issn = "0893-6080",
doi = "https://doi.org/10.1016/j.neunet.2012.11.014",
url = "http://www.sciencedirect.com/science/article/pii/S0893608012003139",
author = "Nikola Kasabov and Kshitij Dhoble and Nuttapod Nuntalid and Giacomo Indiveri",
keywords = "Spatio-temporal pattern recognition, Spiking neural networks, Dynamic synapses, Evolving connectionist systems, Rank-order coding, Spike time based learning, Moving object recognition, EEG pattern recognition",
abstract = "On-line learning and recognition of spatio- and spectro-temporal data (SSTD) is a very challenging task and an important one for the future development of autonomous machine learning systems with broad applications. Models based on spiking neural networks (SNN) have already proved their potential in capturing spatial and temporal data. One class of them, the evolving SNN (eSNN), uses a one-pass rank-order learning mechanism and a strategy to evolve a new spiking neuron and new connections to learn new patterns from incoming data. So far these networks have been mainly used for fast image and speech frame-based recognition. Alternative spike-time learning methods, such as Spike-Timing Dependent Plasticity (STDP) and its variant Spike Driven Synaptic Plasticity (SDSP), can also be used to learn spatio-temporal representations, but they usually require many iterations in an unsupervised or semi-supervised mode of learning. This paper introduces a new class of eSNN, dynamic eSNN, that utilise both rank-order learning and dynamic synapses to learn SSTD in a fast, on-line mode. The paper also introduces a new model called deSNN, that utilises rank-order learning and SDSP spike-time learning in unsupervised, supervised, or semi-supervised modes. The SDSP learning is used to evolve dynamically the network changing connection weights that capture spatio-temporal spike data clusters both during training and during recall. The new deSNN model is first illustrated on simple examples and then applied on two case study applications: (1) moving object recognition using address-event representation (AER) with data collected using a silicon retina device; (2) EEG SSTD recognition for brain–computer interfaces. The deSNN models resulted in a superior performance in terms of accuracy and speed when compared with other SNN models that use either rank-order or STDP learning. The reason is that the deSNN makes use of both the information contained in the order of the first input spikes (which information is explicitly present in input data streams and would be crucial to consider in some tasks) and of the information contained in the timing of the following spikes that is learned by the dynamic synapses as a whole spatio-temporal pattern."
}
@article{STENSRUD201469,
title = "Improving communication in general practice when mental health issues appear: Piloting a set of six evidence-based skills",
journal = "Patient Education and Counseling",
volume = "95",
number = "1",
pages = "69 - 75",
year = "2014",
issn = "0738-3991",
doi = "https://doi.org/10.1016/j.pec.2013.12.005",
url = "http://www.sciencedirect.com/science/article/pii/S0738399113005193",
author = "Tonje Lauritzen Stensrud and Pål Gulbrandsen and Trond Arne Mjaaland and Sidsel Skretting and Arnstein Finset",
keywords = "Mental health, Communication, Pilot, General practice",
abstract = "Objective
To test a communication skills training program teaching general practitioners (GPs) a set of six evidence-based mental health related skills.
Methods
A training program was developed and tested in a pilot test–retest study with 21GPs. Consultations were videotaped and actors used as patients. A coding scheme was created to assess the effect of training on GP behavior. Relevant utterances were categorized as examples of each of the six specified skills. The GPs’ self-perceived learning needs and self-efficacy were measured with questionnaires.
Results
The mean number of GP utterances related to the six skills increased from 13.3 (SD 6.2) utterances before to 23.6 (SD 7.2) utterances after training; an increase of 77.4% (P<0.001). Effect sizes varied from 0.23 to 1.37. Skills exploring emotions, cognitions and resources, and the skill Promote coping, increased significantly. Self-perceived learning needs and self-efficacy did not change significantly.
Conclusion
The results from this pilot test are encouraging. GPs enhanced their use on four out of six mental health related communication skills significantly, and the effects were medium to large.
Practice implications
This training approach appears to be an efficacious approach to mental health related communication skills training in general practice."
}
@article{VOTAW2017218,
title = "Perceived risk of heroin use among nonmedical prescription opioid users",
journal = "Addictive Behaviors",
volume = "65",
pages = "218 - 223",
year = "2017",
issn = "0306-4603",
doi = "https://doi.org/10.1016/j.addbeh.2016.08.025",
url = "http://www.sciencedirect.com/science/article/pii/S0306460316303057",
author = "Victoria R. Votaw and Justine Wittenauer and Hilary S. Connery and Roger D. Weiss and R. Kathryn McHugh",
keywords = "Heroin, Opioid, Nonmedical prescription opioid use, Perceived risk, National Survey on Drug Use and Health",
abstract = "Aims
The prevalence of heroin use among nonmedical prescription opioid (NMPO) users has increased in recent years. Identifying characteristics associated with heroin use in this population can help inform efforts to prevent heroin initiation and maintenance. The aim of this study was to evaluate differences in perceived risk of heroin among NMPO users with and without histories of heroin use, and to examine temporal trends in perceived risk of heroin among this population.
Methods
Data are from the 2002–2013 National Survey on Drug Use and Health, and included all past-year NMPO users (N=49,045). Participants reported perceived risk of trying heroin once or twice and regular heroin use. Responses were coded dichotomously (great risk vs. other risk) and logistic regression analyses were used to evaluate the association between lifetime heroin use and perceived risk of heroin, and to determine temporal changes in perceived risk.
Results
Results indicated a significant association between lifetime heroin use and lower likelihood of reporting great risk of trying heroin (OR=0.38, 95% CI: 0.33, 0.44, p<0.001), and of regular use of heroin (OR=0.39, 95% CI: 0.32, 0.48, p<0.001). There was a significant, yet modest, trend toward decreasing perception of great risk from 2002 to 2013.
Conclusions
Findings from this analysis of nationally representative data indicate that NMPO users with a history of heroin use perceive heroin to be less risky than those without heroin use. Perception of risk has decreased from 2002 to 2013 in this population, consistent with increasing rates of heroin initiation."
}
@article{GUSKOVA2016402,
title = "RNGAVXLIB: Program library for random number generation, AVX realization",
journal = "Computer Physics Communications",
volume = "200",
pages = "402 - 405",
year = "2016",
issn = "0010-4655",
doi = "https://doi.org/10.1016/j.cpc.2015.11.001",
url = "http://www.sciencedirect.com/science/article/pii/S0010465515004117",
author = "M.S. Guskova and L.Yu. Barash and L.N. Shchur",
keywords = "Statistical methods, Monte Carlo, Random number generation, Advanced Vector Extensions (AVX)",
abstract = "We present the random number generator (RNG) library RNGAVXLIB, which contains fast AVX realizations of a number of modern random number generators, and also the abilities to jump ahead inside a RNG sequence and to initialize up to 1019 independent random number streams with block splitting method. Fast AVX implementations produce exactly the same output sequences as the original algorithms. Usage of AVX vectorization allows to substantially improve performance of the generators. The new realizations are up to 2 times faster than the SSE realizations implemented in the previous version of the library (Barash and Shchur, 2013), and up to 40 times faster compared to the original algorithms written in ANSI C.
New version program summary
Program title: RNGAVXLIB Catalogue identifier: AEIT_v3_0 Program summary URL:http://cpc.cs.qub.ac.uk/summaries/AEIT_v3_0.html Program obtainable from: CPC Program Library, Queen’s University, Belfast, N. Ireland Licensing provisions: Standard CPC licence, http://cpc.cs.qub.ac.uk/licence/licence.html No. of lines in distributed program, including test data, etc.: 21061 No. of bytes in distributed program, including test data, etc.: 1763798 Distribution format: tar.gz Programming language: C, Fortran. Computer: PC, laptop, workstation, or server with Intel or AMD processor. Operating system: Unix, Windows. RAM: 4 Mbytes Catalogue identifier of previous version: AEIT_v2_0 Journal reference of previous version: Comput. Phys. Comm. 184(2013)2367 Classification: 4.13. Does the new version supersede the previous version?: Yes Nature of problem: Any calculation requiring uniform pseudorandom number generator, in particular, Monte Carlo calculations. Any calculation requiring parallel streams of uniform pseudorandom numbers. Solution method: The library contains realization of the following modern and reliable generators: MT19937 [2], MRG32K3A [3], LFSR113 [4], GM19, GM31, GM61 [5, 6], and GM29, GM55, GQ58.1, GQ58.3, GQ58.4 [7, 8]. The library contains realizations written in ANSI C, realizations based on SSE command set and realizations based on AVX command set. The use of vectorization allows substantial improvement in performance of all the generators. The library also contains the ability to jump ahead inside the RNG sequence and to initialize independent random number streams with block splitting method for each of the RNGs. C and Fortran are supported. Reasons for new version: Modern CPUs better support vectorization compared to the CPUs available two years ago when the previous version of the library was prepared. In particular, Advanced Vector Instructions 2 (AVX2) are now supported by CPUs fabricated by Intel and AMD. AVX2 has been supported by Intel CPUs since the Haswell microarchitecture was released in June 2013, and has been supported by AMD CPUs since the Streamroller Family 15h microarchitecture was released in January 2014. An important new feature of this version is the ability to employ the AVX2 instruction set of a CPU in order to speed up the calculations. As a result, the new RNG realizations employing AVX2 are up to 2 times faster than the realizations implemented in the previous version of the library. Summary of revisions:1.We added fast AVX realizations for the generators, which are up to 2 times faster than the SSE realizations implemented in the previous version of the library [1], and up to 40 times faster compared to the original algorithms written in ANSI C.2.The function call interface has been simplified compared to previous versions.3.We added automatic detection of whether the CPU supports SSE and/or AVX vectorization at the compilation stage and the functions which employ SSE and AVX vectorization only if the CPU supports them.4.We added support for simultaneous generation of two independent output sequences for the LFSR113 generator using the AVX vectorization. Restrictions: For AVX realizations of the generators, Intel or AMD CPU supporting AVX2 command set is required. For SSE realizations of the generators, Intel or AMD CPU supporting SSE2 command set is required. In order to use the SSE realization for the lfsr113 generator, CPU must support SSE4.1 command set. Additional comments: The function call interface has been simplified compared to the previous versions. For each of the generators, RNGAVXLIB supports the following functions, where rng should be replaced by name of a particular generator: void rng_init_(rng_state∗state); void rng_init_sequence_(rng_state∗state,unsigned long long SequenceNumber); void rng_skipahead_(rng_state∗state, unsigned long long N); unsigned int rng_generate_(rng_state∗state); float rng_generate_uniform_float_(rng_state∗state); unsigned int rng_ansi_generate_(rng_state∗state); float rng_ansi_generate_uniform_float_(rng_state∗state); unsigned int rng_sse_generate_(rng_state∗state); float rng_sse_generate_uniform_float_(rng_state∗state); unsigned int rng_avx_generate_(rng_state∗state); float rng_avx_generate_uniform_float_(rng_state∗state); void rng_print_state_(rng_state∗state); The function call interface for the rng_skipahead_ function, which jumps ahead N output values inside an RNG sequence, can be slightly different for some of the RNGs. For example, the function void mt19937_skipahead_(mt19937_state∗state, unsigned long long a, unsigned b); skips ahead N=a⋅2b numbers, where N<2512, and the function void gm55_skipahead_(gm55_state∗state, unsigned long long offset64, unsigned long long offset0); skips ahead N=264⋅offset64+offset0 numbers. The detailed function call interface can be found in the header files of the include directory. The examples of using the library can be found in the examples directory. Some of the generators have several versions of the rng_init_sequence_ routine, for example, rng_init_short_sequence_, rng_init_medium_sequence_, rng_init_long_sequence_ (see details in [1, 10]). Maximal number of sequences and maximal length of each sequence for pseudorandom streams are indicated in [1, 10]. The algorithms used to jump ahead in the RNG sequence and to initialize parallel streams of pseudorandom numbers are described in detail in [9, 10]. This version of the library automatically detects whether the CPU supports SSE and/or AVX vectorization at the compilation stage. During the compilation of the library, the −march=native compiler option is used, which allows the use of predefined macros such as __SSE2__ and __AVX2__ in the source code. This is supported by both GNU and Intel compilers. The functions rng_generate_ and rng_generate_uniform_float employ SSE and AVX vectorization only if the CPU supports them. Table 1: Speed of the realizations. CPU: Intel Xeon E5-2650v3 (2.3 GHz); Compiler: gcc; Optimization: -O3.  This version of the library also supports simultaneous generation of two independent output sequences for the LFSR113 generator using the AVX vectorization: void lfsr113_avx_generate_two_(lfsr113 _state∗state, unsigned∗out1, unsigned∗out2); This is the fastest possible way to generate LFSR113 random numbers using the CPU which supports the AVX2 instruction set. The function lfsr113_skipahead_ jumps ahead only in the first LFSR output sequence. Jumping ahead in the second output sequence can be performed with the separate lfsr113_skipahead2_ routine. GNU Fortran does not have compiler directives for data alignment to assist vectorization, although Intel Fortran has directives for that, such as !dir$  attributes align:32. By default, GNU Fortran aligns all variables to 16-byte boundaries, which is sufficient to efficiently use SSE, but is not sufficient for AVX. We find that applying an additional SAVE command to the generator state in Fortran results, in particular, in alignment of the data to 32-byte boundaries. This allows one to employ AVX realizations from Fortran (see the examples directory). We have tested this on workstations with various CPUs and various versions of Linux. Development and optimization of the algorithms were supported by the Russian Science Foundation project No. 14-21-00158. Benchmark testing was partially supported by Russian Foundation for Basic Research project No. 13-07-00570 and by the Supercomputing Center of Lomonosov Moscow State University [11]. Table 2: Speed of the realizations. CPU: Intel Core i7-4790K (4 GHz); Compiler: gcc; Optimization: -O3.  Running time: Running time is of the order of 20 sec for generating 109 pseudorandom numbers with a PC based on Intel Core i7-940 CPU. Speed of the random number generation on CPUs widely used in modern servers and workstations is shown in Tables 1 and 2 respectively (see also [6, 7]). References:[1]L.Yu Barash, L.N. Shchur, RNGSSELIB: Program library for random number generation. More generators, parallel streams of random numbers and Fortran compatibility, Computer Physics Communications, 184(10), 2367–2369 (2013).[2]M. Matsumoto and T. Tishimura, Mersenne Twister: A 623- dimensionally equidistributed uniform pseudorandom number generator, ACM Trans. on Mod. and Comp. Simul. 8 (1), 3–30 (1998).[3]P L’Ecuyer, Good Parameter Sets for Combined Multiple Recursive Random Number Generators, Oper. Res. 47 (1), 159–164 (1999).[4]P L’Ecuyer, Tables of Maximally-Equidistributed Combined LFSR Generators, Math. of Comp., 68 (255), 261–269 (1999).[5]L. Barash, L.N. Shchur, Periodic orbits of the ensemble of Sinai- Arnold cat maps and pseudorandom number generation, Phys. Rev. E 73, 036701 (2006).[6]L.Yu Barash, L.N. Shchur, RNGSSELIB: Program library for random number generation, SSE2 realization, Computer Physics Communications, 182 (7), 1518–1527 (2011).[7]L.Yu. Barash, Applying dissipative dynamical systems to pseudorandom number generation: Equidistribution property and statistical independence of bits at distances up to logarithm of mesh size, Europhysics Letters (EPL) 95, 10003 (2011).[8]L.Yu. Barash, Geometric and statistical properties of pseudorandom number generators based on multiple recursive transformations // Springer Proceedings in Mathematics and Statistics, Springer-Verlag, Berlin, Heidelberg, Vol. 23, 265–280 (2012).[9]L.Yu. Barash, L.N. Shchur, On the generation of parallel streams of pseudorandom numbers, Programmnaya inzheneriya, 1 (2013) 24 (in Russian)[10]L.Yu. Barash, L.N. Shchur, PRAND: GPU accelerated parallel random number generation library: Using most reliable algorithms and applying parallelism of modern GPUs and CPUs, Computer Physics Communications, 185(4), 1343–1353 (2014).[11]Voevodin Vl.V., Zhumatiy S.A., Sobolev S.I., Antonov A.S., Bryzgalov P.A., Nikitenko D.A., Stefanov K.S., Voevodin Vad.V., Practice of “Lomonosov” Supercomputer // Open Systems J. - Moscow: Open Systems Publ., 2012, no.7. (In Russian)"
}
@article{JAVANROSHTKHARI20131436,
title = "An on-line, real-time learning method for detecting anomalies in videos using spatio-temporal compositions",
journal = "Computer Vision and Image Understanding",
volume = "117",
number = "10",
pages = "1436 - 1452",
year = "2013",
issn = "1077-3142",
doi = "https://doi.org/10.1016/j.cviu.2013.06.007",
url = "http://www.sciencedirect.com/science/article/pii/S1077314213001239",
author = "Mehrsan Javan Roshtkhari and Martin D. Levine",
keywords = "Video surveillance, On-line anomaly detection, Suspicious event detection, Spatio-temporal video volumes, Spatio-temporal compositions",
abstract = "This paper presents an approach for detecting suspicious events in videos by using only the video itself as the training samples for valid behaviors. These salient events are obtained in real-time by detecting anomalous spatio-temporal regions in a densely sampled video. The method codes a video as a compact set of spatio-temporal volumes, while considering the uncertainty in the codebook construction. The spatio-temporal compositions of video volumes are modeled using a probabilistic framework, which calculates their likelihood of being normal in the video. This approach can be considered as an extension of the Bag of Video words (BOV) approaches, which represent a video as an order-less distribution of video volumes. The proposed method imposes spatial and temporal constraints on the video volumes so that an inference mechanism can estimate the probability density functions of their arrangements. Anomalous events are assumed to be video arrangements with very low frequency of occurrence. The algorithm is very fast and does not employ background subtraction, motion estimation or tracking. It is also robust to spatial and temporal scale changes, as well as some deformations. Experiments were performed on four video datasets of abnormal activities in both crowded and non-crowded scenes and under difficult illumination conditions. The proposed method outperformed all other approaches based on BOV that do not account for contextual information."
}
@article{SANANTONIOGOMEZ201447,
title = "Urban and landscape changes through historical maps: The Real Sitio of Aranjuez (1775–2005), a case study",
journal = "Computers, Environment and Urban Systems",
volume = "44",
pages = "47 - 58",
year = "2014",
issn = "0198-9715",
doi = "https://doi.org/10.1016/j.compenvurbsys.2013.12.001",
url = "http://www.sciencedirect.com/science/article/pii/S0198971513001154",
author = "C. San-Antonio-Gómez and C. Velilla and F. Manzano-Agugliaro",
keywords = "Historical maps, Urban development, Planimetric accuracy, Rectification, Monumental heritage conservation, Graphical reconstruction, Colour code",
abstract = "When determining the evolution of a territory or town over time, comparing historical maps with contemporary maps is indispensable. In this study, we applied the methodology of georectification to compare historical maps with current orthophotos from 2005. We propose colour and lines code as useful tools for the analysis of the urban and landscape changes that the town has undergone since the 18th century, and we graphically reconstruct certain former heritage items that no longer exist. For example, these techniques are applied to the Real Sitio de Aranjuez (Spain) using the two most important historical maps: the 1775 Domingo de Aguirre map, which shows the full extent of the royal site for the first time, and the 1835 General Town Plan, which is the most characteristic of available 19th-century maps, as it displays the consolidated historical town. Next, using two rectified rasters and the orthophoto, we overlay a grid of nine 1×1km squares, allowing us to “see the town and its territory” at three moments in history: 1775, 1835 and 2005. Thus, we obtain formal and dimensional information allowing analysis of the evolution of the territory, urban area and historic buildings. Among the many applications of this methodology in the fields of urban development and monumental-heritage conservation, we propose the graphical reconstruction of three urban elements that no longer exist. We determined that graphical reconstruction, in conjunction with traditional historical research, provides the greatest benefits for recreating an historical landscape. These methodologies will aid in the development of long-range management strategies and facilitate the assessment of threats posed by anthropogenic activities and environmental change to preserve the landscape heritage."
}
@article{PANT201254,
title = "Prevalidation study of the Syrian hamster embryo (SHE) cell transformation assay at pH 6.7 for assessment of carcinogenic potential of chemicals",
journal = "Mutation Research/Genetic Toxicology and Environmental Mutagenesis",
volume = "744",
number = "1",
pages = "54 - 63",
year = "2012",
note = "International Prevalidation Study on Cell Transformation Assays",
issn = "1383-5718",
doi = "https://doi.org/10.1016/j.mrgentox.2011.12.005",
url = "http://www.sciencedirect.com/science/article/pii/S1383571811003585",
author = "Kamala Pant and Shannon W. Bruce and Jamie E. Sly and Thorsten Kunkelmann and Susanne Kunz-Bohnenberger and Albrecht Poth and Günter Engelhardt and Markus Schulz and Karl-Rainer Schwind",
keywords = "Cell transformation assay, pH 6.7, Morphological transformation, Validation, SHE, Syrian hamster embryo",
abstract = "The Syrian hamster embryo (SHE) cell transformation assay (CTA) is an important in vitro method that is highly predictive of rodent carcinogenicity. It is a key method for reducing animal usage for carcinogenicity prediction. The SHE assay has been used for many years primarily to investigate and identify potential rodent carcinogens thereby reducing the number of 2-year bioassays performed in rodents. As for other assays with a long history of use, the SHE CTA has not undergone formal validation. To address this, the European Centre for the Validation of Alternative Methods (ECVAM) coordinated a prevalidation study. The aim of this study was to evaluate the within-laboratory reproducibility, test method transferability, and between-laboratory reproducibility and to develop a standardised state-of-the-art protocol for the SHE CTA at pH 6.7. Formal ECVAM principles for criteria on reproducibility (including the within-laboratory reproducibility, the transferability and the between-laboratories reproducibility) were applied. In addition to the assessment of reproducibility, this study helped define a standard protocol for use in developing an Organisation for Economic Co-operation and Development (OECD) test guideline for the SHE CTA. Six compounds were evaluated in this study: benzo(a)pyrene, 3-methylcholanthrene, o-toluidine HCl, 2,4-diaminotoluene, phthalic anhydride and anthracene. Results of this study demonstrate that a protocol is available that is transferable between laboratories, and that the SHE CTA at pH 6.7 is reproducible within- and between-laboratories."
}
@article{BAEK201624,
title = "A fully persistent and consistent read/write cache using flash-based general SSDs for desktop workloads",
journal = "Information Systems",
volume = "58",
pages = "24 - 42",
year = "2016",
issn = "0306-4379",
doi = "https://doi.org/10.1016/j.is.2016.02.002",
url = "http://www.sciencedirect.com/science/article/pii/S0306437916300473",
author = "Sung Hoon Baek and Ki-Woong Park",
keywords = "Secondary storage",
abstract = "The flash-based SSD is used as a tiered cache between RAM and HDD. Conventional schemes do not utilize the nonvolatile feature of SSD and cannot cache write requests. Writes are a significant, or often dominant, fraction of storage workloads. To cache write requests, the SSD cache should persistently and consistently manage its data and metadata, and guarantee no data loss even after a crash. Persistent cache management may require frequent metadata changes and causes high overhead. Some researchers insist that a nonvolatile persistent cache requires new additional primitives that are not supported by general SSDs in the market. We proposed a fully persistent read/write cache, which improves both read and write performance, does not require any special primitive, has a low overhead, guarantees the integrity of the cache metadata and the consistency of the cached data, even during a crash or power failure, and is able to recover the flash cache quickly without any data loss. We implemented the persistent read/write cache as a block device driver in Linux. Our scheme aims at virtual desktop infra servers. So the evaluation was performed with massive, real desktop traces of five users for ten days. The evaluation shows that our scheme outperforms an LRU version of SSD cache by 50% and the read-only version of our scheme by 37%, on average, for all experiments. This paper describes most of the parts of our scheme in detail. Detailed pseudo-codes are included in the Appendix."
}
@article{GALLERANI2017S109,
title = "“We actually care and we want to make the parks better”: A qualitative study of youth experiences and perceptions after conducting park audits",
journal = "Preventive Medicine",
volume = "95",
pages = "S109 - S114",
year = "2017",
note = "Active Living Research - Equity in Active Living",
issn = "0091-7435",
doi = "https://doi.org/10.1016/j.ypmed.2016.08.043",
url = "http://www.sciencedirect.com/science/article/pii/S009174351630247X",
author = "David G. Gallerani and Gina M. Besenyi and Sonja A. Wilhelm Stanis and Andrew T. Kaczynski",
keywords = "Youth advocacy, Active living, Parks and recreation, Community policy systems, Environmental change",
abstract = "This study explored youths' experiences and perceptions about community engagement as a result of participating in a community-based data collection project using paper and mobile technology park environmental audit tools. In July 2014, youth (ages 11–18, n=50) were recruited to participate in nine focus groups after auditing two parks each using paper, electronic, or both versions of the Community Park Audit Tool in Greenville County, SC. The focus groups explored the youths' experiences participating in the project, changes as a result of participation, suggested uses of park audit data collected, and who should use the tools. Four themes emerged related to youths' project participation experiences: two positive (fun and new experiences) and two negative (uncomfortable/unsafe and travel issues). Changes described as a result of participating in the project fell into four themes: increased awareness, motivation for further action, physical activity benefits, and no change. Additionally, youth had numerous suggestions for utilizing the data collected that were coded into six themes: maintenance & aesthetics, feature/amenity addition, online park information, park rating/review system, fundraising, and organizing community projects. Finally, six themes emerged regarding who the youth felt could use the tools: frequent park visitors, community groups/organizations, parks and recreation professionals, adults, youth, and everyone. This study revealed a wealth of information about youth experiences conducting park audits for community health promotion. Understanding youth attitudes and preferences can help advance youth empowerment and civic engagement efforts to promote individual and community health."
}
@article{BRUMOVSKY20151544,
title = "Cladding in RPV Integrity and Lifetime Evaluation",
journal = "Procedia Engineering",
volume = "130",
pages = "1544 - 1553",
year = "2015",
note = "Pressure Vessel Technology: Preparing for the Future",
issn = "1877-7058",
doi = "https://doi.org/10.1016/j.proeng.2015.12.323",
url = "http://www.sciencedirect.com/science/article/pii/S1877705815042071",
author = "M. Brumovsky and M. Kytka and R. Kopriva",
keywords = "Reactor pressure vessel, austenitic cladding, integrity, WWER reactors",
abstract = "According to all design codes (ASME, RCC-M, KTA, JARC, PNAEG,…) austenitic cladding on inner surface of RPVs is usually taken only as a protection against corrosion. Its tensile properties as well as its existence is not taken into account in design of the RPVs, i.e. in the determination of their dimensions as well as during stress analysis and comparison with allowable stresses/stress intensities. Austenitic cladding due to its manufacturing history – mostly by strip welding without subsequent austenitization – has not very high toughness that can be important in evaluation of some regimes like during emergency cooling when “PTS – pressurized thermal shock” is present. Existence of cladding, its properties, defectness and system of in-service NDT inspection determine the type, size and shape of so-called “postulated defect” in evaluation of RPV resistance against non-ductile failure. According to some codes (e.g. IAEA VERLIFE etc.) fracture properties must be taken into account in these calculations. Unfortunately, each of cladding layers has different properties and their fracture properties are changing during operation – some embrittlement can be found as a result of neutron irradiation. This paper will describe problems connected with the effect of cladding on RPV resistance against non-ductile failure during regimes of PTS type and also gives some examples and criteria for their evaluation."
}
@article{CHEN201613,
title = "Discriminative local collaborative representation for online object tracking",
journal = "Knowledge-Based Systems",
volume = "100",
pages = "13 - 24",
year = "2016",
issn = "0950-7051",
doi = "https://doi.org/10.1016/j.knosys.2016.01.041",
url = "http://www.sciencedirect.com/science/article/pii/S095070511600071X",
author = "Si Chen and Shaozi Li and Rongrong Ji and Yan Yan and Shunzhi Zhu",
keywords = "Object tracking, Online learning, Collaborative representation, Local coding, Discriminative tracking",
abstract = "Sparse representation has been widely applied to object tracking. However, most sparse representation based trackers only use the holistic template to encode the candidates, where the discriminative information to separate the target from the background is ignored. In addition, the sparsity assumption with the l1 norm minimization is computationally expensive. In this paper, we propose a robust discriminative local collaborative (DLC) representation algorithm for online object tracking. DLC collaboratively uses the local image patches of both the target templates and the background ones to encode the candidates by an efficient local regularized least square solver with the l2 norm minimization, where the feature vectors are obtained by employing an effective discriminative-pooling method. Furthermore, we formulate the tracking as a discriminative classification problem, where the classifier is online updated by using the candidates predicted according to the residuals of their local patches. To adapt to the appearance changes, we iteratively update the dictionary with the foreground and background templates from the current frame and take occlusions into account as well. Experimental results demonstrate that our proposed algorithm performs favorably against the state-of-the-art trackers on several challenging video sequences."
}
@article{GU20141086,
title = "Low-disruptive dynamic updating of Java applications",
journal = "Information and Software Technology",
volume = "56",
number = "9",
pages = "1086 - 1098",
year = "2014",
note = "Special Sections from “Asia-Pacific Software Engineering Conference (APSEC), 2012” and “ Software Product Line conference (SPLC), 2012”",
issn = "0950-5849",
doi = "https://doi.org/10.1016/j.infsof.2014.04.003",
url = "http://www.sciencedirect.com/science/article/pii/S0950584914000846",
author = "Tianxiao Gu and Chun Cao and Chang Xu and Xiaoxing Ma and Linghao Zhang and Jian Lü",
keywords = "Dynamic software updating, JVM, Lazy updating, Low disruption",
abstract = "Context
In-use software systems are destined to change in order to fix bugs or add new features. Shutting down a running system before updating it is a normal practice, but the service unavailability can be annoying and sometimes unacceptable. Dynamic software updating (DSU) migrates a running software system to a new version without stopping it. State-of-the-art Java DSU systems are unsatisfactory as they may cause a non-negligible system pause during updating.
Objective
In this paper we present Javelus, a Java HotSpot VM-based Java DSU system with very short pausing time.
Method
Instead of updating everything at once when the running application is suspended, Javelus only updates the changed code during the suspension, and migrates stale objects on-demand after the application is resumed. With a careful design this lazy approach neither sacrifices the update flexibility nor introduces unnecessary object validity checks or access indirections.
Results
Evaluation experiments show that Javelus can reduce the updating pausing time by one to two orders of magnitude without introducing observable overheads before and after the dynamic updating.
Conclusion
Our experience with Javelus indicates that low-disruptive and type-safe dynamic updating of Java applications can be practically achieved with a lazy updating approach."
}
@article{WHITFIELD2012224,
title = "A collaborative platform for integrating and optimising Computational Fluid Dynamics analysis requests",
journal = "Computer-Aided Design",
volume = "44",
number = "3",
pages = "224 - 240",
year = "2012",
note = "Applications in Ship and Floating Structure Design and Analysis",
issn = "0010-4485",
doi = "https://doi.org/10.1016/j.cad.2011.04.004",
url = "http://www.sciencedirect.com/science/article/pii/S0010448511000881",
author = "R.I. Whitfield and A.H.B. Duffy and S. Gatchell and J. Marzi and W. Wang",
keywords = "Integration, Collaboration, Co-ordination, Optimisation, Computational Fluid Dynamics",
abstract = "A Virtual Integration Platform (VIP) is described which provides support for the integration of Computer-Aided Design (CAD) and Computational Fluid Dynamics (CFD) analysis tools into an environment that supports the use of these tools in a distributed collaborative manner. The VIP has evolved through previous EU research conducted within the VRShips-ROPAX 2000 (VRShips) project and the current version discussed here was developed predominantly within the VIRTUE project but also within the SAFEDOR project. The VIP is described with respect to the support it provides to designers and analysts in co-ordinating and optimising CFD analysis requests. Two case studies are provided that illustrate the application of the VIP within HSVA: the use of a panel code for the evaluation of geometry variations in order to improve propeller efficiency, and the use of a dedicated maritime RANS code (FreSCo) to improve the wake distribution for the VIRTUE tanker. A discussion is included detailing the background, application and results from the use of the VIP within these two case studies as well as how the platform was of benefit during the development and a consideration of how it can benefit HSVA in the future."
}
@article{ANDREU20163,
title = "Wize Mirror - a smart, multisensory cardio-metabolic risk monitoring system",
journal = "Computer Vision and Image Understanding",
volume = "148",
pages = "3 - 22",
year = "2016",
note = "Special issue on Assistive Computer Vision and Robotics - Assistive Solutions for Mobility, Communication and HMI",
issn = "1077-3142",
doi = "https://doi.org/10.1016/j.cviu.2016.03.018",
url = "http://www.sciencedirect.com/science/article/pii/S1077314216300224",
author = "Yasmina Andreu and Franco Chiarugi and Sara Colantonio and Giorgos Giannakakis and Daniela Giorgi and Pedro Henriquez and Eleni Kazantzaki and Dimitris Manousos and Kostas Marias and Bogdan J. Matuszewski and Maria Antonietta Pascali and Matthew Pediaditis and Giovanni Raccichini and Manolis Tsiknakis",
keywords = "Unobtrusive health monitoring, 3D face detection, Tracking and reconstruction, 3D morphometric analysis, Psycho-somatic status recognition, Multimodal data integration",
abstract = "In the recent years personal health monitoring systems have been gaining popularity, both as a result of the pull from the general population, keen to improve well-being and early detection of possibly serious health conditions and the push from the industry eager to translate the current significant progress in computer vision and machine learning into commercial products. One of such systems is the Wize Mirror, built as a result of the FP7 funded SEMEOTICONS (SEMEiotic Oriented Technology for Individuals CardiOmetabolic risk self-assessmeNt and Self-monitoring) project. The project aims to translate the semeiotic code of the human face into computational descriptors and measures, automatically extracted from videos, multispectral images, and 3D scans of the face. The multisensory platform, being developed as the result of that project, in the form of a smart mirror, looks for signs related to cardio-metabolic risks. The goal is to enable users to self-monitor their well-being status over time and improve their life-style via tailored user guidance. This paper is focused on the description of the part of that system, utilising computer vision and machine learning techniques to perform 3D morphological analysis of the face and recognition of psycho-somatic status both linked with cardio-metabolic risks. The paper describes the concepts, methods and the developed implementations as well as reports on the results obtained on both real and synthetic datasets."
}
@article{DASHTBAN201791,
title = "Gene selection for microarray cancer classification using a new evolutionary method employing artificial intelligence concepts",
journal = "Genomics",
volume = "109",
number = "2",
pages = "91 - 107",
year = "2017",
issn = "0888-7543",
doi = "https://doi.org/10.1016/j.ygeno.2017.01.004",
url = "http://www.sciencedirect.com/science/article/pii/S0888754317300046",
author = "M. Dashtban and Mohammadali Balafar",
keywords = "Gene selection, Cancer classification, Microarray data analysis, Intelligent Dynamic Algorithm, Random-restart hill climbing, Reinforcement learning, Penalizing strategy, Cut and splice crossover, Self-refinement strategy, Feature selection",
abstract = "Gene selection is a demanding task for microarray data analysis. The diverse complexity of different cancers makes this issue still challenging. In this study, a novel evolutionary method based on genetic algorithms and artificial intelligence is proposed to identify predictive genes for cancer classification. A filter method was first applied to reduce the dimensionality of feature space followed by employing an integer-coded genetic algorithm with dynamic-length genotype, intelligent parameter settings, and modified operators. The algorithmic behaviors including convergence trends, mutation and crossover rate changes, and running time were studied, conceptually discussed, and shown to be coherent with literature findings. Two well-known filter methods, Laplacian and Fisher score, were examined considering similarities, the quality of selected genes, and their influences on the evolutionary approach. Several statistical tests concerning choice of classifier, choice of dataset, and choice of filter method were performed, and they revealed some significant differences between the performance of different classifiers and filter methods over datasets. The proposed method was benchmarked upon five popular high-dimensional cancer datasets; for each, top explored genes were reported. Comparing the experimental results with several state-of-the-art methods revealed that the proposed method outperforms previous methods in DLBCL dataset."
}
@article{FLETCHER201898,
title = "Attitudes toward alcohol use during pregnancy among women recruited from alcohol-serving venues in Cape Town, South Africa: A mixed-methods study",
journal = "Social Science & Medicine",
volume = "215",
pages = "98 - 106",
year = "2018",
issn = "0277-9536",
doi = "https://doi.org/10.1016/j.socscimed.2018.09.008",
url = "http://www.sciencedirect.com/science/article/pii/S027795361830491X",
author = "Olivia V. Fletcher and Philip A. May and Soraya Seedat and Kathleen J. Sikkema and Melissa H. Watt",
keywords = "South Africa, FASD, Fetal alcohol syndrome, Alcohol use, Pregnancy",
abstract = "Background
The Western Cape Province of South Africa has one of the highest rates of fetal alcohol spectrum disorder (FASD) globally. Effective prevention of FASD requires understanding women's attitudes about alcohol use during pregnancy and whether these attitudes translate into behavior.
Objective
The goal of this mixed-methods study was to describe attitudes toward alcohol use during pregnancy and examine how these attitudes influence drinking behaviors during pregnancy.
Method
Over a five month period, 200 women were recruited from alcohol-serving venues in a township in Cape Town; a sub-set of 23 also completed in-depth interviews. Potential gaps between attitudes and behavior were described, and logistic regression models examined predictors of harmful attitudes toward alcohol use during pregnancy. Interviews were reviewed and coded for emergent themes.
Results
Most women (n = 176) reported at least one pregnancy. Among these, the majority (83%) had positive preventive attitudes, but more than half of these still reported alcohol use during a previous pregnancy. The strongest predictors of harmful attitudes were a history of physical or sexual abuse and drinking during a previous pregnancy. Qualitative analysis revealed several themes that contributed to alcohol use during pregnancy: 1) having an unplanned pregnancy; 2) drinking because of stress or to cope with abuse/trauma; 3) reliance on the venue for support; 4) socialization; and 5) feelings of invincibility.
Conclusions
The findings highlight an attitude-behavior gap and suggest that positive preventive attitudes are insufficient to elicit FASD preventive behavior. Interventions are needed that go beyond education to build intrinsic motivation and structural support to refrain from alcohol use during pregnancy."
}
@article{MARTINEZ2013199,
title = "Methodologies for an improved prediction of the isotopic content in high burnup samples. Application to Vandellós-II reactor core",
journal = "Annals of Nuclear Energy",
volume = "57",
pages = "199 - 208",
year = "2013",
issn = "0306-4549",
doi = "https://doi.org/10.1016/j.anucene.2012.11.034",
url = "http://www.sciencedirect.com/science/article/pii/S0306454912004859",
author = "J.S. Martínez and O. Cabellos and C.J. Díez",
keywords = "Burnup credit, Isotopic prediction, High burnup, SCALE 6.0, MONTURNS 2.0, Vandellós-II",
abstract = "Fuel cycles are designed with the aim of obtaining the highest amount of energy possible. Since higher burnup values are reached, it is necessary to improve our disposal designs, traditionally based on the conservative assumption that they contain fresh fuel. The criticality calculations involved must consider burnup by making the most of the experimental and computational capabilities developed, respectively, to measure and predict the isotopic content of the spent nuclear fuel. These high burnup scenarios encourage a review of the computational tools to find out possible weaknesses in the nuclear data libraries, in the methodologies applied and their applicability range. Experimental measurements of the spent nuclear fuel provide the perfect framework to benchmark the most well-known and established codes, both in the industry and academic research activity. For the present paper, SCALE 6.0/TRITON and MONTEBURNS 2.0 have been chosen to follow the isotopic content of four samples irradiated in the Spanish Vandellós-II pressurized water reactor up to burnup values ranging from 40 GWd/MTU to 75 GWd/MTU. By comparison with the experimental data reported for these samples, we can probe the applicability of these codes to deal with high burnup problems. We have developed new computational tools within MONTENBURNS 2.0. They make possible to handle an irradiation history that includes geometrical and positional changes of the samples within the reactor core. This paper describes the irradiation scenario against which the mentioned codes and our capabilities are to be benchmarked."
}
@article{FILATOVA201334,
title = "Is killer whale dialect evolution random?",
journal = "Behavioural Processes",
volume = "99",
pages = "34 - 41",
year = "2013",
issn = "0376-6357",
doi = "https://doi.org/10.1016/j.beproc.2013.06.008",
url = "http://www.sciencedirect.com/science/article/pii/S0376635713001216",
author = "Olga A. Filatova and Alexandr M. Burdin and Erich Hoyt",
keywords = "Killer whale, Cultural evolution, Stereotyped call, Dialect, Vocal learning",
abstract = "The killer whale is among the few species in which cultural change accumulates over many generations, leading to cumulative cultural evolution. Killer whales have group-specific vocal repertoires which are thought to be learned rather than being genetically coded. It is supposed that divergence between vocal repertoires of sister groups increases gradually over time due to random learning mistakes and innovations. In this case, the similarity of calls across groups must be correlated with pod relatedness and, consequently, with each other. In this study we tested this prediction by comparing the patterns of call similarity between matrilines of resident killer whales from Eastern Kamchatka. We calculated the similarity of seven components from three call types across 14 matrilines. In contrast to the theoretical predictions, matrilines formed different clusters on the dendrograms made by different calls and even by different components of the same call. We suggest three possible explanations for this phenomenon. First, the lack of agreement between similarity patterns of different components may be the result of constraints in the call structure. Second, it is possible that call components change in time with different speed and/or in different directions. Third, horizontal cultural transmission of call features may occur between matrilines."
}
@article{SELIGMANN2014216,
title = "Species radiation by DNA replication that systematically exchanges nucleotides?",
journal = "Journal of Theoretical Biology",
volume = "363",
pages = "216 - 222",
year = "2014",
issn = "0022-5193",
doi = "https://doi.org/10.1016/j.jtbi.2014.08.036",
url = "http://www.sciencedirect.com/science/article/pii/S0022519314004974",
author = "Hervé Seligmann",
keywords = "DNA replication, Swinger DNA polymerization, Invertase, 3′-to-5′ polymerization, Ribosomal RNA",
abstract = "RNA and DNA syntheses share many properties. Therefore, the existence of ‘swinger’ RNAs, presumed ‘orphan’ transcripts matching genomic sequences only if transcription systematically exchanged nucleotides, suggests replication producing swinger DNA. Transcripts occur in many short-lived copies, the few cellular DNA molecules are long-lived. Hence pressures for functional swinger DNAs are greater than for swinger RNAs. Protein coding properties of swinger sequences differ from original sequences, suggesting rarity of corresponding swinger DNA. For genes producing structural RNAs, such as tRNAs and rRNAs, three exchanges (A<–>T, C<–>G and A<–>T+C<–>G) conserve self-hybridization properties. All nuclear eukaryote swinger DNA sequences detected in GenBank are for rRNA genes assuming A<–>T+C<–>G exchanges. In brachyuran crabs, 25 species had A<–>T+C<–>G swinger 18S rDNA, all matching the reverse-exchanged version of regular 18S rDNA of a related species. In this taxon, swinger replication of 18S rDNA apparently associated with, or even resulted in species radiation. A<–>T+C<–>G transformation doesn’t invert sequence direction, differing from inverted repeats. Swinger repeats (detectable only assuming swinger transformations, A<–>T+C<–>G swinger repeats most frequent) within regular human rRNAs, independently confirm swinger polymerizations for most swinger types. Swinger replication might be an unsuspected molecular mechanism for ultrafast speciation."
}
@article{BIN201752,
title = "1SWASP J200503.05-343726.5: A high mass ratio eclipsing binary near the period limit",
journal = "New Astronomy",
volume = "54",
pages = "52 - 55",
year = "2017",
issn = "1384-1076",
doi = "https://doi.org/10.1016/j.newast.2017.01.007",
url = "http://www.sciencedirect.com/science/article/pii/S1384107616301105",
author = "Zhang Bin and Qian Shengbang and Miloslav Zejda and Zhu Liying and Liu Nianping",
keywords = "Binary, Eclipsing binary, Short-period limit, Light curves",
abstract = "First CCD photometric light curves of the eclipsing binary system 1SWASP J200503.05-343726.5 are presented. Our complete light curves in V, R and I bands using the Bessell filter show an out-of-eclipsing distortion, which means that the components of the system may be active. The preliminary photometric solutions with a cool star-spot are derived by using the 2013 version of the Wilson–Devinney (W–D) code. The photometric solutions suggest that 1SWASP J200503.05-343726.5 is a shallow-contact eclipsing binary(f=9.0%) with a mass ratio of q=1.0705, which is very high for late-type binary systems near the period limit. The primary component is about 230  K hotter than the secondary component. Based on our new CCD eclipse times, the orbital period change was analyzed. According to O−C diagram, the orbital period of the 1SWASP J200503.05-343726.5 shows an increase at a rate of P˙=+5.43×10−8 days year−1. The period increase may be caused by mass transfer from the less massive component to the more massive one. This shallow-contact system may be formed from a detached short-period binary via orbital shrinkage because of dynamical interactions with a third component or by magnetic braking."
}
@article{BUSA2015224,
title = "CAVE-CL: An OpenCL version of the package for detection and quantitative analysis of internal cavities in a system of overlapping balls: Application to proteins",
journal = "Computer Physics Communications",
volume = "190",
pages = "224 - 227",
year = "2015",
issn = "0010-4655",
doi = "https://doi.org/10.1016/j.cpc.2014.12.017",
url = "http://www.sciencedirect.com/science/article/pii/S0010465514004378",
author = "Ján Buša and Ján Buša and Shura Hayryan and Chin-Kun Hu and Ming-Chya Wu",
keywords = "Protein, Cavity, OpenCL",
abstract = "Here we present the revised and newly rewritten version of our earlier published CAVE package (Buša et al., 2010) which was originally written in FORTRAN. The package has been rewritten in C language, the algorithm has been parallelized and implemented using OpenCL. This makes the program convenient to run on platforms with Graphical Processing Units (GPUs). Improvements include also some modifications/optimizations of the original algorithm. A considerable improvement in the performance of the code has been achieved. A new tool called input_structure has been added which helps the user to make the data input and conversion more easier and universal.
New version program summary
Program Title: CAVE-CL, CAVE C Catalogue identifier: AEHC_v2_0 Program summary URL:http://cpc.cs.qub.ac.uk/summaries/aehc_v2_0.html Program obtainable from: CPC Program Library, Queen’s University, Belfast, N. Ireland Licensing provisions: Standard CPC license, http://cpc.cs.qub.ac.uk/licence/licence.html No. of lines in distributed program, including test data, etc.: 32646 No. of bytes in distributed program, including test data, etc.: 444248 Distribution format: tar.gz Programming language: C, C++, OpenCL. Computer: PC with GPU. Operating system: OpenCL compatible systems. Has the code been vectorized or parallelized?: Parallelized using GPUs. A revised serial version (non GPU) is included in the package as well. Keywords: Proteins, Solvent accessible area, Excluded volume, Cavities, Analytic method, Stereographic projection, GPGPU, OpenCL. PACS: 82.20.Wt, 02.60.Cb, 02.70.Ns. Classification: 16.1. Catalogue identifier of previous version: AEHC_v1_0. Journal reference of previous version: Comput. Phys. Commun. 181 (2010) 2116. Does the new version supersede the previous version?: Yes Nature of problem: Molecular structure analysis. Solution method: Analytical method, which uses the stereographic transformation for exact detection of internal cavities in the system of overlapping balls and numerical algorithm for calculation of the volume and the surface area of cavities. Reasons for the new version: This work is in line with our global efforts to modernize the protein structure related algorithms and software packages developed in our research group during last several years [1–8]. These tools are keeping to receive considerable attention from researches and they have been used in solving many interesting research problems [9,10]. Among many others, one important application has been found by the members of our team [11]. Therefore, we think that there is a demand to revise and modernize these tools and to make them more efficient. Here we follow the approach used earlier in [8] to develop a new version of the CAVE package [7]. The original CAVE package was written in FORTRAN language. One of the reasons for the new version is to rewrite it in C in order to make it more friendly to the young researchers who are not familiar with FORTRAN. Another, a more important reason, is to use the possibilities of the contemporary hardware (for example, the modern graphical cards) to improve the performance of the package. We also want to allow the user to avoid the re-compiling of the program for every molecule during multiple calculations of the array of molecules. For this purpose we are providing the possibility to use general pdb files as an input. After compiling one time, the program can receive any number of input files successively. Also, we found it necessary to go through the algorithm and to optimize, where it is possible, the memory usage and to make the algorithm more efficient. Summary of revisions:1.Memory usage and language. The whole code has been ported into C and the static arrays have been replaced with dynamic memory allocation. This allows to load and handle the proteins of arbitrary size.2.Changes in the algorithm. Like in [8], the original method of North Pole test and molecule rotation [4] has been changed. The details of implementation and the benefits from this change are properly described in [8] and we find it not necessary to repeat it here.3.New tool. A module called input_structure which takes as an input a protein structure file in the format compatible with Protein Data Bank (pdb) [12] has been adopted from [8]. Using external tool allows users to create their own mappings of atoms and radii without re-compiling the module input_structure itself or the CAVE.It is the user’s responsibility to assign proper radii to each type of atoms. One can use any of the published standard sets of radii (see for example, [13–17]). Alternatively, the user can assign his own values for radii immediately in the module input_structure. The radii are assigned in a special file with extension pds (see the documentation) which consists of lines like this: ATOM CA ALA 2.0 which is read as “the Cα atom of Alanine has radius 2.0 Å”.4.Some computational tricks. In several parts of the program square roots were replaced by second powers and calls of sin and cos functions were replaced by calls to sincos allowing for further speed-up (in comparison to original FORTRAN version).The typical value of the relative error between results obtained by original (FORTRAN), C, and OpenCL versions was between 10−8 and 10−10 and it never exceeded 10−5. Small differences in results can be due to the implementation of compiler and specially in case of OpenCL also in the implementation of arithmetic by the GPU vendor. Table 1Speed-up of C and OpenCL versions of the program CAVE when compared to the original (FORTRAN) version calculated using GNU Fortran (gfort) and Intel® FORTRAN (ifort).ProteinNumberTimeSpeed-upSpeed-upSpeed-upPDB IDof atomsgfort (s)ifortCOpenCL1AUW013872345.981.561.941.971AUW13872235.101.701.753.321DJ30658061.371.551.951.971DJ3658068.801.811.703.121I0A013675358.881.571.971.971I0A13675254.811.671.853.441LD4015648305.431.551.871.911LD415648551.281.581.472.531M3Z011292181.311.541.921.951M3Z11292141.041.751.743.061OJX019368503.021.621.901.901OJX19368339.281.691.603.121OK4019358541.841.671.921.931OK419358414.962.322.394.101QI6014384292.941.551.901.931QI614384237.801.671.823.151QNW0716872.241.551.901.931QNW716871.351.851.673.111S3Q015358376.791.571.951.981S3Q15358349.481.762.033.271UPA016272390.911.551.901.931UPA16272289.551.671.843.091YLO015318306.271.551.881.921YLO15318326.211.611.903.142MYS0628751.371.551.981.972MYS628762.211.781.722.655.OpenCL implementation and testing results. OpenCL [18] is an open standard for parallel programming in heterogeneous systems. It is becoming increasingly popular and has proved to be an efficient tool for computations in different fields (see, for example, the most recent [19,20] and the references therein).Table 1 shows the speedup of the C and OpenCL implementations of CAVE as compared to the FORTRAN version. We compare both results obtained using free GNU FORTRAN (g77) and commercial (and faster) ifort. Speedup is calculated as a ratio between the original time obtained by FORTRAN and C or OpenCL version of program. Times of execution are measured in seconds. Fig. 1Dependence of speed-up of OpenCL CAVE on (a) the number of atoms, (b) the number of neighbors for testing sphere radius rp=0, and (c) rp=1.2. The numbers indicate the slopes of linear fits.One could expect greater speed-ups but the problem is that not the whole algorithm could be parallelized. Only about 1/3 of the whole program was parallelized and the effect of this is visible for the proteins with 2000 atoms and more if the calculation time of FORTRAN version is higher than approximately 10 s. The rest of the code is sequential and its parallelization will require entirely new algorithm which might be the future work. Fig. 1 shows the speed-up as a function of number of neighbors. This clearly indicates, that the effect of parallelization is stronger for proteins with many neighbors. This is also the reason, why the effect is not so strong for proteins with 0 testing sphere radius. Most of the cavities in such case are enclosed only in few (around 4–8) spheres, while in the case of 1.2 testing sphere radius we have easily 35 or more enclosing spheres.In global, we can see that C version is a good choice for general proteins (and testing sphere radius of 0), OpenCL is proper for larger proteins and larger computational times. 0 in the name of protein means that no probe radius has been added to the atomic radii. In other cases 1.2 Å was added to all atomic radii.All results were obtained on computer with Intel Core 2 Duo E8500 CPU running at 3.16 GHz with 4 GB RAM and GPU NVIDIA GTX470 and computer with Intel Xeon X5450 CPU running at 3.00 GHz with 32 GB RAM and dedicated NVIDIA C1060 GPU card.When considering which GPU to use, it is important to watch its double precision performance. Consumer oriented GPUs have usually intentionally decreased double precision performance and because of that results can be similar even if newer generation of GPUs is used. For instance in 2010 the performance in double precision of NVIDIA GPUs (except for highly specialized GPUs for scientific computing) was 1/8 of the performance in single precision. Nowadays (2014) this ratio is 1/24, meaning that GPUs from 2010 are as fast as current GPUs (except for special editions of GPUs or dedicated cards). Restrictions: None Running time: Depends on the size of the molecule under consideration. All test examples run under 1 min, usually under 30 s. The work was supported by Grants MOST 103-2120-M-001-005. References: [1] S. Hayryan, C.-K. Hu, S.-Y. Hu, R.-J. Shang, J. Comput. Chem. 22 (2001) 1287. [2] F. Eisenmenger, U.H.E. Hansmann, S. Hayryan, C.-K. Hu, Comput. Phys. Commun. 138 (2001) 192. [3] F. Eisenmenger, U.H.E. Hansmann, S. Hayryan, C.-K. Hu, Comput. Phys. Commun. 174 (2006) 422. [4] S. Hayryan, C.-K. Hu, J. Skřivánek, E. Hayryan, I. Pokorný, J. Comput. Chem. 26 (2005) 334. [5] J. Buša, J. Džurina, E. Hayryan, S. Hayryan, C.-K. Hu, J. Plavka, I. Pokorný, J. Skřivánek, M.-C. Wu, Comput. Phys. Commun. 165 (2005) 59. [6] J. Buša, S. Hayryan, C.-K. Hu, J. Skřivánek, M.-C. Wu, J. Comput. Chem. 30 (2009) 346. [7] J. Buša, S. Hayryan, M.-C. Wu, J. Skřivánek, C.-K. Hu, Comput. Phys. Commun. 181 (2010) 2116. [8] J. Buša Jr., S. Hayryan, M.-C. Wu, J. Buša, and C.-K. Hu, Comp. Phys. Comm. 183 (2012) 2494-2497. [9] H. L. Chen, et al., Proteins: Structure, Function, and Bioinformatics 78 (2010) 2973. [10] P. Kota, et al., Bioinformatics 27 (2011) 2209-2215. [11] M.-C. Wu, M. S. Li, W.-J. Ma, M. Kouza, C.-K. Hu, EPL 96 (2011) 68005. [12] http://www.rcsb.org. [13] B. Lee, F. M. Richards, J. Mol. Biol. 55 (1971) 379. [14] F. M. Richards, Annu. Rev. Bipohys. Bioeng. 6 (1977) 151. [15] A. Shrake, J. A. Rupley, J. Mol. Biol. 79 (1973) 351. [16] A. A. Rashin, M. Iofin, B. Honig, Biochemistry 25 (1986) 3619. [17] C. Chotia, Nature 248 (1974) 338. [18] http://www.khronos.org/opencl/. [19] M. Molero-Armenta, U. Iturraran-Viveros, S. Aparicio, et al., Comp. Phys. Commun. 185 (2014) 2683. [20] M. Bach, V. Lindenstruth, O. Philipsen, et al., Comp. Phys. Commun. 184 (2013) 2042."
}
@article{ERICKSON2014853,
title = "NSTX-U Control System Upgrades",
journal = "Fusion Engineering and Design",
volume = "89",
number = "6",
pages = "853 - 858",
year = "2014",
issn = "0920-3796",
doi = "https://doi.org/10.1016/j.fusengdes.2014.04.069",
url = "http://www.sciencedirect.com/science/article/pii/S0920379614003469",
author = "K.G. Erickson and D.A. Gates and S.P. Gerhardt and J.E. Lawson and R. Mozulay and P. Sichta and G.J. Tchilinguirian",
keywords = "NSTX-U, PCS, Real time control, Linux, RedHawk",
abstract = "The National Spherical Tokamak Experiment (NSTX) is undergoing a wealth of upgrades (NSTX-U). These upgrades, especially including an elongated pulse length, require broad changes to the control system that has served NSTX well. A new fiber serial Front Panel Data Port input and output (I/O) stream will supersede the aging copper parallel version. Driver support for the new I/O and cyber security concerns require updating the operating system from Redhat Enterprise Linux (RHEL) v4 to RedHawk (based on RHEL) v6. While the basic control system continues to use the General Atomics Plasma Control System (GA PCS), the effort to forward port the entire software package to run under 64-bit Linux instead of 32-bit Linux included PCS modifications subsequently shared with GA and other PCS users. Software updates focused on three key areas: (1) code modernization through coding standards (C99/C11), (2) code portability and maintainability through use of the GA PCS code generator, and (3) support of 64-bit platforms. Central to the control system upgrade is the use of a complete real time (RT) Linux platform provided by Concurrent Computer Corporation, consisting of a computer (iHawk), an operating system and drivers (RedHawk), and RT tools (NightStar). Strong vendor support coupled with an extensive RT toolset influenced this decision. The new real-time Linux platform, I/O, and software engineering will foster enhanced capability and performance for NSTX-U plasma control."
}
@article{HARRISON201673,
title = "A Neurocomputational Account of How Inflammation Enhances Sensitivity to Punishments Versus Rewards",
journal = "Biological Psychiatry",
volume = "80",
number = "1",
pages = "73 - 81",
year = "2016",
note = "Inflammation and Immune Mechanisms in Neuropsychiatry",
issn = "0006-3223",
doi = "https://doi.org/10.1016/j.biopsych.2015.07.018",
url = "http://www.sciencedirect.com/science/article/pii/S000632231500637X",
author = "Neil A. Harrison and Valerie Voon and Mara Cercignani and Ella A. Cooper and Mathias Pessiglione and Hugo D. Critchley",
keywords = "Depression, Imaging, Inflammation, Insula, Reward, Striatum",
abstract = "Background
Inflammation rapidly impairs mood and cognition and, when severe, can appear indistinguishable from major depression. These sickness responses are characterized by an acute reorientation of motivational state; pleasurable activities are avoided, and sensitivity to negative stimuli is enhanced. However, it remains unclear how these rapid shifts in behavior are mediated within the brain.
Methods
Here, we combined computational modeling of choice behavior, experimentally induced inflammation, and functional brain imaging (functional magnetic resonance imaging) to describe these mechanisms. Using a double-blind, randomized crossover study design, 24 healthy volunteers completed a probabilistic instrumental learning task on two separate occasions, one 3 hours after typhoid vaccination and one 3 hours after saline (placebo) injection. Participants learned to select high probability reward (win £1) and avoid high probability punishment (lose £1) stimuli. An action-value learning algorithm was fit to the observed behavior, then used within functional magnetic resonance imaging analyses to identify neural coding of prediction error signals driving motivational learning.
Results
Inflammation acutely biased behavior, enhancing punishment compared with reward sensitivity, through distinct actions on neural representations of reward and punishment prediction errors within the ventral striatum and anterior insula. Consequently, choice options leading to potential rewards were less behaviorally attractive, and those leading to punishments were more aversive.
Conclusions
Our findings demonstrate the neural mediation of a rapid, state-dependent reorientation of reward versus punishment sensitivity during inflammation. This mechanism may aid the adaptive reallocation of metabolic resources during acute sickness but might also account for maladaptive, motivational changes that underpin the association between chronic inflammation and depression."
}
@article{DONDANVILLE20161,
title = "Qualitative examination of cognitive change during PTSD treatment for active duty service members",
journal = "Behaviour Research and Therapy",
volume = "79",
pages = "1 - 6",
year = "2016",
issn = "0005-7967",
doi = "https://doi.org/10.1016/j.brat.2016.01.003",
url = "http://www.sciencedirect.com/science/article/pii/S0005796716300110",
author = "Katherine A. Dondanville and Abby E. Blankenship and Alma Molino and Patricia A. Resick and Jennifer Schuster Wachen and Jim Mintz and Jeffrey S. Yarvis and Brett T. Litz and Elisa V. Borah and John D. Roache and Stacey Young-McCaughan and Elizabeth A. Hembree and Alan L. Peterson",
keywords = "Cognitive processing therapy, PTSD, Military personnel, Trauma, Cognitions",
abstract = "The current study investigated changes in service members' cognitions over the course of Cognitive Processing Therapy (CPT) for posttraumatic stress disorder (PTSD). Sixty-three active duty service members with PTSD were drawn from 2 randomized controlled trials of CPT-Cognitive Only (CPT-C). Participants wrote an impact statement about the meaning of their index trauma at the beginning and again at the end of therapy. Clauses from each impact statement were qualitatively coded into three categories for analysis: assimilation, accommodation, and overaccommodation. The PTSD Checklist, Posttraumatic Symptom Scale-Interview Version, and the Beck Depression Inventory-II were administered at baseline and posttreatment. Repeated measures analyses documented a significant decrease in the percentage of assimilated or overaccommodated statements and an increase in the percentage of accommodated statements from the beginning to the end of treatment. Changes in accommodated statements over the course of treatment were negatively associated with PTSD and depression symptom severity, while statements indicative of overaccommodation were positively associated with both PTSD and depression symptom severity. Treatment responders had fewer overaccommodated and more accommodated statements. Findings suggest that CPT-C changes cognitions over the course of treatment. Methodological limitations and the lack of association between assimilation and PTSD symptom severity are further discussed."
}
@article{VISKONTAS2016200,
title = "Responses of neurons in the medial temporal lobe during encoding and recognition of face-scene pairs",
journal = "Neuropsychologia",
volume = "90",
pages = "200 - 209",
year = "2016",
note = "Memory, Consciousness, and the Brain: A Special Issue in Honour of Morris Moscovitch",
issn = "0028-3932",
doi = "https://doi.org/10.1016/j.neuropsychologia.2016.07.014",
url = "http://www.sciencedirect.com/science/article/pii/S0028393216302585",
author = "Indre V. Viskontas and Barbara J. Knowlton and Itzhak Fried",
keywords = "Episodic memory, Hippocampus, Entorhinal cortex, Epilepsy, Electrophysiology",
abstract = "Associations between co-occurring stimuli are formed in the medial temporal lobe (MTL). Here, we recorded from 508 single and multi-units in the MTL while participants learned and retrieved associations between unfamiliar faces and unfamiliar scenes. Participant's memories for the face-scene pairs were later tested using cued recall and recognition tests. The results show that neurons in the parahippocampal cortex are most likely to respond with changes from baseline firing to these stimuli during both encoding and recognition, and this region showed the greatest proportion of cells showing differential responses depending on the phase of the task. Furthermore, we found that cells in the parahippocampal cortex that responded during both encoding and recognition were more likely to show decreases from baseline firing than cells that were only recruited during recognition, which were more likely to show increases in firing. Since all stimuli shown during recognition were familiar to the patients, these findings suggest that with familiarity, cell responses become more sharply tuned. No neurons in this region, however, were found to be affected by recombining face/scene pairs. Neurons in other MTL regions, particularly the hippocampus, were sensitive to stimulus configurations. Thus, the results support the idea that neurons in the parahippocampal cortex code for features of stimuli and neurons in the hippocampus are more likely to represent their specific configurations."
}
@article{HERMANS20174078,
title = "Novel approaches to assess the quality of fertility data stored in dairy herd management software",
journal = "Journal of Dairy Science",
volume = "100",
number = "5",
pages = "4078 - 4089",
year = "2017",
issn = "0022-0302",
doi = "https://doi.org/10.3168/jds.2016-11896",
url = "http://www.sciencedirect.com/science/article/pii/S0022030217301959",
author = "K. Hermans and W. Waegeman and G. Opsomer and B. Van Ranst and J. De Koster and M. Van Eetvelde and M. Hostens",
keywords = "dairy reproduction, data quality, dairy herd management software, random forests",
abstract = "ABSTRACT
Scientific journals and popular press magazines are littered with articles in which the authors use data from dairy herd management software. Almost none of such papers include data cleaning and data quality assessment in their study design despite this being a very critical step during data mining. This paper presents 2 novel data cleaning methods that permit identification of animals with good and bad data quality. The first method is a deterministic or rule-based data cleaning method. Reproduction and mutation or life-changing events such as birth and death were converted to a symbolic (alphabetical letter) representation and split into triplets (3-letter code). The triplets were manually labeled as physiologically correct, suspicious, or impossible. The deterministic data cleaning method was applied to assess the quality of data stored in dairy herd management from 26 farms enrolled in the herd health management program from the Faculty of Veterinary Medicine Ghent University, Belgium. In total, 150,443 triplets were created, 65.4% were labeled as correct, 17.4% as suspicious, and 17.2% as impossible. The second method, a probabilistic method, uses a machine learning algorithm (random forests) to predict the correctness of fertility and mutation events in an early stage of data cleaning. The prediction accuracy of the random forests algorithm was compared with a classical linear statistical method (penalized logistic regression), outperforming the latter substantially, with a superior receiver operating characteristic curve and a higher accuracy (89 vs. 72%). From those results, we conclude that the triplet method can be used to assess the quality of reproduction data stored in dairy herd management software and that a machine learning technique such as random forests is capable of predicting the correctness of fertility data."
}
@article{SHISHKINA2016148,
title = "Evaluation of distribution coefficients and concentration ratios of 90Sr and 137Cs in the Techa River and the Miass River",
journal = "Journal of Environmental Radioactivity",
volume = "158-159",
pages = "148 - 163",
year = "2016",
issn = "0265-931X",
doi = "https://doi.org/10.1016/j.jenvrad.2016.04.005",
url = "http://www.sciencedirect.com/science/article/pii/S0265931X16300959",
author = "E.A. Shishkina and E.A. Pryakhin and I.Ya Popova and D.I. Osipov and Yu Tikhova and S.S. Andreyev and I.A. Shaposhnikova and E.A. Egoreichenkov and E.V. Styazhkina and L.V. Deryabina and G.A. Tryapitsina and V. Melnikov and G. Rudolfsen and H.-C. Teien and M.K. Sneve and A.V. Akleyev",
keywords = "Aquatic ecosystems, Background radiation, Distribution coefficient, Concentration ratio, Strontium-90, Cesium-137",
abstract = "Empirical data on the behavior of radionuclides in aquatic ecosystems are needed for radioecological modeling, which is commonly used for predicting transfer of radionuclides, estimating doses, and assessing possible adverse effects on species and communities. Preliminary studies of radioecological parameters including distribution coefficients and concentration ratios, for 90Sr and 137Cs were not in full agreement with the default values used in the ERICA Tool and the RESRAD BIOTA codes. The unique radiation situation in the Techa River, which was contaminated by long-lived radionuclides (90Sr and 137Cs) in the middle of the last century allows improved knowledge about these parameters for river systems. Therefore, the study was focused on the evaluation of radioecological parameters (distribution coefficients and concentration ratios for 90Sr and 137Cs) for the Techa River and the Miass River, which is assumed as a comparison waterbody. To achieve the aim the current contamination of biotic and abiotic components of the river ecosystems was studied; distribution coefficients for 90Sr and 137Cs were calculated; concentration ratios of 90Sr and 137Cs for three fish species (roach, perch and pike), gastropods and filamentous algae were evaluated. Study results were then compared with default values available for use in the well-known computer codes ERICA Tool and RESRAD BIOTA (when site-specific data are not available). We show that the concentration ratios of 137Cs in whole fish bodies depend on the predominant type of nutrition (carnivores and phytophagous). The results presented here are useful in the context of improving of tools for assessing concentrations of radionuclides in biota, which could rely on a wider range of ecosystem information compared with the process limited the current versions of ERICA and RESRAD codes. Further, the concentration ratios of 90Sr are species-specific and strongly dependent on Ca2+ concentration in water. The universal characteristic allows us to combine the data of fish caught in the water with different mineralization by multiplying the concentration of Ca2+. The concentration ratios for fishes were well-fitted by Generalized Logistic Distribution function (GLD). In conclusion, the GLD can be used for probabilistic modeling of the concentration ratios in freshwater fishes to improve the confidence in the modeling results. This is important in the context of risk assessment and regulatory."
}
@article{GUT201856,
title = "The effect of human interaction on guinea pig behavior in animal-assisted therapy",
journal = "Journal of Veterinary Behavior",
volume = "25",
pages = "56 - 64",
year = "2018",
issn = "1558-7878",
doi = "https://doi.org/10.1016/j.jveb.2018.02.004",
url = "http://www.sciencedirect.com/science/article/pii/S1558787817300928",
author = "Winnie Gut and Lisa Crump and Jakob Zinsstag and Jan Hattendorf and Karin Hediger",
keywords = "guinea pig, behavior, human-animal interaction, animal-assisted therapy, stress, enrichment",
abstract = "Guinea pigs are included in various animal-assisted interventions (AAIs), but no research has been published to date on behavioral changes in guinea pigs interacting with humans. The goal of this study was to evaluate the behavior in guinea pigs during animal-assisted therapy (AAT) and to identify factors that influence their stress and well-being. Five guinea pigs were studied during 50 observations in a randomized controlled within-subject design with repeated measurement. All guinea pigs were tested under all the following conditions: (1) therapy setting with retreat possibility (n = 20), (2) therapy setting without retreat possibility (n = 10), and (3) control setting without human interaction (n = 20). Behavior was coded according to a specifically designed ethogram using continuous recording and focal animal sampling with The Observer® XT 12.5. The data were analyzed using generalized linear mixed models with SPSS®, version 22.0. Results show that the frequency but not the duration of hiding was significantly increased in the therapy setting with retreat possibility compared to the control condition. During therapy with retreat possibility, the number of comfort behavior episodes stayed constant, while the number of startling and explorative behavior and the duration of locomotion increased significantly in comparison to the control setting. During therapy without retreat possibility, the frequency of freezing was increased significantly in comparison to the therapy setting with retreat possibility and the control setting. Comfort behavior was never observed during therapy without retreat possibility. This study provides evidence that the possibility of retreat is instrumental in reducing stress and should be provided during AAT using guinea pigs. In this form, AAT elicits limited stress and may possibly even provide enrichment. Further research is needed to understand factors influencing guinea pig behavior to ensure animal welfare in AAIs in the future."
}
@article{XIE2016193,
title = "Acoustic classification of Australian frogs based on enhanced features and machine learning algorithms",
journal = "Applied Acoustics",
volume = "113",
pages = "193 - 201",
year = "2016",
issn = "0003-682X",
doi = "https://doi.org/10.1016/j.apacoust.2016.06.029",
url = "http://www.sciencedirect.com/science/article/pii/S0003682X16301864",
author = "Jie Xie and Michael Towsey and Jinglan Zhang and Paul Roe",
keywords = "Frog call classification, Soundscape ecology, Bioacoustics, Acoustic feature extraction",
abstract = "Frogs are often considered as excellent indicators of the overall state of the natural environment, but a steady decrease in the frog population has been noticed worldwide. To monitor this change of frog population and optimise the protection policy, frog call classification has become an important bioacoustic research topic. However, automatic acoustic classification of frog calls has not been adequately addressed in the literature. In this paper, an enhanced feature representation for frog call classification using the temporal, perceptual and cepstral features is presented. With the enhanced feature representation, the time-frequency information of frog calls can be effectively represented, which gives a good classification performance. To be specific, each continuous frog recording is first segmented into individual syllables using the Ha¨rma¨’s method. Then, temporal, perceptual, and cepstral features are calculated from each syllable: syllable duration, Shannon entropy, Rényi entropy, zero-crossing rate, averaged energy, oscillation rate, spectral centroid, spectral flatness, spectral roll-off, signal bandwidth, spectral flux, fundamental frequency, linear predictive coding, and Mel-frequency cepstral coefficients. Next, different feature vectors are fused to obtain different enhanced feature representations. Finally, different enhanced feature representations are compared using five machine learning algorithms: linear discriminant analysis, K-nearest neighbour, support vector machines, random forest, and artificial neural network. Experiment results show that our proposed feature representation could achieve better classification performance comparing to other methods with twenty-four frog species, which are geographically well distributed throughout Queensland, Australia."
}
@article{SPRINGER2015178,
title = "Interordinal gene capture, the phylogenetic position of Steller’s sea cow based on molecular and morphological data, and the macroevolutionary history of Sirenia",
journal = "Molecular Phylogenetics and Evolution",
volume = "91",
pages = "178 - 193",
year = "2015",
issn = "1055-7903",
doi = "https://doi.org/10.1016/j.ympev.2015.05.022",
url = "http://www.sciencedirect.com/science/article/pii/S1055790315001657",
author = "Mark S. Springer and Anthony V. Signore and Johanna L.A. Paijmans and Jorge Vélez-Juarbe and Daryl P. Domning and Cameron E. Bauer and Kai He and Lorelei Crerar and Paula F. Campos and William J. Murphy and Robert W. Meredith and John Gatesy and Eske Willerslev and Ross D.E. MacPhee and Michael Hofreiter and Kevin L. Campbell",
keywords = "Steller’s sea cow, Ancient DNA, Macroevolution, Sirenia, Teeth",
abstract = "The recently extinct (ca. 1768) Steller’s sea cow (Hydrodamalis gigas) was a large, edentulous North Pacific sirenian. The phylogenetic affinities of this taxon to other members of this clade, living and extinct, are uncertain based on previous morphological and molecular studies. We employed hybridization capture methods and second generation sequencing technology to obtain >30kb of exon sequences from 26 nuclear genes for both H. gigas and Dugong dugon. We also obtained complete coding sequences for the tooth-related enamelin (ENAM) gene. Hybridization probes designed using dugong and manatee sequences were both highly effective in retrieving sequences from H. gigas (mean=98.8% coverage), as were more divergent probes for regions of ENAM (99.0% coverage) that were designed exclusively from a proboscidean (African elephant) and a hyracoid (Cape hyrax). New sequences were combined with available sequences for representatives of all other afrotherian orders. We also expanded a previously published morphological matrix for living and fossil Sirenia by adding both new taxa and nine new postcranial characters. Maximum likelihood and parsimony analyses of the molecular data provide robust support for an association of H. gigas and D. dugon to the exclusion of living trichechids (manatees). Parsimony analyses of the morphological data also support the inclusion of H. gigas in Dugongidae with D. dugon and fossil dugongids. Timetree analyses based on calibration density approaches with hard- and soft-bounded constraints suggest that H. gigas and D. dugon diverged in the Oligocene and that crown sirenians last shared a common ancestor in the Eocene. The coding sequence for the ENAM gene in H. gigas does not contain frameshift mutations or stop codons, but there is a transversion mutation (AG to CG) in the acceptor splice site of intron 2. This disruption in the edentulous Steller’s sea cow is consistent with previous studies that have documented inactivating mutations in tooth-specific loci of a variety of edentulous and enamelless vertebrates including birds, turtles, aardvarks, pangolins, xenarthrans, and baleen whales. Further, branch-site dN/dS analyses provide evidence for positive selection in ENAM on the stem dugongid branch where extensive tooth reduction occurred, followed by neutral evolution on the Hydrodamalis branch. Finally, we present a synthetic evolutionary tree for living and fossil sirenians showing several key innovations in the history of this clade including character state changes that parallel those that occurred in the evolutionary history of cetaceans."
}
@article{KUHL2016533,
title = "The incidence of schizophrenia and schizophrenia spectrum disorders in Denmark in the period 2000–2012. A register-based study",
journal = "Schizophrenia Research",
volume = "176",
number = "2",
pages = "533 - 539",
year = "2016",
issn = "0920-9964",
doi = "https://doi.org/10.1016/j.schres.2016.06.023",
url = "http://www.sciencedirect.com/science/article/pii/S0920996416302900",
author = "Johanne Olivia Grønne Kühl and Thomas Munk Laursen and Anne Thorup and Merete Nordentoft",
keywords = "Schizophrenia, First episode psychosis, Incidence, Epidemiology, Early detection",
abstract = "Introduction
We aimed to examine changes over time in the incidence of broad and narrow schizophrenia spectrum disorders in Denmark from 2000 to 2012.
Methods
Patients were classified as incident schizophrenia if registered with a first time in- or outpatient contact with relevant diagnostic codes in the Danish Psychiatric Central Register between 2000 and 2012. Their history of contacts was traced back to 1969. Broad schizophrenia included schizophrenia, schizotypal disorder, persistent delusional disorder, acute and transient psychotic disorders, schizoaffective disorders, and other nonorganic and unspecified psychotic disorders, (ICD 10 codes F20–F29). Narrow schizophrenia was defined with the ICD 10 codes F20.0–F20.9. Incidence rates (IR) and incidence rate ratios (IRR) were calculated using Poisson regression.
Results
The IRR for broad schizophrenia increased by 1.43 (CI 95% 1.34–1.52) for females and 1.26 (CI 95% 1.20–1.33) for males. IRR for narrow schizophrenia increased by 1.36 (CI 95% 1.24–1.48) for females and 1.20 (CI 95% 1.11–1.29) for males. There was a significantly increased incidence in patients up to 32years of age. This was mainly explained by a significant 2–3 fold increase in outpatient incidence. We found a significant decrease in IRR for patients with broad and narrow schizophrenia aged 33 or older for both in- and outpatients.
Conclusion
The increased incidence of schizophrenia could partly be explained by better implementation of the diagnostic criteria for schizophrenia in child and adolescent psychiatry and improved access to early intervention services, but a true increase in incidence of schizophrenia cannot be excluded. The decrease of incidence in the older age group could indicate that the national Danish early intervention strategy was successful."
}
@article{BARROS2015684,
title = "Learning from optimization: A case study with Apache Ant",
journal = "Information and Software Technology",
volume = "57",
pages = "684 - 704",
year = "2015",
issn = "0950-5849",
doi = "https://doi.org/10.1016/j.infsof.2014.07.015",
url = "http://www.sciencedirect.com/science/article/pii/S0950584914001839",
author = "Márcio de Oliveira Barros and Fábio de Almeida Farzat and Guilherme Horta Travassos",
keywords = "Apache Ant, Heuristic search, Software module clustering, Experimental Software Engineering",
abstract = "Context
Software architecture degrades when changes violating the design-time architectural intents are imposed on the software throughout its life cycle. Such phenomenon is called architecture erosion. When changes are not controlled, erosion makes maintenance harder and negatively affects software evolution.
Objective
To study the effects of architecture erosion on a large software project and determine whether search-based module clustering might reduce the conceptual distance between the current architecture and the design-time one.
Method
To run an exploratory study with Apache Ant. First, we characterize Ant’s evolution in terms of size, change dispersion, cohesion, and coupling metrics, highlighting the potential introduction of architecture and code-level problems that might affect the cost of changing the system. Then, we reorganize the distribution of Ant’s classes using a heuristic search approach, intending to re-emerge its design-time architecture.
Results
In characterizing the system, we observed that its original, simple design was lost due to maintenance and the addition of new features. In optimizing its architecture, we found that current models used to drive search-based software module clustering produce complex designs, which maximize the characteristics driving optimization while producing class distributions that would hardly be acceptable to developers maintaining Ant.
Conclusion
The structural perspective promoted by the coupling and cohesion metrics precludes observing the adequate software module clustering from the perspective of software engineers when considering a large open source system. Our analysis adds evidence to the criticism of the dogma of driving design towards high cohesion and low coupling, at the same time observing the need for better models to drive design decisions. Apart from that, we see SBSE as a learning tool, allowing researchers to test Software Engineering models in extreme situations that would not be easily found in software projects."
}
@article{HE2014315,
title = "Exp2 polymorphisms associated with variation for fiber quality properties in cotton (Gossypium spp.)",
journal = "The Crop Journal",
volume = "2",
number = "5",
pages = "315 - 328",
year = "2014",
issn = "2214-5141",
doi = "https://doi.org/10.1016/j.cj.2014.06.002",
url = "http://www.sciencedirect.com/science/article/pii/S2214514114000543",
author = "Daohua He and Zhongping Lei and Hongyi Xing and Baoshan Tang and Junxing Zhao and Bixia Lu",
keywords = "Cotton, , Fiber quality, Linkage disequilibrium, Association mapping",
abstract = "Plant expansins are a group of extracellular proteins thought to affect the quality of cotton fibers. Previous expression profile analysis revealed that six Expansin A genes are present in cotton, of which two (GhExp1 and GhExp2) produce transcripts that are specific to the developing cotton fiber. To identify the phenotypic function of Exp2, and to determine whether nucleotide variation among alleles of Exp2 affects fiber quality, candidate gene association mapping was conducted. Gene-specific primers were designed to amplify the Exp2 gene. By amplicon sequencing, the nucleotide diversity of Exp2 was investigated across 92 accessions (including 7 Gossypium arboreum, 74 Gossypium hirsutum, and 11 Gossypium barbadense accessions) with different fiber qualities. Twenty-six SNPs and seven InDels including 14 from the coding region of Exp2 were detected, forming twelve distinct haplotypes in the cotton collection. Among the 14 SNPs in the coding region, five were missense mutations and nine were synonymous nucleotide changes. The average SNP/InDel per nucleotide ratio was 2.61% (one SNP per 39bp), with 1.81 and 3.87% occurring in coding and non-coding regions, respectively. Nucleotide and haplotype diversity across the entire Exp2 region was 0.00603 (π) and 0.844, respectively, and diversity in non-coding regions was higher than that in coding regions. For linkage disequilibrium (LD), the mean r2 value for all polymorphism loci pairs was 0.48, and LD did not decay over 748bp. Based on 132 simple sequence repeat (SSR) loci evenly covering 26 chromosomes, the population structure was estimated, and the accessions were divided into seven groups that agreed well with their genomic origin and evolutionary history. A general linear model was used to calculate the Exp2-wide diversity–trait associations of 5 fiber quality traits, considering population structure (Q). Four SNPs in Exp2 were associated with at least one of the fiber quality traits, but not with fiber elongation. The highest positive effect on UHML and STR was observed for haplotype Hap_6 of Exp2. There was a significant association of Exp2 with fiber quality traits. There were many haplotypes in the Exp2 region, of which the most favorable was Hap_6. The association between nucleotide diversity and these fiber traits sheds light on the gene's potential contribution to the improvement of fiber quality, and should be useful to facilitate MAS programs in cotton."
}
@article{SANDEEP20161534,
title = "Accident analyses of selected postulated events for safety assessment of Indian LLCB TBS in ITER",
journal = "Fusion Engineering and Design",
volume = "109-111",
pages = "1534 - 1537",
year = "2016",
note = "Proceedings of the 12th International Symposium on Fusion Nuclear Technology-12 (ISFNT-12)",
issn = "0920-3796",
doi = "https://doi.org/10.1016/j.fusengdes.2015.11.031",
url = "http://www.sciencedirect.com/science/article/pii/S0920379615303562",
author = "K.T. Sandeep and Vilas Chaudhari",
keywords = "Accident analyses, Lead Lithium cooled Ceramic Breeder (LLCB), Loss of Coolant Accident (LOCA), Safety analyses, RELAP/MOD4.0",
abstract = "The Lead Lithium cooled Ceramic Breeder (LLCB) TBM) is being developed by India for testing in ITER machine. Thermal hydraulic safety analyses are the essential part of engineering design of LLCB Test Blanket System (TBS) for safe operation in ITER environment. The current work involves thermal hydraulic analyses and preliminary results of selected accident scenarios involving ancillary systems, the First Wall Helium Cooling System (FWHCS) and the Lead Lithium Cooling System (LLCS). A modified version of RELAP/MOD4.0 safety analysis code is used to simulate the transient scenarios. A detailed nodalization is carried out with all the major components in FWHCS and LLCS along with associated heat structures and connected confinement volumes. The accident analysis is performed for the scenarios including the ex-vessel Loss Of Coolant Accident (LOCA) in FWHCS into Port Interspace, Loss Of Fluid Accident (LOFA) and Loss Of Heat Sink (LOHS) accident in FWHCS and LLCS. Transient analyses results of each accident case are reported here and it is found that current design meets most of the thermal hydraulic safety requirements while changes in the design are proposed for certain accident scenarios."
}
@article{DAMSGARD2018516,
title = "Understanding Pain and Pain Management in Elderly Nursing Home Patients Applying an Interprofessional Learning Activity in Health Care Students: A Norwegian Pilot Study",
journal = "Pain Management Nursing",
volume = "19",
number = "5",
pages = "516 - 524",
year = "2018",
issn = "1524-9042",
doi = "https://doi.org/10.1016/j.pmn.2018.02.064",
url = "http://www.sciencedirect.com/science/article/pii/S1524904217303958",
author = "Elin Damsgård and Hege Solgård and Karin Johannessen and Katrine Wennevold and Gunnvald Kvarstein and Gunn Pettersen and Beate Garcia",
abstract = "Background: Pain is common among elderly patients in nursing homes. However, pain assessment and treatment are inadequate. Interprofessional treatment is recommended, and consequently interprofessional education in pain management is necessary. Aims: This pilot project aimed to describe how two interprofessional groups of students approached pain management in two nursing home patients. Design: We formed two teams comprising one student from the nursing, physical therapy, pharmacy, and medical educations. Each team spent one day examining a patient with chronic pain at a nursing home and they developed pain management plans. Methods: We collected data through video recordings during teamwork before and after examining the patients and field notes during the patient examination. We analysed the video-recordings applying the seven-step model including 1) viewing the video data, 2) describing the video data, 3) identifying critical events, 4) transcribing, 5) coding, 6) constructing storyline and 7) composing a narrative. Field notes supplied the transcripts. Results: Both teams succeeded in making a pain management plan for their patient. The common examination of the patient was crucial for the students’ approaches to pain management and changed their pre-assumptions about the patients’ pain. By sharing knowledge and reflecting together, the students reached a common consensus on suggestions for management of the patients’ problems. Interprofessional collaboration fostered enthusiasm and a more holistic pain management approach. However, students’ lack of knowledge limited their understanding of pain. Conclusion: Knowledge of pain management in nursing home patients and the practice of interprofessional cooperation should be included in pain curricula for health care professionals."
}